{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 01:03:23.812516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 01:03:24.689264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 01:03:24.689345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-13 01:03:24.689351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sgt import SGT\n",
    "import os \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.metrics import binary_accuracy, Precision, Recall, AUC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Corpus\n",
    "path = '../TOP_CON/Healthy/'\n",
    "folder_names = os.listdir(path)\n",
    "\n",
    "def load_files(folder_names, path):\n",
    "    l = []\n",
    "    for folder in folder_names: \n",
    "        p = path + folder + '/'\n",
    "        p_os = os.listdir(p)\n",
    "        for filename in p_os:\n",
    "            if filename!='.ipynb_checkpoints': \n",
    "                new_path = p + filename \n",
    "                x = pd.read_csv(new_path)\n",
    "                l.append(x)\n",
    "    return l\n",
    "corpus_healthy = load_files(folder_names, path)\n",
    "\n",
    "path = '../TOP_CON/Glaucoma/'\n",
    "folder_names = os.listdir(path)\n",
    "\n",
    "corpus_diseased = load_files(folder_names, path)\n",
    "\n",
    "\n",
    "for i in corpus_diseased:\n",
    "    i['fixation_id_new'] = i['fixation_id'] - i.iloc[0,2] + 1\n",
    "\n",
    "for i in corpus_healthy:\n",
    "    i['fixation_id_new'] = i['fixation_id'] - i.iloc[0,2] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encode(x,y):\n",
    "    arr = []\n",
    "    for i,j in zip(x,y):\n",
    "        if 0<i and 0.6 > i and 0<j and 0.6 > j: \n",
    "            arr.append('A')\n",
    "        elif 0<i and 0.25 > i and 0.6<j and 1 > j: \n",
    "            arr.append('B')\n",
    "        elif 0.25<i and 0.48 > i and 0.6<j and 1 > j: \n",
    "            arr.append('C')\n",
    "        elif 0.48<i and 0.6 > i and 0.6<j and 1 > j: \n",
    "            arr.append('D')\n",
    "        elif 0.6<i and 1 > i and 0<j and 0.6 > j: \n",
    "            arr.append('E')\n",
    "        elif 0.6<i and 0.77 > i and 0.6<j and 1 > j: \n",
    "            arr.append('F')\n",
    "        elif 0.77<i and 1 > i and 0.6<j and 1 > j: \n",
    "            arr.append('G')\n",
    "        else: \n",
    "            arr.append('error')\n",
    "\n",
    "    return arr\n",
    "    \n",
    "def make_corpus(corpus_new):\n",
    "    A = np.array(corpus_new.fixation_id_new[corpus_new.letters=='A'])\n",
    "    B = np.array(corpus_new.fixation_id_new[corpus_new.letters=='B'])\n",
    "    C = np.array(corpus_new.fixation_id_new[corpus_new.letters=='C'])\n",
    "    D = np.array(corpus_new.fixation_id_new[corpus_new.letters=='D'])\n",
    "    E = np.array(corpus_new.fixation_id_new[corpus_new.letters=='E'])\n",
    "    F = np.array(corpus_new.fixation_id_new[corpus_new.letters=='F'])\n",
    "    G = np.array(corpus_new.fixation_id_new[corpus_new.letters=='G'])\n",
    "    corpus = pd.DataFrame([[1, A], \n",
    "                           [2, B],\n",
    "                           [3, C], \n",
    "                           [4, D], \n",
    "                           [5, E], \n",
    "                           [6, F],\n",
    "                           [7, G]], columns=['id', 'sequence'])\n",
    "    return corpus\n",
    "\n",
    "l = []\n",
    "for i in corpus_healthy: \n",
    "    arr = cat_encode(i.norm_pos_x, i.norm_pos_y)\n",
    "    \n",
    "    i['letters'] = arr\n",
    "    i_new = i[['letters', 'fixation_id_new']]\n",
    "    i_new = make_corpus(i_new)\n",
    "    l.append(i_new)\n",
    "    \n",
    "for i in corpus_diseased: \n",
    "    arr = cat_encode(i.norm_pos_x, i.norm_pos_y)\n",
    "    i['letters'] = arr\n",
    "    i_new = i[['letters', 'fixation_id_new']]\n",
    "    i_new = make_corpus(i_new)\n",
    "    l.append(i_new)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "179\n",
      "       (1, 1)    (1, 2)    (1, 3)    (1, 4)    (1, 5)        (1, 6)  \\\n",
      "id                                                                    \n",
      "1.0  0.367879  0.126073  0.004864  0.000115  0.000006  3.889671e-07   \n",
      "2.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "3.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "4.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "5.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "6.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "7.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "\n",
      "           (1, 7)        (1, 8)        (1, 9)       (1, 11)  ...  (16, 5)  \\\n",
      "id                                                           ...            \n",
      "1.0  3.856611e-08  1.920094e-09  9.559584e-11  3.687803e-12  ...      0.0   \n",
      "2.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "3.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "4.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "5.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "6.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "7.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "\n",
      "     (16, 6)  (16, 7)  (16, 8)  (16, 9)  (16, 11)  (16, 13)  (16, 14)  \\\n",
      "id                                                                      \n",
      "1.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "2.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "3.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "4.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "5.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "6.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "7.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "\n",
      "     (16, 15)  (16, 16)  \n",
      "id                       \n",
      "1.0       0.0  0.290365  \n",
      "2.0       0.0  0.000000  \n",
      "3.0       0.0  0.000000  \n",
      "4.0       0.0  0.000000  \n",
      "5.0       0.0  0.000000  \n",
      "6.0       0.0  0.000000  \n",
      "7.0       0.0  0.000000  \n",
      "\n",
      "[7 rows x 196 columns]\n"
     ]
    }
   ],
   "source": [
    "e = []\n",
    "for i in l: \n",
    "    sgt_ = SGT(kappa=1, \n",
    "               lengthsensitive=False, \n",
    "               mode='multiprocessing')\n",
    "    sgtembedding_df = sgt_.fit_transform(i)\n",
    "    sgtembedding_df = sgtembedding_df.set_index('id')\n",
    "    e.append(sgtembedding_df)\n",
    "    \n",
    "\n",
    "print(len(e))\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0x1</th>\n",
       "      <th>1x1</th>\n",
       "      <th>2x1</th>\n",
       "      <th>3x1</th>\n",
       "      <th>4x1</th>\n",
       "      <th>5x1</th>\n",
       "      <th>6x1</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958814</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.171003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492505</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.109084</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.040909</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.177155</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583557</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.119260</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398856</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.026890</td>\n",
       "      <td>-0.316938</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.054057</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.189305</td>\n",
       "      <td>-0.186566</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.687810</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.147840</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.074732</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.313248</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.124787</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.261763</td>\n",
       "      <td>-0.157908</td>\n",
       "      <td>-0.182191</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.549556</td>\n",
       "      <td>-0.129901</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.099188</td>\n",
       "      <td>-0.176525</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>-0.385461</td>\n",
       "      <td>-0.154107</td>\n",
       "      <td>-0.139862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0x1       1x1       2x1       3x1       4x1       5x1       6x1  \\\n",
       "0    0.958814 -0.157562 -0.157562 -0.157562 -0.157562 -0.157562 -0.171003   \n",
       "1    0.492505 -0.076684 -0.076684 -0.076684 -0.076684 -0.109084 -0.076684   \n",
       "2    1.040909 -0.152488 -0.152488 -0.177155 -0.253801 -0.152488 -0.152488   \n",
       "3    0.583557 -0.083858 -0.083858 -0.083858 -0.119260 -0.106362 -0.106362   \n",
       "4    0.398856 -0.013757 -0.013757 -0.013757 -0.026890 -0.316938 -0.013757   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  1.054057 -0.169547 -0.169547 -0.189305 -0.186566 -0.169547 -0.169547   \n",
       "175  0.687810 -0.116309 -0.147840 -0.116309 -0.074732 -0.116309 -0.116309   \n",
       "176  0.313248 -0.037692 -0.037692 -0.037692 -0.124787 -0.037692 -0.037692   \n",
       "177  1.261763 -0.157908 -0.182191 -0.121104 -0.549556 -0.129901 -0.121104   \n",
       "178  1.099188 -0.176525 -0.081416 -0.161817 -0.385461 -0.154107 -0.139862   \n",
       "\n",
       "     labels  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "174       0  \n",
       "175       0  \n",
       "176       0  \n",
       "177       0  \n",
       "178       0  \n",
       "\n",
       "[179 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for i in e: \n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(i)\n",
    "    X=pca.transform(i)\n",
    "    df = pd.DataFrame(data=X, columns=['x1'])\n",
    "    df_new = pd.DataFrame([[df.iloc[0,0], \n",
    "                   df.iloc[1,0], \n",
    "                   df.iloc[2,0], \n",
    "                  df.iloc[3,0],\n",
    "                  df.iloc[4,0], \n",
    "                   df.iloc[5,0],\n",
    "                  df.iloc[6,0]]], \n",
    "                 columns = ['0x1', '1x1', '2x1',  '3x1',  '4x1', '5x1',  '6x1'])\n",
    "    df2 = pd.concat([df2, df_new])\n",
    "df2 = df2.reset_index().drop([\"index\"], axis = 1)\n",
    "labels = [1]*90 + [0]*89\n",
    "\n",
    "df2['labels'] = labels\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0x1</th>\n",
       "      <th>0x2</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>2x1</th>\n",
       "      <th>2x2</th>\n",
       "      <th>3x1</th>\n",
       "      <th>3x2</th>\n",
       "      <th>4x1</th>\n",
       "      <th>4x2</th>\n",
       "      <th>5x1</th>\n",
       "      <th>5x3</th>\n",
       "      <th>6x1</th>\n",
       "      <th>6x2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958814</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.171003</td>\n",
       "      <td>0.241227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492505</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.109084</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.040909</td>\n",
       "      <td>0.045676</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.177155</td>\n",
       "      <td>-0.188429</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>0.583907</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583557</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.119260</td>\n",
       "      <td>0.287432</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398856</td>\n",
       "      <td>0.211806</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.026890</td>\n",
       "      <td>-0.208519</td>\n",
       "      <td>-0.316938</td>\n",
       "      <td>0.297288</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.054057</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.189305</td>\n",
       "      <td>0.281765</td>\n",
       "      <td>-0.186566</td>\n",
       "      <td>-0.217804</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.687810</td>\n",
       "      <td>-0.021888</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.147840</td>\n",
       "      <td>-0.238143</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.074732</td>\n",
       "      <td>0.242721</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.313248</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.124787</td>\n",
       "      <td>0.221661</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.261763</td>\n",
       "      <td>0.311580</td>\n",
       "      <td>-0.157908</td>\n",
       "      <td>-0.316158</td>\n",
       "      <td>-0.182191</td>\n",
       "      <td>-0.378833</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.229561</td>\n",
       "      <td>-0.549556</td>\n",
       "      <td>1.091942</td>\n",
       "      <td>-0.129901</td>\n",
       "      <td>-0.249410</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.229561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.099188</td>\n",
       "      <td>0.177750</td>\n",
       "      <td>-0.176525</td>\n",
       "      <td>-0.257409</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>-0.209941</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>-0.227856</td>\n",
       "      <td>-0.385461</td>\n",
       "      <td>0.917953</td>\n",
       "      <td>-0.154107</td>\n",
       "      <td>-0.213162</td>\n",
       "      <td>-0.139862</td>\n",
       "      <td>-0.187336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0x1       0x2       1x1       1x2       2x1       2x2       3x1  \\\n",
       "0    0.958814  0.002904 -0.157562 -0.048826 -0.157562 -0.048826 -0.157562   \n",
       "1    0.492505  0.013559 -0.076684 -0.050352 -0.076684 -0.050352 -0.076684   \n",
       "2    1.040909  0.045676 -0.152488 -0.110288 -0.152488 -0.110288 -0.177155   \n",
       "3    0.583557  0.007808 -0.083858 -0.024879 -0.083858 -0.024879 -0.083858   \n",
       "4    0.398856  0.211806 -0.013757 -0.075144 -0.013757 -0.075144 -0.013757   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  1.054057  0.001520 -0.169547 -0.016370 -0.169547 -0.016370 -0.189305   \n",
       "175  0.687810 -0.021888 -0.116309  0.004327 -0.147840 -0.238143 -0.116309   \n",
       "176  0.313248  0.055010 -0.037692 -0.055334 -0.037692 -0.055334 -0.037692   \n",
       "177  1.261763  0.311580 -0.157908 -0.316158 -0.182191 -0.378833 -0.121104   \n",
       "178  1.099188  0.177750 -0.176525 -0.257409 -0.081416 -0.209941 -0.161817   \n",
       "\n",
       "          3x2       4x1       4x2       5x1       5x3       6x1       6x2  \\\n",
       "0   -0.048826 -0.157562 -0.048826 -0.157562 -0.048826 -0.171003  0.241227   \n",
       "1   -0.050352 -0.076684 -0.050352 -0.109084  0.238200 -0.076684 -0.050352   \n",
       "2   -0.188429 -0.253801  0.583907 -0.152488 -0.110288 -0.152488 -0.110288   \n",
       "3   -0.024879 -0.119260  0.287432 -0.106362 -0.110301 -0.106362 -0.110301   \n",
       "4   -0.075144 -0.026890 -0.208519 -0.316938  0.297288 -0.013757 -0.075144   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  0.281765 -0.186566 -0.217804 -0.169547 -0.016370 -0.169547 -0.016370   \n",
       "175  0.004327 -0.074732  0.242721 -0.116309  0.004327 -0.116309  0.004327   \n",
       "176 -0.055334 -0.124787  0.221661 -0.037692 -0.055334 -0.037692 -0.055334   \n",
       "177 -0.229561 -0.549556  1.091942 -0.129901 -0.249410 -0.121104 -0.229561   \n",
       "178 -0.227856 -0.385461  0.917953 -0.154107 -0.213162 -0.139862 -0.187336   \n",
       "\n",
       "     labels  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "174       0  \n",
       "175       0  \n",
       "176       0  \n",
       "177       0  \n",
       "178       0  \n",
       "\n",
       "[179 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "for i in e: \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(i)\n",
    "    X=pca.transform(i)\n",
    "    df = pd.DataFrame(data=X, columns=['x1', 'x2'])\n",
    "    df_new = pd.DataFrame([[df.iloc[0,0], df.iloc[0,1], \n",
    "                   df.iloc[1,0], df.iloc[1,1], \n",
    "                   df.iloc[2,0], df.iloc[2,1], \n",
    "                  df.iloc[3,0], df.iloc[3,1], \n",
    "                  df.iloc[4,0], df.iloc[4,1], \n",
    "                   df.iloc[5,0], df.iloc[5,1], \n",
    "                  df.iloc[6,0], df.iloc[6,1]]], \n",
    "                 columns = ['0x1', '0x2', '1x1', '1x2', '2x1', '2x2', '3x1', '3x2', '4x1', '4x2', '5x1', '5x3', '6x1', '6x2'])\n",
    "    df1 = pd.concat([df1, df_new])\n",
    "df1 = df1.reset_index().drop([\"index\"], axis = 1)\n",
    "labels = [1]*90 + [0]*89\n",
    "\n",
    "df1['labels'] = labels\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.sample(frac=1)\n",
    "labels = df1.labels\n",
    "df_new = df1.drop(['labels'], axis =1 )\n",
    "col = df_new.columns\n",
    "mm = MinMaxScaler()\n",
    "df_new = mm.fit_transform(df_new)\n",
    "df_new = df_new*100\n",
    "\n",
    "\n",
    "# train = df_new[0:120]\n",
    "# train_labels = np.array(labels[0:120])\n",
    "\n",
    "# test = df_new[120:]\n",
    "# test_labels = np.array(labels[120:])\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_new, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "labels = df2.labels\n",
    "df_one_feature = df2.drop(['labels'], axis =1 )\n",
    "col = df_one_feature.columns\n",
    "mm = MinMaxScaler()\n",
    "df_one_feature = mm.fit_transform(df_one_feature)\n",
    "df_one_feature = df_one_feature*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 77, 54, 31]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes-first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    return layers\n",
    "\n",
    "FindLayerNodesLinear(4, 100, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3287029/3524246904.py:16: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =  KerasClassifier(build_fn=createmodel, verbose = False)\n"
     ]
    }
   ],
   "source": [
    "def createmodel(n_layers, first_layer_nodes, activation_func, loss_func, last_layer_nodes):\n",
    "    model = Sequential()\n",
    "    print(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='sgd', loss=loss_func, metrics = [\"accuracy\"]) \n",
    "    \n",
    "    return model\n",
    "\n",
    "model =  KerasClassifier(build_fn=createmodel, verbose = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_funcs = ['relu', 'tanh'] \n",
    "loss_funcs = ['binary_crossentropy']\n",
    "param_grid = dict(n_layers=np.arange(2,7), first_layer_nodes = [100], activation_func = activation_funcs, loss_func = loss_funcs, last_layer_nodes= [40,50], batch_size = [50], epochs = [25,50,75])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 100 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa6c423a410&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [50], &#x27;epochs&#x27;: [25, 50, 75],\n",
       "                         &#x27;first_layer_nodes&#x27;: [100],\n",
       "                         &#x27;last_layer_nodes&#x27;: [40, 50],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;binary_crossentropy&#x27;],\n",
       "                         &#x27;n_layers&#x27;: array([2, 3, 4, 5, 6])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa6c423a410&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [50], &#x27;epochs&#x27;: [25, 50, 75],\n",
       "                         &#x27;first_layer_nodes&#x27;: [100],\n",
       "                         &#x27;last_layer_nodes&#x27;: [40, 50],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;binary_crossentropy&#x27;],\n",
       "                         &#x27;n_layers&#x27;: array([2, 3, 4, 5, 6])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa6c423a410&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa6c423a410&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa6c423a410>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation_func': ['relu', 'tanh'],\n",
       "                         'batch_size': [50], 'epochs': [25, 50, 75],\n",
       "                         'first_layer_nodes': [100],\n",
       "                         'last_layer_nodes': [40, 50],\n",
       "                         'loss_func': ['binary_crossentropy'],\n",
       "                         'n_layers': array([2, 3, 4, 5, 6])})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7154035568237305\n",
      "{'activation_func': 'relu', 'batch_size': 50, 'epochs': 75, 'first_layer_nodes': 100, 'last_layer_nodes': 40, 'loss_func': 'binary_crossentropy', 'n_layers': 3}\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "3 100 40\n",
      "4 100 50\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 40\n",
      "6 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "5 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "6 100 50\n",
      "5 100 50\n",
      "5 100 40\n",
      "4 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 50\n",
      "3 100 40\n",
      "6 100 40\n",
      "3 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 40\n",
      "3 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "2 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 40\n",
      "2 100 50\n",
      "4 100 50\n",
      "6 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "3 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "6 100 40\n",
      "2 100 40\n",
      "6 100 40\n",
      "2 100 40\n",
      "5 100 50\n",
      "6 100 40\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "3 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 100 50\n",
      "5 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "6 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "2 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "6 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "5 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "4 100 50\n",
      "6 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "6 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "6 100 40\n",
      "4 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 40\n",
      "3 100 40\n",
      "6 100 50\n",
      "6 100 40\n",
      "3 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "6 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 30\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "6 100 40\n",
      "3 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 50\n",
      "4 100 40\n",
      "6 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "5 100 50\n",
      "3 100 50\n",
      "5 100 40\n",
      "5 100 50\n",
      "5 100 50\n",
      "6 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "5 100 40\n",
      "4 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "6 100 50\n",
      "5 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "5 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "6 100 50\n",
      "4 100 50\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 30\n",
      "2 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "5 100 40\n",
      "2 100 40\n",
      "6 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "2 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "5 100 50\n",
      "5 100 40\n",
      "3 100 40\n",
      "5 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 40\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 40\n",
      "2 100 40\n",
      "5 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "5 100 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "5 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "6 100 40\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "5 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 50\n",
      "6 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "5 100 50\n",
      "5 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "5 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "3 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 40\n",
      "4 100 40\n",
      "2 100 50\n",
      "2 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 40\n",
      "5 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "6 100 50\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 40\n",
      "4 100 50\n",
      "4 100 40\n",
      "6 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 40\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "6 100 50\n",
      "6 100 40\n",
      "4 100 40\n",
      "6 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "5 100 50\n",
      "6 100 40\n",
      "3 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "3 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "2 100 30\n",
      "4 100 40\n",
      "3 100 40\n",
      "2 100 40\n",
      "6 100 40\n",
      "5 100 40\n",
      "2 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 100 50\n",
      "5 100 40\n",
      "6 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "2 100 30\n",
      "3 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 30\n",
      "3 100 50\n",
      "3 100 40\n",
      "3 100 30\n",
      "4 100 40\n",
      "2 100 40\n",
      "2 100 40\n",
      "4 100 40\n",
      "4 100 40\n",
      "2 100 30\n",
      "2 100 50\n",
      "3 100 40\n",
      "2 100 40\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 50\n",
      "2 100 30\n",
      "2 100 50\n",
      "4 100 30\n",
      "4 100 30\n",
      "3 100 30\n",
      "4 100 40\n",
      "4 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 100 50\n",
      "6 100 40\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 40\n",
      "4 100 50\n",
      "6 100 40\n",
      "4 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "4 100 40\n",
      "3 100 30\n",
      "3 100 40\n",
      "3 100 30\n",
      "3 100 30\n",
      "4 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "4 100 40\n",
      "4 100 30\n",
      "3 100 50\n",
      "2 100 40\n",
      "4 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "4 100 50\n",
      "4 100 50\n",
      "3 100 40\n",
      "2 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 100 50\n",
      "2 100 40\n",
      "3 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "3 100 40\n",
      "4 100 30\n",
      "2 100 30\n",
      "4 100 50\n",
      "3 100 50\n",
      "5 100 50\n",
      "4 100 50\n",
      "4 100 40\n",
      "6 100 50\n",
      "4 100 50\n",
      "5 100 40\n",
      "5 100 50\n",
      "5 100 40\n",
      "6 100 50\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(7,), activation='relu'))\n",
    "model.add(Dense(75, input_shape=(7,), activation='relu'))\n",
    "model.add(Dense(50, input_shape=(7,), activation='relu'))\n",
    "# model.add(Dense(30, input_shape=(7,), activation='tanh'))\n",
    "\n",
    "# model.add(Dense(84, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(76, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(67, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(59, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(51, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(75, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(65, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(55, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 929us/step - loss: 0.1119 - accuracy: 0.9545\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.1131 - accuracy: 0.9527\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.1136 - accuracy: 0.9551\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.0860 - accuracy: 0.9667\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 766us/step - loss: 0.0788 - accuracy: 0.9650\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.1107 - accuracy: 0.9545\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 852us/step - loss: 0.0914 - accuracy: 0.9615\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 785us/step - loss: 0.0847 - accuracy: 0.9632\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.1216 - accuracy: 0.9498\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 782us/step - loss: 0.1166 - accuracy: 0.9446\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 798us/step - loss: 0.1055 - accuracy: 0.9592\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.0733 - accuracy: 0.9720\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 842us/step - loss: 0.0665 - accuracy: 0.9720\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 786us/step - loss: 0.0863 - accuracy: 0.9627\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.0940 - accuracy: 0.9638\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 784us/step - loss: 0.1092 - accuracy: 0.9597\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.1078 - accuracy: 0.9516\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.0861 - accuracy: 0.9644\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.0853 - accuracy: 0.9632\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.1081 - accuracy: 0.9545\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.1048 - accuracy: 0.9621\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.1427 - accuracy: 0.9498\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 786us/step - loss: 0.0733 - accuracy: 0.9767\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1000 - accuracy: 0.9597\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.1060 - accuracy: 0.9580\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 788us/step - loss: 0.1123 - accuracy: 0.9551\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.0880 - accuracy: 0.9662\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 802us/step - loss: 0.0956 - accuracy: 0.9632\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.1223 - accuracy: 0.9498\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 793us/step - loss: 0.0938 - accuracy: 0.9650\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.1127 - accuracy: 0.9562\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.0616 - accuracy: 0.9755\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 811us/step - loss: 0.0643 - accuracy: 0.9714\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 816us/step - loss: 0.0808 - accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 796us/step - loss: 0.0912 - accuracy: 0.9609\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.0807 - accuracy: 0.9732\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.1070 - accuracy: 0.9539\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.0900 - accuracy: 0.9638\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.0750 - accuracy: 0.9732\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 803us/step - loss: 0.1228 - accuracy: 0.9545\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1145 - accuracy: 0.9557\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.0935 - accuracy: 0.9603\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 781us/step - loss: 0.1087 - accuracy: 0.9621\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.0958 - accuracy: 0.9632\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.0906 - accuracy: 0.9627\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 783us/step - loss: 0.0896 - accuracy: 0.9627\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 822us/step - loss: 0.1236 - accuracy: 0.9510\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 829us/step - loss: 0.1054 - accuracy: 0.9592\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.1147 - accuracy: 0.9463\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 811us/step - loss: 0.0799 - accuracy: 0.9726\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7083 - accuracy: 0.6389\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 1ms/step - loss: 0.0747 - recall_6: 0.9716\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 939us/step - loss: 0.0968 - recall_6: 0.9740\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 816us/step - loss: 0.0972 - recall_6: 0.9621\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.1177 - recall_6: 0.9538\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.1505 - recall_6: 0.9550\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.0693 - recall_6: 0.9811\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.0720 - recall_6: 0.9740\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.0880 - recall_6: 0.9669\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.0617 - recall_6: 0.9728\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.1057 - recall_6: 0.9598\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.1166 - recall_6: 0.9432\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.0733 - recall_6: 0.9633\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.1076 - recall_6: 0.9598\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.1637 - recall_6: 0.9290\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.1368 - recall_6: 0.9467\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.1222 - recall_6: 0.9598\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.0932 - recall_6: 0.9609\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.0810 - recall_6: 0.9645\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.0951 - recall_6: 0.9669\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.1179 - recall_6: 0.9574\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.1711 - recall_6: 0.9195\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.1207 - recall_6: 0.9609\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.1021 - recall_6: 0.9550\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.0806 - recall_6: 0.9728\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 766us/step - loss: 0.0990 - recall_6: 0.9621\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.0604 - recall_6: 0.9775\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.0594 - recall_6: 0.9775\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 817us/step - loss: 0.0583 - recall_6: 0.9787\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 795us/step - loss: 0.0761 - recall_6: 0.9704\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 800us/step - loss: 0.0658 - recall_6: 0.9704\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 798us/step - loss: 0.0817 - recall_6: 0.9669\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 790us/step - loss: 0.1668 - recall_6: 0.9456\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.0846 - recall_6: 0.9704\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.0752 - recall_6: 0.9728\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 794us/step - loss: 0.0833 - recall_6: 0.9704\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 790us/step - loss: 0.0922 - recall_6: 0.9669\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 788us/step - loss: 0.1283 - recall_6: 0.9527\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 785us/step - loss: 0.1292 - recall_6: 0.9456\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.1224 - recall_6: 0.9467\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.0772 - recall_6: 0.9680\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.1360 - recall_6: 0.9503\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 838us/step - loss: 0.0733 - recall_6: 0.9846\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.0809 - recall_6: 0.9763\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 772us/step - loss: 0.1093 - recall_6: 0.9657\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.0769 - recall_6: 0.9763\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.0839 - recall_6: 0.9728\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.0922 - recall_6: 0.9704\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.1007 - recall_6: 0.9633\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 772us/step - loss: 0.1112 - recall_6: 0.9645\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.1105 - recall_6: 0.9562\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7450 - recall_6: 0.7222\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 1s 1ms/step - loss: 0.0908 - auc_2: 0.9948\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 990us/step - loss: 0.0959 - auc_2: 0.9945\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.1460 - auc_2: 0.9873\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 834us/step - loss: 0.0851 - auc_2: 0.9956\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.1540 - auc_2: 0.9847\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 883us/step - loss: 0.0820 - auc_2: 0.9960\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 855us/step - loss: 0.0779 - auc_2: 0.9965\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.0694 - auc_2: 0.9970\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 808us/step - loss: 0.0709 - auc_2: 0.9966\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.1161 - auc_2: 0.9912\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 840us/step - loss: 0.0900 - auc_2: 0.9946\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.0828 - auc_2: 0.9959\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.1000 - auc_2: 0.9941\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 821us/step - loss: 0.0631 - auc_2: 0.9972\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 798us/step - loss: 0.0554 - auc_2: 0.9976\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 817us/step - loss: 0.0706 - auc_2: 0.9967\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.1511 - auc_2: 0.9857\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.0846 - auc_2: 0.9954\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.0942 - auc_2: 0.9932\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 806us/step - loss: 0.1474 - auc_2: 0.9871\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 801us/step - loss: 0.1245 - auc_2: 0.9906\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 793us/step - loss: 0.0927 - auc_2: 0.9949\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 796us/step - loss: 0.1323 - auc_2: 0.9891\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 793us/step - loss: 0.1063 - auc_2: 0.9930\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 793us/step - loss: 0.0905 - auc_2: 0.9950\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 866us/step - loss: 0.0497 - auc_2: 0.9985\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 916us/step - loss: 0.0523 - auc_2: 0.9983\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 819us/step - loss: 0.1126 - auc_2: 0.9913\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 811us/step - loss: 0.0821 - auc_2: 0.9959\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 810us/step - loss: 0.1068 - auc_2: 0.9925\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 817us/step - loss: 0.0804 - auc_2: 0.9961\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 817us/step - loss: 0.0663 - auc_2: 0.9970\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 811us/step - loss: 0.0585 - auc_2: 0.9976\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 843us/step - loss: 0.0649 - auc_2: 0.9975\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.1379 - auc_2: 0.9880\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 959us/step - loss: 0.2033 - auc_2: 0.9744\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 992us/step - loss: 0.1713 - auc_2: 0.9817\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 805us/step - loss: 0.1036 - auc_2: 0.9933\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 805us/step - loss: 0.0670 - auc_2: 0.9978\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 801us/step - loss: 0.0922 - auc_2: 0.9938\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 781us/step - loss: 0.0775 - auc_2: 0.9953\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1064 - auc_2: 0.9927\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 782us/step - loss: 0.1532 - auc_2: 0.9856\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 851us/step - loss: 0.0936 - auc_2: 0.9946\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 781us/step - loss: 0.1708 - auc_2: 0.9824\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 783us/step - loss: 0.0790 - auc_2: 0.9963\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 781us/step - loss: 0.0600 - auc_2: 0.9978\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1160 - auc_2: 0.9907\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.1024 - auc_2: 0.9918\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 788us/step - loss: 0.1832 - auc_2: 0.9783\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9573 - auc_2: 0.6497\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 815us/step - loss: 0.6386 - accuracy: 0.7509\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 782us/step - loss: 0.4829 - accuracy: 0.7602\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.5044 - accuracy: 0.7550\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.4410 - accuracy: 0.7917\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 735us/step - loss: 0.4982 - accuracy: 0.7690\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 752us/step - loss: 0.4097 - accuracy: 0.8151\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.4531 - accuracy: 0.7870\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 803us/step - loss: 0.4852 - accuracy: 0.7736\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 723us/step - loss: 0.4561 - accuracy: 0.7870\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.5124 - accuracy: 0.7503\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 722us/step - loss: 0.4635 - accuracy: 0.7730\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 692us/step - loss: 0.4393 - accuracy: 0.7952\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 705us/step - loss: 0.4629 - accuracy: 0.7771\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 752us/step - loss: 0.4246 - accuracy: 0.8022\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.4199 - accuracy: 0.8063\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.4369 - accuracy: 0.7905\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.4376 - accuracy: 0.7894\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 723us/step - loss: 0.4015 - accuracy: 0.8075\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 718us/step - loss: 0.3835 - accuracy: 0.8343\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 729us/step - loss: 0.4142 - accuracy: 0.8098\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 733us/step - loss: 0.4359 - accuracy: 0.7917\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.4554 - accuracy: 0.7625\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 734us/step - loss: 0.4896 - accuracy: 0.7515\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.4850 - accuracy: 0.7538\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 733us/step - loss: 0.5029 - accuracy: 0.7468\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.4731 - accuracy: 0.7690\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.4530 - accuracy: 0.7818\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 731us/step - loss: 0.4580 - accuracy: 0.7643\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 719us/step - loss: 0.4464 - accuracy: 0.7736\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 718us/step - loss: 0.4441 - accuracy: 0.7719\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 724us/step - loss: 0.4565 - accuracy: 0.7579\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 721us/step - loss: 0.5171 - accuracy: 0.7240\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.5346 - accuracy: 0.7135\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 732us/step - loss: 0.4922 - accuracy: 0.7509\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 735us/step - loss: 0.4880 - accuracy: 0.7550\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 735us/step - loss: 0.5438 - accuracy: 0.7188\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 733us/step - loss: 0.5062 - accuracy: 0.7445\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.4799 - accuracy: 0.7660\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 728us/step - loss: 0.5125 - accuracy: 0.7322\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 724us/step - loss: 0.4820 - accuracy: 0.7526\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 727us/step - loss: 0.4731 - accuracy: 0.7649\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 725us/step - loss: 0.4800 - accuracy: 0.7509\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.4867 - accuracy: 0.7503\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.4594 - accuracy: 0.7853\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.4699 - accuracy: 0.7596\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 736us/step - loss: 0.5139 - accuracy: 0.7293\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.4780 - accuracy: 0.7497\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.5117 - accuracy: 0.7485\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.5296 - accuracy: 0.7433\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.4686 - accuracy: 0.7649\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7455 - accuracy: 0.5833\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 920us/step - loss: 0.4739 - recall_6: 0.7590\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 862us/step - loss: 0.4550 - recall_6: 0.7432\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.4095 - recall_6: 0.7834\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.4385 - recall_6: 0.8107\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.5200 - recall_6: 0.7811\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 755us/step - loss: 0.4839 - recall_6: 0.7751\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.4733 - recall_6: 0.8178\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.5031 - recall_6: 0.7822\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.5235 - recall_6: 0.7586\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.5026 - recall_6: 0.7491\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.5102 - recall_6: 0.7574\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.5445 - recall_6: 0.7870\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 745us/step - loss: 0.5360 - recall_6: 0.7527\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.5397 - recall_6: 0.7680\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 747us/step - loss: 0.5319 - recall_6: 0.7917\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 738us/step - loss: 0.5036 - recall_6: 0.7775\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 738us/step - loss: 0.4764 - recall_6: 0.7598\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.4570 - recall_6: 0.8178\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.5024 - recall_6: 0.7799\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.4935 - recall_6: 0.7527\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.4992 - recall_6: 0.7811\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.4988 - recall_6: 0.7609\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.4716 - recall_6: 0.7953\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.4917 - recall_6: 0.7586\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.4603 - recall_6: 0.7704\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 728us/step - loss: 0.4503 - recall_6: 0.7787\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 738us/step - loss: 0.4286 - recall_6: 0.8107\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 818us/step - loss: 0.4874 - recall_6: 0.7858\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 805us/step - loss: 0.5319 - recall_6: 0.7243\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4888 - recall_6: 0.7964\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.4900 - recall_6: 0.7550\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4612 - recall_6: 0.7811\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 747us/step - loss: 0.4724 - recall_6: 0.8225\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4875 - recall_6: 0.7917\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 747us/step - loss: 0.4275 - recall_6: 0.8012\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.4402 - recall_6: 0.8000\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.4629 - recall_6: 0.8000\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.4456 - recall_6: 0.8118\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.4350 - recall_6: 0.8178\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.5511 - recall_6: 0.7266\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.4898 - recall_6: 0.7964\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 735us/step - loss: 0.4726 - recall_6: 0.7858\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 741us/step - loss: 0.4854 - recall_6: 0.7834\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.5553 - recall_6: 0.7266\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.5269 - recall_6: 0.7278\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 735us/step - loss: 0.5270 - recall_6: 0.7254\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.5224 - recall_6: 0.7396\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 732us/step - loss: 0.5072 - recall_6: 0.7893\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 740us/step - loss: 0.5118 - recall_6: 0.7716\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 737us/step - loss: 0.4944 - recall_6: 0.7751\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.7698 - recall_6: 0.7778\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 881us/step - loss: 0.4424 - auc_2: 0.8653\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 783us/step - loss: 0.4395 - auc_2: 0.8729\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.4551 - auc_2: 0.8635\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.4542 - auc_2: 0.8639\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.4259 - auc_2: 0.8808\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 789us/step - loss: 0.4717 - auc_2: 0.8467\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.4499 - auc_2: 0.8663\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 784us/step - loss: 0.4884 - auc_2: 0.8427\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.4507 - auc_2: 0.8655\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.4833 - auc_2: 0.8406\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 759us/step - loss: 0.4696 - auc_2: 0.8570\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.4404 - auc_2: 0.8785\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.4862 - auc_2: 0.8342\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.4592 - auc_2: 0.8556\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 750us/step - loss: 0.4497 - auc_2: 0.8639\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 747us/step - loss: 0.4519 - auc_2: 0.8625\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.4789 - auc_2: 0.8373\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 752us/step - loss: 0.4427 - auc_2: 0.8710\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.4293 - auc_2: 0.8821\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.4416 - auc_2: 0.8749\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4680 - auc_2: 0.8582\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 777us/step - loss: 0.4966 - auc_2: 0.8283\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.4472 - auc_2: 0.8765\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4659 - auc_2: 0.8544\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.4482 - auc_2: 0.8689\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.4406 - auc_2: 0.8736\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.4537 - auc_2: 0.8670\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.4568 - auc_2: 0.8628\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.4100 - auc_2: 0.8925\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 772us/step - loss: 0.4413 - auc_2: 0.8731\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.4806 - auc_2: 0.8401\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 786us/step - loss: 0.4241 - auc_2: 0.8823\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.4319 - auc_2: 0.8780\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.4342 - auc_2: 0.8770\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.4409 - auc_2: 0.8734\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 778us/step - loss: 0.4106 - auc_2: 0.8934\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.4506 - auc_2: 0.8613\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 795us/step - loss: 0.4809 - auc_2: 0.8429\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 785us/step - loss: 0.5319 - auc_2: 0.8000\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.4779 - auc_2: 0.8436\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.4659 - auc_2: 0.8554\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 764us/step - loss: 0.4515 - auc_2: 0.8686\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.4168 - auc_2: 0.8883\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.4352 - auc_2: 0.8781\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.4203 - auc_2: 0.8866\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 766us/step - loss: 0.4189 - auc_2: 0.8860\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.4369 - auc_2: 0.8747\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 765us/step - loss: 0.4150 - auc_2: 0.8888\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.4007 - auc_2: 0.8973\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.4102 - auc_2: 0.8925\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8329 - auc_2: 0.7114\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 864us/step - loss: 0.4620 - accuracy: 0.7649\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.4108 - accuracy: 0.7958\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.3903 - accuracy: 0.7975\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 776us/step - loss: 0.3852 - accuracy: 0.8127\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.3680 - accuracy: 0.8104\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 754us/step - loss: 0.3657 - accuracy: 0.8092\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.3593 - accuracy: 0.8232\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.3504 - accuracy: 0.8238\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.3660 - accuracy: 0.8291\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.3576 - accuracy: 0.8209\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.3589 - accuracy: 0.8279\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.3458 - accuracy: 0.8372\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.3519 - accuracy: 0.8378\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.3424 - accuracy: 0.8413\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.3445 - accuracy: 0.8477\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.3230 - accuracy: 0.8594\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.3249 - accuracy: 0.8588\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 802us/step - loss: 0.3235 - accuracy: 0.8635\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.3099 - accuracy: 0.8594\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 750us/step - loss: 0.3089 - accuracy: 0.8664\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.3123 - accuracy: 0.8646\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.3163 - accuracy: 0.8611\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 744us/step - loss: 0.3052 - accuracy: 0.8629\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 743us/step - loss: 0.3027 - accuracy: 0.8681\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 750us/step - loss: 0.3001 - accuracy: 0.8728\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.3023 - accuracy: 0.8594\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.2952 - accuracy: 0.8646\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.2960 - accuracy: 0.8751\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.2864 - accuracy: 0.8681\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.2807 - accuracy: 0.8821\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.2925 - accuracy: 0.8746\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.2772 - accuracy: 0.8781\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.2817 - accuracy: 0.8781\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 746us/step - loss: 0.2787 - accuracy: 0.8827\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.2778 - accuracy: 0.8786\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 748us/step - loss: 0.2706 - accuracy: 0.8909\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.2684 - accuracy: 0.8880\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 742us/step - loss: 0.2713 - accuracy: 0.8816\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 812us/step - loss: 0.2738 - accuracy: 0.8781\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.2836 - accuracy: 0.8693\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.2664 - accuracy: 0.8862\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.2640 - accuracy: 0.8821\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 745us/step - loss: 0.2699 - accuracy: 0.8827\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.2668 - accuracy: 0.8833\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.2628 - accuracy: 0.8821\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 775us/step - loss: 0.2557 - accuracy: 0.8926\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 803us/step - loss: 0.2500 - accuracy: 0.8973\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 745us/step - loss: 0.2595 - accuracy: 0.8903\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.2417 - accuracy: 0.8880\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.2443 - accuracy: 0.8926\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5905 - accuracy: 0.5000\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 942us/step - loss: 0.2765 - recall_6: 0.9073\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 0s 846us/step - loss: 0.2430 - recall_6: 0.9231\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.2379 - recall_6: 0.9148\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.2400 - recall_6: 0.9207\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 762us/step - loss: 0.2397 - recall_6: 0.9266\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 747us/step - loss: 0.2379 - recall_6: 0.9254\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.2386 - recall_6: 0.9290\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.2302 - recall_6: 0.9290\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.2388 - recall_6: 0.9101\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 755us/step - loss: 0.2333 - recall_6: 0.9195\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.2413 - recall_6: 0.9231\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.2368 - recall_6: 0.9136\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.2263 - recall_6: 0.9314\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 744us/step - loss: 0.2307 - recall_6: 0.9302\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 815us/step - loss: 0.2224 - recall_6: 0.9278\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.2353 - recall_6: 0.9101\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.2282 - recall_6: 0.9254\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 748us/step - loss: 0.2241 - recall_6: 0.9219\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 754us/step - loss: 0.2325 - recall_6: 0.9148\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 769us/step - loss: 0.2450 - recall_6: 0.9136\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 787us/step - loss: 0.2152 - recall_6: 0.9266\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.2317 - recall_6: 0.9219\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.2155 - recall_6: 0.9314\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 750us/step - loss: 0.2307 - recall_6: 0.9219\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.2188 - recall_6: 0.9325\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 752us/step - loss: 0.2222 - recall_6: 0.9207\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 754us/step - loss: 0.2150 - recall_6: 0.9325\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 739us/step - loss: 0.2296 - recall_6: 0.9254\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 749us/step - loss: 0.2286 - recall_6: 0.9385\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 761us/step - loss: 0.2156 - recall_6: 0.9373\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.2200 - recall_6: 0.9243\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 754us/step - loss: 0.2048 - recall_6: 0.9314\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.2125 - recall_6: 0.9290\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 756us/step - loss: 0.2086 - recall_6: 0.9396\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.2101 - recall_6: 0.9325\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 757us/step - loss: 0.2149 - recall_6: 0.9172\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 755us/step - loss: 0.2160 - recall_6: 0.9290\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 755us/step - loss: 0.2017 - recall_6: 0.9396\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 750us/step - loss: 0.2150 - recall_6: 0.9278\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 751us/step - loss: 0.2137 - recall_6: 0.9243\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.2041 - recall_6: 0.9278\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 753us/step - loss: 0.2124 - recall_6: 0.9325\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.2121 - recall_6: 0.9219\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 765us/step - loss: 0.2141 - recall_6: 0.9314\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.2034 - recall_6: 0.9349\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 770us/step - loss: 0.1993 - recall_6: 0.9349\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 763us/step - loss: 0.2045 - recall_6: 0.9266\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.2033 - recall_6: 0.9385\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 758us/step - loss: 0.1981 - recall_6: 0.9361\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 760us/step - loss: 0.2107 - recall_6: 0.9385\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7480 - recall_6: 0.6111\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 0s 949us/step - loss: 0.2169 - auc_2: 0.9676\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 848us/step - loss: 0.2014 - auc_2: 0.9747\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 0s 825us/step - loss: 0.2051 - auc_2: 0.9740\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 0s 816us/step - loss: 0.2032 - auc_2: 0.9744\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 0s 805us/step - loss: 0.1970 - auc_2: 0.9770\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.1926 - auc_2: 0.9775\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 0s 789us/step - loss: 0.2061 - auc_2: 0.9738\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 0s 803us/step - loss: 0.1965 - auc_2: 0.9766\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.1833 - auc_2: 0.9800\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.1967 - auc_2: 0.9763\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 0s 800us/step - loss: 0.1876 - auc_2: 0.9781\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 0s 814us/step - loss: 0.1950 - auc_2: 0.9770\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 0s 804us/step - loss: 0.1729 - auc_2: 0.9822\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 0s 799us/step - loss: 0.1784 - auc_2: 0.9805\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 0s 798us/step - loss: 0.1749 - auc_2: 0.9815\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 0s 798us/step - loss: 0.1819 - auc_2: 0.9799\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 0s 789us/step - loss: 0.1869 - auc_2: 0.9787\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 0s 786us/step - loss: 0.1778 - auc_2: 0.9804\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 0s 790us/step - loss: 0.1790 - auc_2: 0.9804\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1857 - auc_2: 0.9785\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 0s 798us/step - loss: 0.1738 - auc_2: 0.9815\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 0s 809us/step - loss: 0.1724 - auc_2: 0.9819\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 0s 793us/step - loss: 0.1771 - auc_2: 0.9810\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 0s 766us/step - loss: 0.1709 - auc_2: 0.9821\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 0s 772us/step - loss: 0.1674 - auc_2: 0.9826\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 0s 771us/step - loss: 0.1715 - auc_2: 0.9820\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 0s 780us/step - loss: 0.1805 - auc_2: 0.9796\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 0s 804us/step - loss: 0.1758 - auc_2: 0.9808\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 0s 928us/step - loss: 0.1748 - auc_2: 0.9808\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 0s 847us/step - loss: 0.1716 - auc_2: 0.9813\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 0s 961us/step - loss: 0.1719 - auc_2: 0.9820\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 0s 906us/step - loss: 0.1755 - auc_2: 0.9811\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 0s 774us/step - loss: 0.1653 - auc_2: 0.9830\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 0s 767us/step - loss: 0.1725 - auc_2: 0.9816\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 0s 765us/step - loss: 0.1584 - auc_2: 0.9847\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.1683 - auc_2: 0.9826\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 768us/step - loss: 0.1683 - auc_2: 0.9826\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 0s 773us/step - loss: 0.1584 - auc_2: 0.9848\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 0s 790us/step - loss: 0.1739 - auc_2: 0.9814\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 0s 785us/step - loss: 0.1589 - auc_2: 0.9848\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 0s 796us/step - loss: 0.1600 - auc_2: 0.9840\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 0s 794us/step - loss: 0.1533 - auc_2: 0.9853\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 0s 804us/step - loss: 0.1679 - auc_2: 0.9825\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 0s 791us/step - loss: 0.1668 - auc_2: 0.9833\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 0s 799us/step - loss: 0.1545 - auc_2: 0.9848\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.1592 - auc_2: 0.9843\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 779us/step - loss: 0.1601 - auc_2: 0.9842\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 792us/step - loss: 0.1608 - auc_2: 0.9843\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 0s 801us/step - loss: 0.1636 - auc_2: 0.9831\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 0s 797us/step - loss: 0.1660 - auc_2: 0.9833\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7343 - auc_2: 0.5741\n",
      "0.7454907894134521\n",
      "sgd\n",
      "accuracy\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "metrics = ['accuracy', Recall(), AUC()]\n",
    "best_loss = float('inf')\n",
    "best_optimizer = None\n",
    "best_metric = None\n",
    "# Compile the model with each optimizer and metric\n",
    "for optimizer in optimizers:\n",
    "    for metric in metrics:\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metric)\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=30)\n",
    "        val_loss, val_metric = model.evaluate(X_test, y_test)\n",
    "        \n",
    "        # Print the validation loss and metric\n",
    "#         print('Optimizer: {}, Metric: {}, Validation Loss: {:.4f}, Validation Metric: {:.4f}'.format(optimizer, metric, val_loss, val_metric))\n",
    "        if val_loss < best_loss: \n",
    "            best_loss = val_loss\n",
    "            best_optimizer = optimizer\n",
    "            best_metric = metric\n",
    "print(best_loss)\n",
    "print(best_optimizer)\n",
    "print(best_metric)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #1 -> 72)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #1 -> 72)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #1 -> 72)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #1 -> 72)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_one_feature, labels, test_size=0.2, random_state=84)\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy={1: 1000, 0: 1000})\n",
    "\n",
    "# Fit SMOTE on X and y\n",
    "smote.fit(X_train, y_train)\n",
    "\n",
    "# Generate synthetic samples\n",
    "n_synthetic_samples = 1000\n",
    "X_synthetic, y_synthetic = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Concatenate original and synthetic data\n",
    "X_train = np.concatenate((X_train, X_synthetic))\n",
    "y_train = np.concatenate((y_train, y_synthetic))\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_new, y_new, test_size=0.2, random_state=84)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.1795 - accuracy: 0.9291\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 778us/step - loss: 0.1749 - accuracy: 0.9221\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 750us/step - loss: 0.1873 - accuracy: 0.9207\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 734us/step - loss: 0.1681 - accuracy: 0.9319\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 742us/step - loss: 0.1904 - accuracy: 0.9165\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 736us/step - loss: 0.1645 - accuracy: 0.9295\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 738us/step - loss: 0.1594 - accuracy: 0.9319\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 748us/step - loss: 0.2919 - accuracy: 0.8987\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 740us/step - loss: 0.1725 - accuracy: 0.9249\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 728us/step - loss: 0.1569 - accuracy: 0.9356\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 729us/step - loss: 0.1503 - accuracy: 0.9370\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 725us/step - loss: 0.2014 - accuracy: 0.9221\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 730us/step - loss: 0.1583 - accuracy: 0.9342\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 739us/step - loss: 0.1424 - accuracy: 0.9468\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 735us/step - loss: 0.1517 - accuracy: 0.9431\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 729us/step - loss: 0.1810 - accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 725us/step - loss: 0.1547 - accuracy: 0.9323\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 734us/step - loss: 0.1409 - accuracy: 0.9351\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 737us/step - loss: 0.2004 - accuracy: 0.9113\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 730us/step - loss: 0.1555 - accuracy: 0.9272\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df_new, labels, test_size=0.2, random_state=84)\n",
    "\n",
    "h = model.fit(\n",
    "  X_train, # training data\n",
    "  y_train, # training targets\n",
    "  epochs=20,\n",
    "  batch_size=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report the training accuracy at that 5th epoch \n",
    "#Look at preciosn & recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 552us/step\n",
      "Accuracy is: 90.85394307046198\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_train)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "Accuracy is: 58.333333333333336\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3287029/921476724.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(col, rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "\n",
    "# print feature importances\n",
    "fig, ax = plt.subplots()\n",
    "col = ['0_x1', '1_x1', '2_x1', '3_x1', '4_x1', '5_x1', '6_x1']\n",
    "ax.bar(col, result.importances_mean)\n",
    "ax.set_xticklabels(col, rotation=90)\n",
    "ax.set_title('Feature Importances from Permutation Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(rounded, y_test)\n",
    "labels = ['Diseased', 'Healthy']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "#Plot accuracy on same plt\n",
    "#Downward trend for loss, and upward trend for the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    72\n",
      "0    71\n",
      "Name: labels, dtype: int64\n",
      "0    18\n",
      "1    18\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2143, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sana-env",
   "language": "python",
   "name": "sana-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
