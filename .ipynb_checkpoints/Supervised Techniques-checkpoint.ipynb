{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 15:07:56.520567: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 15:07:57.051361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 15:07:57.051403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-12 15:07:57.051407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sgt import SGT\n",
    "import os \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.metrics import binary_accuracy, Precision, Recall, AUC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Corpus\n",
    "path = '../TOP_CON/Healthy/'\n",
    "folder_names = os.listdir(path)\n",
    "\n",
    "def load_files(folder_names, path):\n",
    "    l = []\n",
    "    for folder in folder_names: \n",
    "        p = path + folder + '/'\n",
    "        p_os = os.listdir(p)\n",
    "        for filename in p_os:\n",
    "            if filename!='.ipynb_checkpoints': \n",
    "                new_path = p + filename \n",
    "                x = pd.read_csv(new_path)\n",
    "                l.append(x)\n",
    "    return l\n",
    "corpus_healthy = load_files(folder_names, path)\n",
    "\n",
    "path = '../TOP_CON/Glaucoma/'\n",
    "folder_names = os.listdir(path)\n",
    "\n",
    "corpus_diseased = load_files(folder_names, path)\n",
    "\n",
    "\n",
    "for i in corpus_diseased:\n",
    "    i['fixation_id_new'] = i['fixation_id'] - i.iloc[0,2] + 1\n",
    "\n",
    "for i in corpus_healthy:\n",
    "    i['fixation_id_new'] = i['fixation_id'] - i.iloc[0,2] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encode(x,y):\n",
    "    arr = []\n",
    "    for i,j in zip(x,y):\n",
    "        if 0<i and 0.6 > i and 0<j and 0.6 > j: \n",
    "            arr.append('A')\n",
    "        elif 0<i and 0.25 > i and 0.6<j and 1 > j: \n",
    "            arr.append('B')\n",
    "        elif 0.25<i and 0.48 > i and 0.6<j and 1 > j: \n",
    "            arr.append('C')\n",
    "        elif 0.48<i and 0.6 > i and 0.6<j and 1 > j: \n",
    "            arr.append('D')\n",
    "        elif 0.6<i and 1 > i and 0<j and 0.6 > j: \n",
    "            arr.append('E')\n",
    "        elif 0.6<i and 0.77 > i and 0.6<j and 1 > j: \n",
    "            arr.append('F')\n",
    "        elif 0.77<i and 1 > i and 0.6<j and 1 > j: \n",
    "            arr.append('G')\n",
    "        else: \n",
    "            arr.append('error')\n",
    "\n",
    "    return arr\n",
    "    \n",
    "def make_corpus(corpus_new):\n",
    "    A = np.array(corpus_new.fixation_id_new[corpus_new.letters=='A'])\n",
    "    B = np.array(corpus_new.fixation_id_new[corpus_new.letters=='B'])\n",
    "    C = np.array(corpus_new.fixation_id_new[corpus_new.letters=='C'])\n",
    "    D = np.array(corpus_new.fixation_id_new[corpus_new.letters=='D'])\n",
    "    E = np.array(corpus_new.fixation_id_new[corpus_new.letters=='E'])\n",
    "    F = np.array(corpus_new.fixation_id_new[corpus_new.letters=='F'])\n",
    "    G = np.array(corpus_new.fixation_id_new[corpus_new.letters=='G'])\n",
    "    corpus = pd.DataFrame([[1, A], \n",
    "                           [2, B],\n",
    "                           [3, C], \n",
    "                           [4, D], \n",
    "                           [5, E], \n",
    "                           [6, F],\n",
    "                           [7, G]], columns=['id', 'sequence'])\n",
    "    return corpus\n",
    "\n",
    "l = []\n",
    "for i in corpus_healthy: \n",
    "    arr = cat_encode(i.norm_pos_x, i.norm_pos_y)\n",
    "    \n",
    "    i['letters'] = arr\n",
    "    i_new = i[['letters', 'fixation_id_new']]\n",
    "    i_new = make_corpus(i_new)\n",
    "    l.append(i_new)\n",
    "    \n",
    "for i in corpus_diseased: \n",
    "    arr = cat_encode(i.norm_pos_x, i.norm_pos_y)\n",
    "    i['letters'] = arr\n",
    "    i_new = i[['letters', 'fixation_id_new']]\n",
    "    i_new = make_corpus(i_new)\n",
    "    l.append(i_new)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 31 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "179\n",
      "       (1, 1)    (1, 2)    (1, 3)    (1, 4)    (1, 5)        (1, 6)  \\\n",
      "id                                                                    \n",
      "1.0  0.367879  0.126073  0.004864  0.000115  0.000006  3.889671e-07   \n",
      "2.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "3.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "4.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "5.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "6.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "7.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
      "\n",
      "           (1, 7)        (1, 8)        (1, 9)       (1, 11)  ...  (16, 5)  \\\n",
      "id                                                           ...            \n",
      "1.0  3.856611e-08  1.920094e-09  9.559584e-11  3.687803e-12  ...      0.0   \n",
      "2.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "3.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "4.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "5.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "6.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "7.0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...      0.0   \n",
      "\n",
      "     (16, 6)  (16, 7)  (16, 8)  (16, 9)  (16, 11)  (16, 13)  (16, 14)  \\\n",
      "id                                                                      \n",
      "1.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "2.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "3.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "4.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "5.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "6.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "7.0      0.0      0.0      0.0      0.0       0.0       0.0       0.0   \n",
      "\n",
      "     (16, 15)  (16, 16)  \n",
      "id                       \n",
      "1.0       0.0  0.290365  \n",
      "2.0       0.0  0.000000  \n",
      "3.0       0.0  0.000000  \n",
      "4.0       0.0  0.000000  \n",
      "5.0       0.0  0.000000  \n",
      "6.0       0.0  0.000000  \n",
      "7.0       0.0  0.000000  \n",
      "\n",
      "[7 rows x 196 columns]\n"
     ]
    }
   ],
   "source": [
    "e = []\n",
    "for i in l: \n",
    "    sgt_ = SGT(kappa=1, \n",
    "               lengthsensitive=False, \n",
    "               mode='multiprocessing')\n",
    "    sgtembedding_df = sgt_.fit_transform(i)\n",
    "    sgtembedding_df = sgtembedding_df.set_index('id')\n",
    "    e.append(sgtembedding_df)\n",
    "    \n",
    "\n",
    "print(len(e))\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0x1</th>\n",
       "      <th>1x1</th>\n",
       "      <th>2x1</th>\n",
       "      <th>3x1</th>\n",
       "      <th>4x1</th>\n",
       "      <th>5x1</th>\n",
       "      <th>6x1</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958814</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.171003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492505</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.109084</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.040909</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.177155</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583557</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.119260</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398856</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.026890</td>\n",
       "      <td>-0.316938</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.054057</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.189305</td>\n",
       "      <td>-0.186566</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.687810</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.147840</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.074732</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.313248</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.124787</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.261763</td>\n",
       "      <td>-0.157908</td>\n",
       "      <td>-0.182191</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.549556</td>\n",
       "      <td>-0.129901</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.099188</td>\n",
       "      <td>-0.176525</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>-0.385461</td>\n",
       "      <td>-0.154107</td>\n",
       "      <td>-0.139862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0x1       1x1       2x1       3x1       4x1       5x1       6x1  \\\n",
       "0    0.958814 -0.157562 -0.157562 -0.157562 -0.157562 -0.157562 -0.171003   \n",
       "1    0.492505 -0.076684 -0.076684 -0.076684 -0.076684 -0.109084 -0.076684   \n",
       "2    1.040909 -0.152488 -0.152488 -0.177155 -0.253801 -0.152488 -0.152488   \n",
       "3    0.583557 -0.083858 -0.083858 -0.083858 -0.119260 -0.106362 -0.106362   \n",
       "4    0.398856 -0.013757 -0.013757 -0.013757 -0.026890 -0.316938 -0.013757   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  1.054057 -0.169547 -0.169547 -0.189305 -0.186566 -0.169547 -0.169547   \n",
       "175  0.687810 -0.116309 -0.147840 -0.116309 -0.074732 -0.116309 -0.116309   \n",
       "176  0.313248 -0.037692 -0.037692 -0.037692 -0.124787 -0.037692 -0.037692   \n",
       "177  1.261763 -0.157908 -0.182191 -0.121104 -0.549556 -0.129901 -0.121104   \n",
       "178  1.099188 -0.176525 -0.081416 -0.161817 -0.385461 -0.154107 -0.139862   \n",
       "\n",
       "     labels  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "174       0  \n",
       "175       0  \n",
       "176       0  \n",
       "177       0  \n",
       "178       0  \n",
       "\n",
       "[179 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "for i in e: \n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(i)\n",
    "    X=pca.transform(i)\n",
    "    df = pd.DataFrame(data=X, columns=['x1'])\n",
    "    df_new = pd.DataFrame([[df.iloc[0,0], \n",
    "                   df.iloc[1,0], \n",
    "                   df.iloc[2,0], \n",
    "                  df.iloc[3,0],\n",
    "                  df.iloc[4,0], \n",
    "                   df.iloc[5,0],\n",
    "                  df.iloc[6,0]]], \n",
    "                 columns = ['0x1', '1x1', '2x1',  '3x1',  '4x1', '5x1',  '6x1'])\n",
    "    df2 = pd.concat([df2, df_new])\n",
    "df2 = df2.reset_index().drop([\"index\"], axis = 1)\n",
    "labels = [1]*90 + [0]*89\n",
    "\n",
    "df2['labels'] = labels\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0x1</th>\n",
       "      <th>0x2</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>2x1</th>\n",
       "      <th>2x2</th>\n",
       "      <th>3x1</th>\n",
       "      <th>3x2</th>\n",
       "      <th>4x1</th>\n",
       "      <th>4x2</th>\n",
       "      <th>5x1</th>\n",
       "      <th>5x3</th>\n",
       "      <th>6x1</th>\n",
       "      <th>6x2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958814</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.157562</td>\n",
       "      <td>-0.048826</td>\n",
       "      <td>-0.171003</td>\n",
       "      <td>0.241227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.492505</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>-0.109084</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>-0.076684</td>\n",
       "      <td>-0.050352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.040909</td>\n",
       "      <td>0.045676</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.177155</td>\n",
       "      <td>-0.188429</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>0.583907</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>-0.152488</td>\n",
       "      <td>-0.110288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583557</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.024879</td>\n",
       "      <td>-0.119260</td>\n",
       "      <td>0.287432</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>-0.106362</td>\n",
       "      <td>-0.110301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.398856</td>\n",
       "      <td>0.211806</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>-0.026890</td>\n",
       "      <td>-0.208519</td>\n",
       "      <td>-0.316938</td>\n",
       "      <td>0.297288</td>\n",
       "      <td>-0.013757</td>\n",
       "      <td>-0.075144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.054057</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.189305</td>\n",
       "      <td>0.281765</td>\n",
       "      <td>-0.186566</td>\n",
       "      <td>-0.217804</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.169547</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.687810</td>\n",
       "      <td>-0.021888</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.147840</td>\n",
       "      <td>-0.238143</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.074732</td>\n",
       "      <td>0.242721</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.116309</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.313248</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.124787</td>\n",
       "      <td>0.221661</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>-0.055334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.261763</td>\n",
       "      <td>0.311580</td>\n",
       "      <td>-0.157908</td>\n",
       "      <td>-0.316158</td>\n",
       "      <td>-0.182191</td>\n",
       "      <td>-0.378833</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.229561</td>\n",
       "      <td>-0.549556</td>\n",
       "      <td>1.091942</td>\n",
       "      <td>-0.129901</td>\n",
       "      <td>-0.249410</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.229561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.099188</td>\n",
       "      <td>0.177750</td>\n",
       "      <td>-0.176525</td>\n",
       "      <td>-0.257409</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>-0.209941</td>\n",
       "      <td>-0.161817</td>\n",
       "      <td>-0.227856</td>\n",
       "      <td>-0.385461</td>\n",
       "      <td>0.917953</td>\n",
       "      <td>-0.154107</td>\n",
       "      <td>-0.213162</td>\n",
       "      <td>-0.139862</td>\n",
       "      <td>-0.187336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0x1       0x2       1x1       1x2       2x1       2x2       3x1  \\\n",
       "0    0.958814  0.002904 -0.157562 -0.048826 -0.157562 -0.048826 -0.157562   \n",
       "1    0.492505  0.013559 -0.076684 -0.050352 -0.076684 -0.050352 -0.076684   \n",
       "2    1.040909  0.045676 -0.152488 -0.110288 -0.152488 -0.110288 -0.177155   \n",
       "3    0.583557  0.007808 -0.083858 -0.024879 -0.083858 -0.024879 -0.083858   \n",
       "4    0.398856  0.211806 -0.013757 -0.075144 -0.013757 -0.075144 -0.013757   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  1.054057  0.001520 -0.169547 -0.016370 -0.169547 -0.016370 -0.189305   \n",
       "175  0.687810 -0.021888 -0.116309  0.004327 -0.147840 -0.238143 -0.116309   \n",
       "176  0.313248  0.055010 -0.037692 -0.055334 -0.037692 -0.055334 -0.037692   \n",
       "177  1.261763  0.311580 -0.157908 -0.316158 -0.182191 -0.378833 -0.121104   \n",
       "178  1.099188  0.177750 -0.176525 -0.257409 -0.081416 -0.209941 -0.161817   \n",
       "\n",
       "          3x2       4x1       4x2       5x1       5x3       6x1       6x2  \\\n",
       "0   -0.048826 -0.157562 -0.048826 -0.157562 -0.048826 -0.171003  0.241227   \n",
       "1   -0.050352 -0.076684 -0.050352 -0.109084  0.238200 -0.076684 -0.050352   \n",
       "2   -0.188429 -0.253801  0.583907 -0.152488 -0.110288 -0.152488 -0.110288   \n",
       "3   -0.024879 -0.119260  0.287432 -0.106362 -0.110301 -0.106362 -0.110301   \n",
       "4   -0.075144 -0.026890 -0.208519 -0.316938  0.297288 -0.013757 -0.075144   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "174  0.281765 -0.186566 -0.217804 -0.169547 -0.016370 -0.169547 -0.016370   \n",
       "175  0.004327 -0.074732  0.242721 -0.116309  0.004327 -0.116309  0.004327   \n",
       "176 -0.055334 -0.124787  0.221661 -0.037692 -0.055334 -0.037692 -0.055334   \n",
       "177 -0.229561 -0.549556  1.091942 -0.129901 -0.249410 -0.121104 -0.229561   \n",
       "178 -0.227856 -0.385461  0.917953 -0.154107 -0.213162 -0.139862 -0.187336   \n",
       "\n",
       "     labels  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "174       0  \n",
       "175       0  \n",
       "176       0  \n",
       "177       0  \n",
       "178       0  \n",
       "\n",
       "[179 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "for i in e: \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(i)\n",
    "    X=pca.transform(i)\n",
    "    df = pd.DataFrame(data=X, columns=['x1', 'x2'])\n",
    "    df_new = pd.DataFrame([[df.iloc[0,0], df.iloc[0,1], \n",
    "                   df.iloc[1,0], df.iloc[1,1], \n",
    "                   df.iloc[2,0], df.iloc[2,1], \n",
    "                  df.iloc[3,0], df.iloc[3,1], \n",
    "                  df.iloc[4,0], df.iloc[4,1], \n",
    "                   df.iloc[5,0], df.iloc[5,1], \n",
    "                  df.iloc[6,0], df.iloc[6,1]]], \n",
    "                 columns = ['0x1', '0x2', '1x1', '1x2', '2x1', '2x2', '3x1', '3x2', '4x1', '4x2', '5x1', '5x2', '6x1', '6x2'])\n",
    "    df1 = pd.concat([df1, df_new])\n",
    "df1 = df1.reset_index().drop([\"index\"], axis = 1)\n",
    "labels = [1]*90 + [0]*89\n",
    "\n",
    "df1['labels'] = labels\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.sample(frac=1)\n",
    "labels = df1.labels\n",
    "df_new = df1.drop(['labels'], axis =1 )\n",
    "col = df_new.columns\n",
    "mm = MinMaxScaler()\n",
    "df_new = mm.fit_transform(df_new)\n",
    "df_new = df_new*100\n",
    "\n",
    "\n",
    "# train = df_new[0:120]\n",
    "# train_labels = np.array(labels[0:120])\n",
    "\n",
    "# test = df_new[120:]\n",
    "# test_labels = np.array(labels[120:])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 92, 84, 76, 67, 59, 51]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes-first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    return layers\n",
    "\n",
    "FindLayerNodesLinear(7, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2789350/3524246904.py:16: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =  KerasClassifier(build_fn=createmodel, verbose = False)\n"
     ]
    }
   ],
   "source": [
    "def createmodel(n_layers, first_layer_nodes, activation_func, loss_func, last_layer_nodes):\n",
    "    model = Sequential()\n",
    "    print(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='sgd', loss=loss_func, metrics = [\"accuracy\"]) \n",
    "    \n",
    "    return model\n",
    "\n",
    "model =  KerasClassifier(build_fn=createmodel, verbose = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_funcs = ['relu', 'tanh'] \n",
    "loss_funcs = ['binary_crossentropy']\n",
    "param_grid = dict(n_layers=np.arange(2,10), first_layer_nodes = [50,100,150,200],activation_func = activation_funcs, loss_func = loss_funcs, last_layer_nodes= [30,40,50], batch_size = [30,40,50], epochs = [50,100,150])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:40.782333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.387909: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.437501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.446531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.448884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.452334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:41.452545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:41.452598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:41.456990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.464463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.469763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.471542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.481133: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.494820: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.499039: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.504606: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.535759: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.569790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.606277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.615678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.626841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.633373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.641181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.719231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.734067: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:41.823691: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.864926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.865338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.881784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.883411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:41.954059: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.040669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.139310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.187575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.303228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.345015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.345083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.345089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.351508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.351657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.351688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.367520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.367670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.367699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.400313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.400454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.400483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.402134: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.402284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.402322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.402959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:42.403342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:42.422458: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.422598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.422627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.445592: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.445697: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:42.445991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:42.447316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.447437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.447459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.467691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.467847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.467873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.471421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.471503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.471513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:42.526627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.526694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.526700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.558743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.558812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.558819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.561658: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.561803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.561833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.598467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.598536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.598545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.618575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.618804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.618863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.626056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.626128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.626136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.704647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.704699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.704705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.798448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.798810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.798840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.926342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.926623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.926705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:42.978791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.978863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:42.978870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.052883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.062625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.062828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.076812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.076937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.076962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.226064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.226323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.226407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:43.300653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.301258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.324786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.325140: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.329101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.345314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.345691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.346613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.346634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.347072: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.347159: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.347452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.357826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.358186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.361621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.366963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.380371: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.380484: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.380809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.381623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.381687: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.381972: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.392130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.392412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.392497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.398860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.398958: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.399259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.415579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.415828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.415893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.417259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.417564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.419880: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.420083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.420133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.423075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.423168: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.423473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.428815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.438598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.438690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.456145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.456263: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.456531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.473203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.473354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.473382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.484095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.484482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:43.532505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.533232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.541364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.541487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.541511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.557164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.557276: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.557555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.578312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.578438: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.578710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.610875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.611428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.615817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.616274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.637165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.637477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.647474: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.647640: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.647944: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.667742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.667776: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.668030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.681613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.682517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.684927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.685019: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.685334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.691680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.691836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.691876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:43.719549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.720099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.728348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.728960: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:43.735476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.735780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.750316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.750444: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.750718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.774989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.775301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.775330: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.775423: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.775704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.800012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.800214: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.800567: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.806925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.807525: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:43.809763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.809864: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.810141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.833915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.833945: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.834186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.848223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.848394: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:43.848712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:43.965738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.965813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:43.965821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:45:44.184443: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.189453: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.197822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.198250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.274212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.276237: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.276739: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.330962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.338460: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.338937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.339014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.339315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:44.394912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.397902: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.398346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.445039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.445374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.510621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.510812: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.511183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.516874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.517271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.550214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.550388: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.550703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.609319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.610354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.635532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.635919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.663117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.663314: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.663653: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.673032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.673115: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.673361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.678648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.679161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.687991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.692029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.692334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.702950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.774197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.774259: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.774537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.786024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.786052: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.786298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.788256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.788562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.797019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:44.797438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:45:44.826288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.837372: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.837464: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.837596: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.837730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.838023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:44.856921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:44.857109: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:44.857453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:45.095724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:45.096514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:45.165382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:45.174453: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:45.174917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:45:45.858231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:45.859068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:45:45.935334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:45:45.935421: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:45:45.935669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fddf032c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd4a0e24af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2878280b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f15a841cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f50e0ae4dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4e302d4ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fddf032dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f11f47c52d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff3e0515120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9c00198a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdfd0568d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc2ff0acdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd0487f0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3c0830cd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f78041e8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc5e4434c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7c100c8c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6f9c740c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff02c1f4ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd4a0e267a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1240a60dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd5383589d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f33782281f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2878282440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f00c9da8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f05d07a8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f50e0ae68c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f06100a8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd8a8440550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4e302d6c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa9c82dce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd480440670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdfd0569d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f24580dcdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f15a841e4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9c0019a710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f78041ea710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff3e0515480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9904c0af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f12282bc8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc2ff0ac1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc5e4436b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6b3c368c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f11f47c64d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd0487f0d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd724751240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd538359ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1240a629e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6f9c741d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7c100ca320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3c0830e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f00c9daab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff02c1f6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f05d07aac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f33782292d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f12282bc550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f24580de710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd8a8441900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9904c15a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f06100aab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa9c82de7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6b3c36a710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd480442b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd724752b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "4 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "3 100 40\n",
      "6 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "3 150 30\n",
      "8 150 30\n",
      "9 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "3 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "8 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "3 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "8 200 50\n",
      "7 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "4 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "6 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "7 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "6 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "5 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "7 50 40\n",
      "2 100 30\n",
      "2 100 40\n",
      "5 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "2 200 40\n",
      "9 200 40\n",
      "9 200 50\n",
      "7 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "8 150 50\n",
      "6 200 30\n",
      "2 200 50\n",
      "7 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 30\n",
      "8 50 30\n",
      "9 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "6 50 40\n",
      "2 100 30\n",
      "7 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "6 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "2 200 40\n",
      "7 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "2 50 40\n",
      "7 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "6 150 40\n",
      "7 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "8 200 50\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "6 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "9 100 30\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "7 150 50\n",
      "7 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "6 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "5 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "9 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:52:48.894199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:52:50.086694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:50.088345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:50.088542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:52:50.088973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:52:51.474818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:52:51.475126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:52:51.532592: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:51.535990: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:52:51.536405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:52:51.611610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:51.611732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:51.611759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:52:52.509658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:52:52.510184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:52:52.548781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:52:52.548882: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:52:52.549135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 30\n",
      "8 50 30\n",
      "8 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "5 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "5 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "5 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 50 30\n",
      "6 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "9 200 30\n",
      "2 200 50\n",
      "6 200 50\n",
      "4 50 30\n",
      "9 50 30\n",
      "3 50 50\n",
      "7 50 50\n",
      "9 100 30\n",
      "9 100 40\n",
      "2 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "2 200 50\n",
      "6 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "5 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "7 200 50\n",
      "4 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "2 200 40\n",
      "4 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "9 200 40\n",
      "2 50 30\n",
      "6 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "6 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "6 200 50\n",
      "4 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "7 100 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:00.450370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:01.430047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:01.430534: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:01.430599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd488144dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:03.229401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:03.229638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:03.290188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:03.290266: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:03.290546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5e8434dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd488146680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5e84368c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "3 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "3 150 50\n",
      "9 150 50\n",
      "2 200 40\n",
      "4 200 40\n",
      "9 200 40\n",
      "8 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "3 100 50\n",
      "7 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "4 150 50\n",
      "8 150 50\n",
      "3 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "6 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "9 50 40\n",
      "7 50 50\n",
      "8 100 30\n",
      "8 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "3 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "8 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "8 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "6 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "7 200 50\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "5 100 50\n",
      "2 150 30\n",
      "8 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "6 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "4 150 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:09.206762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "2 150 30\n",
      "8 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "2 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "3 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 150 30\n",
      "8 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "8 200 40\n",
      "2 50 30\n",
      "5 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "9 100 40\n",
      "7 100 50\n",
      "7 150 30\n",
      "7 150 40\n",
      "2 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "3 100 40\n",
      "6 100 40\n",
      "7 100 50\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "4 200 40\n",
      "8 200 40\n",
      "5 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "9 50 40\n",
      "5 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "7 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "6 50 30\n",
      "8 50 40\n",
      "9 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "6 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "9 200 50\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "9 150 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:10.352649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:10.353129: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:10.353184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "9 50 50\n",
      "2 100 40\n",
      "6 100 40\n",
      "5 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "9 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "9 200 30\n",
      "6 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "2 100 30\n",
      "6 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "5 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "8 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "8 200 50\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "2 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "3 150 50\n",
      "9 150 50\n",
      "2 200 40\n",
      "3 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "5 50 40\n",
      "7 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "7 150 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:11.468594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:11.819162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:11.819943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:11.904456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:11.907774: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:11.908515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50 30\n",
      "3 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "3 50 30\n",
      "8 50 30\n",
      "7 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "9 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "6 100 40\n",
      "2 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "9 200 30\n",
      "3 200 50\n",
      "9 200 50\n",
      "6 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "9 150 30\n",
      "9 150 40\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "3 200 50\n",
      "2 50 30\n",
      "6 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "6 100 50\n",
      "7 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "9 50 30\n",
      "3 50 50\n",
      "8 50 50\n",
      "8 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "8 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "7 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "5 200 50\n",
      "2 50 30\n",
      "5 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "5 150 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:12.702924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:12.703415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:12.703476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:12.982684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "6 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "6 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "8 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "7 150 30\n",
      "3 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "7 200 30\n",
      "3 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "2 50 40\n",
      "5 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "3 150 40\n",
      "7 150 40\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "8 200 50\n",
      "9 50 30\n",
      "9 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "5 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "8 100 30\n",
      "2 100 50\n",
      "5 100 50\n",
      "7 150 30\n",
      "7 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "7 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "9 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "9 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "6 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "9 50 40\n",
      "7 50 50\n",
      "9 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "6 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "2 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "8 50 30\n",
      "4 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "3 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "3 150 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:13.736027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:14.022936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:14.023245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:14.078424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:14.078522: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:14.078794: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f302c714a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:14.309516: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:14.309719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:14.309746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:14.927054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:15.127743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:15.136449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:15.136535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:15.296906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:15.297309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:15.352748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:15.352823: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:15.353065: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:15.811492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:15.811910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:15.811949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "9 100 40\n",
      "7 100 50\n",
      "9 150 30\n",
      "2 150 50\n",
      "7 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "9 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "8 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "7 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "2 150 30\n",
      "5 150 30\n",
      "2 150 40\n",
      "8 150 40\n",
      "8 150 50\n",
      "2 200 40\n",
      "5 200 40\n",
      "4 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "6 100 50\n",
      "8 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "2 200 40\n",
      "5 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "7 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "9 200 30\n",
      "7 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "7 150 40\n",
      "7 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "3 200 30\n",
      "9 200 30\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "6 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "7 50 50\n",
      "8 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "9 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "7 150 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f302c715cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:16.337410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:16.337646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:16.464128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:16.470452: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:16.470953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "9 200 50\n",
      "8 50 30\n",
      "7 50 40\n",
      "8 50 50\n",
      "9 100 30\n",
      "3 100 50\n",
      "6 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "9 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "9 50 40\n",
      "9 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "7 150 30\n",
      "5 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "4 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "6 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "2 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "3 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "7 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "7 100 50\n",
      "4 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "9 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "8 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "2 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:17.694379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:17.741449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:17.741972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:17.817846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:17.818295: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:17.818676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 30\n",
      "2 50 40\n",
      "8 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "9 150 50\n",
      "9 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "3 200 50\n",
      "6 200 50\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "9 100 30\n",
      "2 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "5 150 40\n",
      "3 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "6 150 40\n",
      "6 150 50\n",
      "8 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "9 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "3 50 30\n",
      "6 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "3 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "8 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "5 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "3 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "4 150 50\n",
      "9 150 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:18.868928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:18.868983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:18.868989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:19.098473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50 30\n",
      "8 50 30\n",
      "3 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "3 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "8 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "2 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "4 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "2 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "8 50 50\n",
      "2 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "7 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "9 100 40\n",
      "6 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "3 100 50\n",
      "8 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "6 200 30\n",
      "6 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "7 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "2 50 30\n",
      "6 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "8 100 50\n",
      "4 150 30\n",
      "8 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "6 150 50\n",
      "3 200 30\n",
      "6 200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:20.131117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:20.131917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:20.155808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:20.159374: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:20.159425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:20.179373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:20.179460: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:20.179706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:20.253334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "2 200 40\n",
      "7 200 40\n",
      "3 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "2 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "6 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "9 150 30\n",
      "5 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "6 200 40\n",
      "8 200 50\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "9 100 50\n",
      "3 150 40\n",
      "9 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "5 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "6 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "7 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "5 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "3 50 50\n",
      "3 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "2 150 50\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "2 50 50\n",
      "9 50 50\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "9 200 30\n",
      "9 200 40\n",
      "2 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "8 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "9 150 30\n",
      "8 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "9 200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:21.260116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:21.391269: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:21.391391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:21.391415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:21.496568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:21.496878: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:21.539706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:21.539917: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:21.540282: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 50 30\n",
      "2 50 40\n",
      "4 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "2 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "9 200 50\n",
      "9 50 30\n",
      "8 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "6 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "8 200 30\n",
      "2 200 50\n",
      "5 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "9 50 40\n",
      "8 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "6 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "8 50 30\n",
      "4 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "8 150 50\n",
      "9 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "7 100 30\n",
      "7 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "8 150 50\n",
      "8 200 30\n",
      "7 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "2 100 40\n",
      "7 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "4 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "5 200 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:22.437030: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:22.437299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:22.437305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:22.463700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:22.587934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:22.588497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:22.642545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:22.642875: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:22.643182: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "9 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "3 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "3 200 40\n",
      "7 200 40\n",
      "9 200 50\n",
      "3 50 40\n",
      "8 50 40\n",
      "7 50 50\n",
      "3 100 40\n",
      "8 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "7 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "8 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "7 50 30\n",
      "4 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "6 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "2 100 30\n",
      "5 100 30\n",
      "2 100 40\n",
      "2 100 50\n",
      "3 150 30\n",
      "7 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "8 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "8 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "8 150 50\n",
      "9 200 30\n",
      "4 200 50\n",
      "8 200 50\n",
      "7 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "9 200 30\n",
      "7 200 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:23.238430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:23.238869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:23.238922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fca19f349d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "7 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "6 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "6 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "8 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "9 200 40\n",
      "3 50 30\n",
      "8 50 30\n",
      "9 50 40\n",
      "7 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "6 100 50\n",
      "5 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "6 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "8 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "2 200 40\n",
      "4 200 40\n",
      "2 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "8 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "6 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "7 200 30\n",
      "4 200 40\n",
      "8 200 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:23.831085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:23.831491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:23.874274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:23.874389: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:23.874681: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:23.990325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:24.354131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:24.354968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:24.394359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:24.394409: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:24.394875: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "6 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "9 150 40\n",
      "3 200 30\n",
      "7 200 30\n",
      "8 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "7 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "3 200 40\n",
      "8 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "7 50 50\n",
      "8 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "3 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "6 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "3 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "2 100 50\n",
      "5 100 50\n",
      "3 150 30\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "8 150 50\n",
      "4 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "9 200 50\n",
      "2 50 40\n",
      "9 50 40\n",
      "7 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "8 200 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:24.778772: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:25.133213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:25.133663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:25.133722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "7 50 50\n",
      "7 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "6 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "8 200 30\n",
      "7 200 40\n",
      "8 200 50\n",
      "5 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "5 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "8 150 30\n",
      "9 150 40\n",
      "7 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "8 150 30\n",
      "2 150 50\n",
      "5 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "9 200 50\n",
      "9 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "8 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "5 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "2 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "8 200 30\n",
      "9 200 40\n",
      "3 50 30\n",
      "7 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "3 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "6 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "8 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "8 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "2 50 30\n",
      "6 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "7 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "5 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fca19f36050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:25.950700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:26.202989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:26.203177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:26.203185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:26.245824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:26.246075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:26.302239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:26.307433: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:26.307839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:26.431533: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "3 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "5 50 30\n",
      "9 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "7 200 30\n",
      "8 200 40\n",
      "2 50 30\n",
      "8 50 30\n",
      "2 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "4 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "6 50 30\n",
      "2 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "7 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "7 50 30\n",
      "8 50 40\n",
      "6 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "9 100 50\n",
      "9 150 30\n",
      "2 150 50\n",
      "4 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "8 200 50\n",
      "5 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "9 100 50\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "7 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5c742312d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:26.868137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:26.868375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:26.868444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:27.286562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:27.287197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:27.350703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:27.356190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:27.356372: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:27.356693: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:27.449890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:27.449976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:27.449984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 30\n",
      "9 50 30\n",
      "9 50 40\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "8 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "8 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "9 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "8 50 30\n",
      "6 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "6 150 40\n",
      "9 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "4 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "8 100 30\n",
      "8 100 40\n",
      "6 100 50\n",
      "7 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "8 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "2 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "7 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "9 200 50\n",
      "8 50 30\n",
      "2 50 50\n",
      "6 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "3 100 50\n",
      "9 100 50\n",
      "8 150 30\n",
      "9 150 40\n",
      "6 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "9 50 30\n",
      "7 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "2 150 40\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "7 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa58c930a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5490254ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:27.936101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:27.936793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:28.061454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:28.061550: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:28.061803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:28.402718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:28.553124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:28.553375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:28.553451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:28.555112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:28.555589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "8 200 30\n",
      "8 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "2 50 30\n",
      "7 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "2 200 50\n",
      "6 200 50\n",
      "4 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "5 50 50\n",
      "3 100 30\n",
      "7 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "6 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "6 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "6 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "4 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "2 100 30\n",
      "8 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "8 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "2 100 40\n",
      "5 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "2 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "5 50 40\n",
      "6 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "5 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "9 200 40\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "4 200 50\n",
      "8 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:28.639444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:28.641011: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:28.641396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "8 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "5 50 30\n",
      "5 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "6 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "3 150 40\n",
      "7 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "6 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "3 150 30\n",
      "7 150 30\n",
      "9 150 40\n",
      "9 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "6 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "2 200 50\n",
      "8 200 50\n",
      "9 50 30\n",
      "9 50 40\n",
      "8 50 50\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "3 150 40\n",
      "7 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "6 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "5 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "2 50 50\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "9 100 40\n",
      "2 150 30\n",
      "8 150 30\n",
      "7 150 40\n",
      "8 150 50\n",
      "9 200 30\n",
      "8 200 40\n",
      "9 200 50\n",
      "9 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "2 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "9 200 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:29.593132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f951013cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5c74232f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:29.803815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:29.804475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:29.831730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:29.831800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:29.831806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:29.845232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:29.850477: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:29.850851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:30.251907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 50 30\n",
      "2 50 40\n",
      "5 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "8 150 30\n",
      "9 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "7 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "7 50 50\n",
      "5 100 30\n",
      "2 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "5 150 30\n",
      "5 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "6 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "9 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "4 50 30\n",
      "6 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "9 100 30\n",
      "8 100 40\n",
      "8 100 50\n",
      "9 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "8 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "6 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "7 200 30\n",
      "7 200 40\n",
      "7 200 50\n",
      "7 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "2 200 50\n",
      "7 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "8 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "6 100 40\n",
      "6 100 50\n",
      "6 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "6 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "4 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "9 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "7 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "2 50 30\n",
      "5 50 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:30.698005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:30.698277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:30.698332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:30.874966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:30.875212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:30.936406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:30.936440: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:30.936676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:30.980383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:31.478897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:31.479157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:31.479174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f951013eb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5490256950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa58c9327a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:31.960117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:31.960527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:31.996755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:31.996946: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:31.997306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:32.311592: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:32.311937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:32.311966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:32.800665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:32.801448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:32.859043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:32.866450: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:32.866956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:32.902955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "3 100 30\n",
      "7 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "2 200 40\n",
      "5 200 40\n",
      "2 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "9 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "3 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "5 50 30\n",
      "2 50 40\n",
      "8 50 40\n",
      "5 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "4 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "4 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "9 200 50\n",
      "2 50 40\n",
      "6 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "4 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "8 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "8 50 40\n",
      "7 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "9 100 50\n",
      "6 150 30\n",
      "3 150 40\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "7 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "4 200 50\n",
      "2 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "9 50 30\n",
      "3 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "6 50 30\n",
      "2 50 40\n",
      "5 50 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:33.912667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:33.913093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:33.947164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:33.947259: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:33.947513: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:34.233378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:34.233792: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:34.233845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f29145411b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:35.133116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:35.133408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:35.195185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:35.195288: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:35.195554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:35.576473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3fe8238d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f12d9ab0d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:36.924666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:36.925121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:36.925176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "9 100 50\n",
      "2 150 40\n",
      "8 150 40\n",
      "7 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "9 50 40\n",
      "3 100 30\n",
      "9 100 30\n",
      "3 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "3 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "9 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "8 50 50\n",
      "3 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "8 150 30\n",
      "7 150 40\n",
      "7 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "2 50 40\n",
      "4 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "8 100 50\n",
      "8 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "7 100 30\n",
      "8 100 40\n",
      "9 100 50\n",
      "8 150 30\n",
      "9 150 40\n",
      "7 150 50\n",
      "7 200 30\n",
      "4 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "8 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "5 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "2 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "2 100 40\n",
      "7 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "9 150 50\n",
      "2 200 40\n",
      "5 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "3 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "6 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "3 50 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:38.139839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:38.140167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:38.194239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:38.194425: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:38.194715: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6998f78dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2914542c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f12d9ab2830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:38.956935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3fe82395a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:40.069196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:40.085712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:40.085883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3f9c558ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6998f7ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8d98474160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:41.303326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:41.303940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:41.363673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:41.363850: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:41.364167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f177c1d4c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "8 50 50\n",
      "8 100 30\n",
      "2 100 50\n",
      "5 100 50\n",
      "3 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "6 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "6 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "9 100 50\n",
      "9 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "8 200 30\n",
      "2 200 50\n",
      "7 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "3 150 30\n",
      "9 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "4 50 30\n",
      "7 50 30\n",
      "9 50 40\n",
      "2 100 30\n",
      "5 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "9 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "8 150 40\n",
      "9 150 50\n",
      "3 200 40\n",
      "8 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "6 50 30\n",
      "4 50 40\n",
      "8 50 40\n",
      "8 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "5 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "8 150 30\n",
      "2 150 50\n",
      "5 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "7 200 40\n",
      "8 200 50\n",
      "6 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "8 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "8 200 50\n",
      "8 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "5 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "3 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "5 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "3 150 40\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "2 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "2 200 30\n",
      "6 200 30\n",
      "5 200 40\n",
      "9 200 40\n",
      "3 50 30\n",
      "6 50 30\n",
      "3 50 40\n",
      "8 50 40\n",
      "6 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "8 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "7 100 50\n",
      "8 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "3 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "9 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "7 150 50\n",
      "7 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "3 50 50\n",
      "7 50 50\n",
      "8 100 30\n",
      "9 100 40\n",
      "3 150 30\n",
      "9 150 30\n",
      "3 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "8 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "2 150 50\n",
      "6 150 50\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "5 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "2 150 40\n",
      "6 150 40\n",
      "2 150 50\n",
      "9 150 50\n",
      "5 200 30\n",
      "2 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8d98475750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3f9c55a5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa830090d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:44.331774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f32e87ccb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6948ddce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f47205b05e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:45.567365: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:45.567719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:45.567799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:53:46.029860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f177c1d67a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:46.492860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:46.493249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:46.544163: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:46.544324: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:46.544638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:53:47.297830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:47.299529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:47.299685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6948dde830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f47205b28c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd95046ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f32e87cd480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:53:48.250281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:48.250674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:53:48.287928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:53:48.288093: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:53:48.288384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa8300927a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1de0e28ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f91f3a605e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd95046eb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f59481c4e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f91f3a628c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1de0e29750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f59481c6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5c7c29cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5a5022cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 50 30\n",
      "2 50 50\n",
      "5 50 50\n",
      "6 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "8 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "9 50 30\n",
      "3 50 50\n",
      "6 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "7 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "9 200 50\n",
      "9 50 30\n",
      "7 50 40\n",
      "5 50 50\n",
      "4 100 30\n",
      "9 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "6 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "5 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "6 200 30\n",
      "2 200 40\n",
      "7 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "3 150 30\n",
      "9 150 30\n",
      "3 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "9 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "9 150 40\n",
      "2 200 30\n",
      "4 200 30\n",
      "2 200 40\n",
      "5 200 40\n",
      "4 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "2 50 30\n",
      "8 50 30\n",
      "7 50 40\n",
      "4 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "6 150 30\n",
      "9 150 40\n",
      "8 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "8 50 40\n",
      "8 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "3 150 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:53:59.501097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 50 30\n",
      "2 50 40\n",
      "5 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "6 100 50\n",
      "9 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "7 100 50\n",
      "7 150 30\n",
      "9 150 40\n",
      "9 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "4 50 30\n",
      "8 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "5 150 30\n",
      "5 150 40\n",
      "3 150 50\n",
      "8 150 50\n",
      "2 200 40\n",
      "6 200 40\n",
      "8 200 50\n",
      "9 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "9 50 50\n",
      "2 100 40\n",
      "5 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "3 200 50\n",
      "6 200 50\n",
      "5 50 30\n",
      "3 50 40\n",
      "9 50 40\n",
      "2 100 30\n",
      "7 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "6 150 30\n",
      "7 150 40\n",
      "8 150 50\n",
      "2 200 40\n",
      "8 200 40\n",
      "9 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "8 50 50\n",
      "6 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "9 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "9 50 30\n",
      "9 50 40\n",
      "9 50 50\n",
      "7 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "8 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "2 50 30\n",
      "7 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "9 150 30\n",
      "7 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "6 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "7 200 50\n",
      "5 50 30\n",
      "8 50 30\n",
      "8 50 40\n",
      "7 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "7 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "8 150 30\n",
      "4 150 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5c7c29e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:54:00.297921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:00.298007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:00.298015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:54:01.065819: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5a5022c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:54:01.230923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:01.231171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:01.291052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:01.291422: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:54:01.291757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fef70179090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2023-02-27 22:54:02.356842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:02.358050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:02.358111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:54:03.383489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:03.384376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:03.424041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:03.424126: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:54:03.424383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe1d9ccc160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fef7017ac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 50 30\n",
      "6 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "6 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "4 50 40\n",
      "9 50 40\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "9 100 50\n",
      "7 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "5 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "5 200 50\n",
      "6 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "7 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "9 150 30\n",
      "7 150 40\n",
      "9 150 50\n",
      "3 200 40\n",
      "6 200 40\n",
      "8 200 50\n",
      "4 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "8 150 30\n",
      "2 150 50\n",
      "8 150 50\n",
      "6 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "8 50 30\n",
      "5 50 40\n",
      "8 50 50\n",
      "2 100 40\n",
      "2 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "5 150 50\n",
      "4 200 30\n",
      "2 200 40\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "2 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "9 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "9 50 50\n",
      "7 100 30\n",
      "3 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "8 150 30\n",
      "8 150 40\n",
      "7 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "9 50 30\n",
      "8 50 40\n",
      "5 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "8 100 40\n",
      "2 150 30\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "7 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "4 50 30\n",
      "3 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "4 100 50\n",
      "2 150 30\n",
      "7 150 30\n",
      "6 150 40\n",
      "3 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "3 200 50\n",
      "7 200 50\n",
      "3 50 40\n",
      "8 50 40\n",
      "5 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "7 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "4 200 50\n",
      "2 50 30\n",
      "8 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "5 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "6 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "7 150 50\n",
      "4 200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe1d9ccc040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "7 50 50\n",
      "5 100 30\n",
      "4 100 40\n",
      "4 100 50\n",
      "2 150 30\n",
      "4 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "8 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "2 50 30\n",
      "9 50 30\n",
      "4 50 50\n",
      "9 50 50\n",
      "2 100 40\n",
      "5 100 40\n",
      "3 100 50\n",
      "8 100 50\n",
      "2 150 40\n",
      "7 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "6 50 50\n",
      "7 100 30\n",
      "5 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "9 200 30\n",
      "3 200 50\n",
      "7 200 50\n",
      "3 50 40\n",
      "8 50 40\n",
      "9 50 50\n",
      "9 100 30\n",
      "9 100 40\n",
      "7 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "4 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "7 200 40\n",
      "7 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "9 100 30\n",
      "7 100 40\n",
      "4 100 50\n",
      "4 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "6 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "2 50 50\n",
      "2 100 30\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 150 30\n",
      "8 150 30\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "2 200 50\n",
      "7 200 50\n",
      "3 50 40\n",
      "9 50 40\n",
      "8 50 50\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "8 150 30\n",
      "6 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n",
      "9 200 40\n",
      "6 200 50\n",
      "6 50 30\n",
      "5 50 40\n",
      "3 50 50\n",
      "9 50 50\n",
      "9 100 30\n",
      "8 100 40\n",
      "8 100 50\n",
      "7 150 30\n",
      "8 150 40\n",
      "6 150 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "6 150 40\n",
      "6 150 50\n",
      "9 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "6 50 40\n",
      "3 50 50\n",
      "3 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 150 30\n",
      "2 150 40\n",
      "7 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "4 200 50\n",
      "8 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "9 50 40\n",
      "9 50 50\n",
      "2 100 40\n",
      "5 100 40\n",
      "4 100 50\n",
      "3 150 30\n",
      "2 150 40\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "6 200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:54:09.741127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:54:10.649464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:54:10.693719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:10.693927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:10.693983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 50 30\n",
      "3 50 40\n",
      "7 50 40\n",
      "5 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "9 150 30\n",
      "9 150 40\n",
      "2 200 30\n",
      "7 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "5 50 30\n",
      "2 50 40\n",
      "5 50 40\n",
      "2 50 50\n",
      "7 50 50\n",
      "6 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "3 150 30\n",
      "8 150 30\n",
      "8 150 40\n",
      "8 150 50\n",
      "8 200 30\n",
      "8 200 40\n",
      "5 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "8 50 40\n",
      "9 50 50\n",
      "8 100 30\n",
      "3 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "3 150 40\n",
      "9 150 40\n",
      "3 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "5 200 50\n",
      "4 50 30\n",
      "8 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "8 50 50\n",
      "7 100 30\n",
      "7 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "8 150 40\n",
      "9 150 50\n",
      "9 200 30\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 50 30\n",
      "9 50 30\n",
      "8 50 40\n",
      "5 50 50\n",
      "5 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "8 100 50\n",
      "5 150 30\n",
      "4 150 40\n",
      "2 150 50\n",
      "7 150 50\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "7 50 30\n",
      "7 50 40\n",
      "6 50 50\n",
      "4 100 30\n",
      "3 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "7 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "2 200 30\n",
      "8 200 30\n",
      "6 200 40\n",
      "9 200 50\n",
      "7 50 40\n",
      "6 50 50\n",
      "5 100 30\n",
      "5 100 40\n",
      "5 100 50\n",
      "2 150 30\n",
      "6 150 30\n",
      "4 150 40\n",
      "5 150 50\n",
      "3 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "4 200 50\n",
      "3 50 30\n",
      "2 50 40\n",
      "7 50 40\n",
      "7 50 50\n",
      "8 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "5 150 30\n",
      "9 150 30\n",
      "7 150 40\n",
      "9 150 50\n",
      "7 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "5 50 30\n",
      "4 50 40\n",
      "2 50 50\n",
      "6 50 50\n",
      "4 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "6 150 30\n",
      "4 150 40\n",
      "3 150 50\n",
      "9 150 50\n",
      "7 200 30\n",
      "2 200 50\n",
      "3 50 30\n",
      "7 50 30\n",
      "4 50 40\n",
      "3 50 50\n",
      "2 100 30\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "3 150 30\n",
      "9 150 30\n",
      "9 150 40\n",
      "9 150 50\n",
      "8 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "7 50 30\n",
      "6 50 40\n",
      "4 50 50\n",
      "3 100 30\n",
      "8 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "2 150 30\n",
      "6 150 30\n",
      "5 150 40\n",
      "4 150 50\n",
      "3 200 30\n",
      "9 200 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:54:11.621859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:11.622415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:11.675356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:11.675448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:54:11.675711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:54:11.844423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:11.844671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:11.844677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:54:12.672475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:12.672890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:12.743692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:12.743784: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:54:12.749107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:54:12.762733: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:54:13.767866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:13.768218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:13.768244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:54:14.753552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:14.759721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-27 22:54:14.887013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:54:14.887196: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 22:54:14.888715: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5fcce5cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7efee4704790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5fcce5e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7efee4705e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f97490f8c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb6b83509d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4fc83a8820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb6b83524d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f97490fa8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4fc83aa680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 100 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82ec1d33a0&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [30, 40, 50], &#x27;epochs&#x27;: [50, 100, 150],\n",
       "                         &#x27;first_layer_nodes&#x27;: [50, 100, 150, 200],\n",
       "                         &#x27;last_layer_nodes&#x27;: [30, 40, 50],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;binary_crossentropy&#x27;],\n",
       "                         &#x27;n_layers&#x27;: array([2, 3, 4, 5, 6, 7, 8, 9])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82ec1d33a0&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;activation_func&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;],\n",
       "                         &#x27;batch_size&#x27;: [30, 40, 50], &#x27;epochs&#x27;: [50, 100, 150],\n",
       "                         &#x27;first_layer_nodes&#x27;: [50, 100, 150, 200],\n",
       "                         &#x27;last_layer_nodes&#x27;: [30, 40, 50],\n",
       "                         &#x27;loss_func&#x27;: [&#x27;binary_crossentropy&#x27;],\n",
       "                         &#x27;n_layers&#x27;: array([2, 3, 4, 5, 6, 7, 8, 9])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82ec1d33a0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82ec1d33a0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f82ec1d33a0>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation_func': ['relu', 'tanh'],\n",
       "                         'batch_size': [30, 40, 50], 'epochs': [50, 100, 150],\n",
       "                         'first_layer_nodes': [50, 100, 150, 200],\n",
       "                         'last_layer_nodes': [30, 40, 50],\n",
       "                         'loss_func': ['binary_crossentropy'],\n",
       "                         'n_layers': array([2, 3, 4, 5, 6, 7, 8, 9])})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6307881712913513\n",
      "{'activation_func': 'tanh', 'batch_size': 40, 'epochs': 50, 'first_layer_nodes': 100, 'last_layer_nodes': 50, 'loss_func': 'binary_crossentropy', 'n_layers': 3}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(14,), activation='tanh'))\n",
    "model.add(Dense(75, input_shape=(14,), activation='tanh'))\n",
    "model.add(Dense(50, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(84, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(76, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(67, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(59, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(51, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(75, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(65, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(55, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 14ms/step - loss: 0.7484 - accuracy: 0.4965\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.5385\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6713\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7343\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.7273\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7762\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7762\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7692\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7832\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7902\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7972\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8462\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8392\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8252\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.8322\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.8531\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.8881\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8881\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8951\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8951\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.9161\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.9091\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.9091\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.9091\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.9231\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8811\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.9021\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8462\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2906 - accuracy: 0.9091\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9231\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8951\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9161\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9301\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2207 - accuracy: 0.9441\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2236 - accuracy: 0.9510\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9441\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9441\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9580\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9720\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9441\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9580\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1664 - accuracy: 0.9580\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9510\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9720\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9790\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1342 - accuracy: 0.9510\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9510\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9790\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9650\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2190 - accuracy: 0.5000\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 11ms/step - loss: 0.2479 - recall_11: 0.9722\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2471 - recall_11: 0.8194\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1642 - recall_11: 1.0000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1264 - recall_11: 0.9583\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1095 - recall_11: 0.9861\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1073 - recall_11: 1.0000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1039 - recall_11: 0.9861\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0949 - recall_11: 1.0000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0921 - recall_11: 1.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0881 - recall_11: 0.9861\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0902 - recall_11: 1.0000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0863 - recall_11: 0.9861\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0939 - recall_11: 1.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1099 - recall_11: 0.9306\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0890 - recall_11: 1.0000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0832 - recall_11: 0.9722\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0834 - recall_11: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0797 - recall_11: 0.9861\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1279 - recall_11: 0.9722\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1935 - recall_11: 0.8194\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1893 - recall_11: 1.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0897 - recall_11: 0.9861\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0650 - recall_11: 1.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0850 - recall_11: 0.9861\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0686 - recall_11: 0.9722\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0632 - recall_11: 1.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0654 - recall_11: 0.9861\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0607 - recall_11: 1.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0611 - recall_11: 1.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0491 - recall_11: 1.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0516 - recall_11: 1.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0505 - recall_11: 0.9861\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0502 - recall_11: 1.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0440 - recall_11: 1.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0527 - recall_11: 0.9861\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0395 - recall_11: 1.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0475 - recall_11: 0.9861\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0402 - recall_11: 1.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0606 - recall_11: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0618 - recall_11: 0.9583\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0892 - recall_11: 0.9861\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0723 - recall_11: 0.9167\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1679 - recall_11: 1.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1897 - recall_11: 0.8194\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2473 - recall_11: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3499 - recall_11: 0.7639\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2707 - recall_11: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1433 - recall_11: 0.9167\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1006 - recall_11: 0.9444\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1041 - recall_11: 1.0000\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.7151 - recall_11: 0.4444\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.5061 - auc_11: 0.9137\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2768 - auc_11: 0.9929\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2339 - auc_11: 0.9927\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1049 - auc_11: 0.9954\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1526 - auc_11: 0.9965\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0759 - auc_11: 0.9988\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1014 - auc_11: 0.9972\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0893 - auc_11: 0.9980\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0562 - auc_11: 1.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0560 - auc_11: 0.9996\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0546 - auc_11: 0.9996\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0510 - auc_11: 0.9994\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0485 - auc_11: 1.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0467 - auc_11: 0.9996\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0482 - auc_11: 0.9998\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0453 - auc_11: 1.0000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0428 - auc_11: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0512 - auc_11: 0.9996\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0360 - auc_11: 1.0000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0393 - auc_11: 1.0000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0435 - auc_11: 1.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0417 - auc_11: 1.0000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0407 - auc_11: 0.9998\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0451 - auc_11: 0.9994\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0348 - auc_11: 0.9998\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0464 - auc_11: 0.9994\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0487 - auc_11: 0.9990\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0372 - auc_11: 0.9998\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0403 - auc_11: 0.9998\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0542 - auc_11: 0.9996\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0821 - auc_11: 0.9998\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0886 - auc_11: 1.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1297 - auc_11: 0.9923\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1397 - auc_11: 0.9947\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0905 - auc_11: 0.9934\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1054 - auc_11: 0.9974\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0991 - auc_11: 0.9988\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0576 - auc_11: 0.9990\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0513 - auc_11: 0.9994\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0643 - auc_11: 0.9987\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0456 - auc_11: 1.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0395 - auc_11: 0.9998\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0396 - auc_11: 0.9996\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0341 - auc_11: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0323 - auc_11: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0387 - auc_11: 0.9998\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0305 - auc_11: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0426 - auc_11: 0.9992\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0301 - auc_11: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0298 - auc_11: 1.0000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1807 - auc_11: 0.5231\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.2140 - accuracy: 0.7552\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6465 - accuracy: 0.6014\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3.3924 - accuracy: 0.4895\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0780 - accuracy: 0.6014\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.4131 - accuracy: 0.5664\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.5664\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.6434\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6294\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7483\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.6853\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.6923\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7063\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5092 - accuracy: 0.7273\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7273\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7203\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7273\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7622\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7203\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7063\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7552\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7483\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.7622\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7622\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7692\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7552\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7692\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7133\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4669 - accuracy: 0.7343\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4743 - accuracy: 0.7133\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7063\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7203\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7552\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7622\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7692\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7832\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7273\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7483\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7343\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8182\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8112\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3661 - accuracy: 0.8182\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3925 - accuracy: 0.7832\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7832\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7622\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7483\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7622\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8042\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7902\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.7972\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.2390 - accuracy: 0.4722\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4487 - recall_11: 0.7333\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3805 - recall_11: 0.7639\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3645 - recall_11: 0.8056\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3825 - recall_11: 0.7917\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4459 - recall_11: 0.6806\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4748 - recall_11: 0.6389\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4343 - recall_11: 0.7361\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3779 - recall_11: 0.8333\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3929 - recall_11: 0.8194\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5654 - recall_11: 0.6389\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4480 - recall_11: 0.7500\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6234 - recall_11: 0.7083\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4529 - recall_11: 0.7778\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3790 - recall_11: 0.8333\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3530 - recall_11: 0.8611\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3710 - recall_11: 0.8333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6006 - recall_11: 0.7639\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4145 - recall_11: 0.7778\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4363 - recall_11: 0.7083\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3918 - recall_11: 0.7778\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3941 - recall_11: 0.7778\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4341 - recall_11: 0.7778\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5031 - recall_11: 0.8056\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4146 - recall_11: 0.8889\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4506 - recall_11: 0.7639\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4656 - recall_11: 0.7917\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3803 - recall_11: 0.7639\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3626 - recall_11: 0.9444\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3478 - recall_11: 0.8750\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3648 - recall_11: 0.8611\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3676 - recall_11: 0.8056\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3874 - recall_11: 0.7917\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3917 - recall_11: 0.8611\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3832 - recall_11: 0.7500\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3809 - recall_11: 0.8611\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3609 - recall_11: 0.8194\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3768 - recall_11: 0.6667\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3430 - recall_11: 0.8056\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3590 - recall_11: 0.8194\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3650 - recall_11: 0.8472\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3226 - recall_11: 0.8750\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4058 - recall_11: 0.7917\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3798 - recall_11: 0.8194\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4144 - recall_11: 0.7222\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4947 - recall_11: 0.6806\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4137 - recall_11: 0.8611\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4221 - recall_11: 0.7778\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3582 - recall_11: 0.8194\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3219 - recall_11: 0.8333\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3402 - recall_11: 0.8750\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1719 - recall_11: 0.2778\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3481 - auc_11: 0.8069\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3367 - auc_11: 0.9343\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3629 - auc_11: 0.9192\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5054 - auc_11: 0.8334\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5831 - auc_11: 0.8245\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4780 - auc_11: 0.8468\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3488 - auc_11: 0.9322\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3475 - auc_11: 0.9271\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3758 - auc_11: 0.9178\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3761 - auc_11: 0.9065\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3679 - auc_11: 0.9086\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3259 - auc_11: 0.9410\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4661 - auc_11: 0.8646\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4381 - auc_11: 0.8708\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3320 - auc_11: 0.9455\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3854 - auc_11: 0.9056\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3287 - auc_11: 0.9361\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3801 - auc_11: 0.9041\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3336 - auc_11: 0.9344\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3251 - auc_11: 0.9332\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3531 - auc_11: 0.9214\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3110 - auc_11: 0.9463\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3034 - auc_11: 0.9459\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2920 - auc_11: 0.9563\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2961 - auc_11: 0.9529\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3739 - auc_11: 0.9001\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3322 - auc_11: 0.9355\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3684 - auc_11: 0.9128\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3144 - auc_11: 0.9442\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3123 - auc_11: 0.9447\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3244 - auc_11: 0.9336\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2980 - auc_11: 0.9471\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3146 - auc_11: 0.9400\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3536 - auc_11: 0.9249\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3105 - auc_11: 0.9441\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3361 - auc_11: 0.9288\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3688 - auc_11: 0.9078\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4538 - auc_11: 0.8656\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5289 - auc_11: 0.8326\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5538 - auc_11: 0.8119\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3984 - auc_11: 0.8973\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4725 - auc_11: 0.8509\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4365 - auc_11: 0.8718\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3706 - auc_11: 0.9136\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3950 - auc_11: 0.8889\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4150 - auc_11: 0.8774\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4205 - auc_11: 0.8810\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3743 - auc_11: 0.9087\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4493 - auc_11: 0.8597\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4217 - auc_11: 0.8709\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1822 - auc_11: 0.4491\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0608 - accuracy: 0.6713\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7133\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7902\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7622\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8462\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7622\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7552\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.7902\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.7972\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.7762\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.7972\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8671\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8042\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8392\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2959 - accuracy: 0.8671\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8182\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8182\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8392\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7622\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8112\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8182\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7552\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8392\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8881\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6713\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8811\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2841 - accuracy: 0.8741\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7832\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8531\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3395 - accuracy: 0.8322\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8811\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7063\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2681 - accuracy: 0.8671\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8252\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.7902\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2998 - accuracy: 0.8322\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8881\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8182\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8392\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2976 - accuracy: 0.8182\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2920 - accuracy: 0.8462\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.7972\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8182\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8811\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.7762\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.7622\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3187 - accuracy: 0.8112\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2794 - accuracy: 0.8392\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.8671\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1955 - accuracy: 0.5278\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8364 - recall_11: 0.6667\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3043 - recall_11: 0.8611\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3747 - recall_11: 0.7778\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3175 - recall_11: 0.8056\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2660 - recall_11: 0.9167\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2441 - recall_11: 0.8750\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2734 - recall_11: 0.8750\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2559 - recall_11: 0.8750\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2392 - recall_11: 0.9028\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3484 - recall_11: 0.9167\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2987 - recall_11: 0.7917\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3093 - recall_11: 0.8333\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3174 - recall_11: 0.8056\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2887 - recall_11: 0.9028\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2582 - recall_11: 0.8611\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2558 - recall_11: 0.8750\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2625 - recall_11: 0.8889\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3070 - recall_11: 0.8472\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2859 - recall_11: 0.8611\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3730 - recall_11: 0.7500\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2639 - recall_11: 0.8333\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2484 - recall_11: 0.8472\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2818 - recall_11: 0.8333\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2715 - recall_11: 0.9444\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2406 - recall_11: 0.8611\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4068 - recall_11: 0.7917\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2323 - recall_11: 0.9167\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2835 - recall_11: 0.7778\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2420 - recall_11: 0.8889\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2385 - recall_11: 0.9444\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2529 - recall_11: 0.8472\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2500 - recall_11: 0.8750\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3654 - recall_11: 0.8194\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2506 - recall_11: 0.8056\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2392 - recall_11: 0.9444\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2231 - recall_11: 0.8889\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4355 - recall_11: 0.8472\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2571 - recall_11: 0.8333\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2721 - recall_11: 0.8194\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2146 - recall_11: 0.9444\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2279 - recall_11: 0.9167\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3109 - recall_11: 0.8333\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2456 - recall_11: 0.8750\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3613 - recall_11: 0.8056\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2213 - recall_11: 0.9167\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2157 - recall_11: 0.8889\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2143 - recall_11: 0.8750\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2484 - recall_11: 0.8750\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3676 - recall_11: 0.8194\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2693 - recall_11: 0.8889\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3738 - recall_11: 0.4444\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 9ms/step - loss: 0.6458 - auc_11: 0.8049\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2683 - auc_11: 0.9497\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3096 - auc_11: 0.9327\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2322 - auc_11: 0.9640\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2285 - auc_11: 0.9611\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2752 - auc_11: 0.9488\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2485 - auc_11: 0.9586\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2529 - auc_11: 0.9579\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2135 - auc_11: 0.9746\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2817 - auc_11: 0.9518\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2352 - auc_11: 0.9606\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2556 - auc_11: 0.9531\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3003 - auc_11: 0.9427\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2294 - auc_11: 0.9704\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2987 - auc_11: 0.9420\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2302 - auc_11: 0.9675\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2381 - auc_11: 0.9615\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2735 - auc_11: 0.9450\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2701 - auc_11: 0.9546\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2160 - auc_11: 0.9727\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2528 - auc_11: 0.9571\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2111 - auc_11: 0.9687\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2229 - auc_11: 0.9681\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2059 - auc_11: 0.9731\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3964 - auc_11: 0.9097\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2092 - auc_11: 0.9707\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2145 - auc_11: 0.9700\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2038 - auc_11: 0.9738\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2267 - auc_11: 0.9646\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3357 - auc_11: 0.9292\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2316 - auc_11: 0.9675\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2018 - auc_11: 0.9741\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2721 - auc_11: 0.9525\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2257 - auc_11: 0.9621\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1921 - auc_11: 0.9775\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1898 - auc_11: 0.9795\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2797 - auc_11: 0.9535\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2175 - auc_11: 0.9684\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3112 - auc_11: 0.9362\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1917 - auc_11: 0.9761\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1874 - auc_11: 0.9772\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2512 - auc_11: 0.9611\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2036 - auc_11: 0.9739\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1977 - auc_11: 0.9740\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2339 - auc_11: 0.9655\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1890 - auc_11: 0.9783\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2132 - auc_11: 0.9684\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2165 - auc_11: 0.9691\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2216 - auc_11: 0.9640\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1909 - auc_11: 0.9801\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6727 - auc_11: 0.5417\n",
      "1.1719412803649902\n",
      "sgd\n",
      "Recall(name=recall_11,dtype=float32,thresholds=None,top_k=None,class_id=None)\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "metrics = ['accuracy', Recall(), AUC()]\n",
    "best_loss = float('inf')\n",
    "best_optimizer = None\n",
    "best_metric = None\n",
    "# Compile the model with each optimizer and metric\n",
    "for optimizer in optimizers:\n",
    "    for metric in metrics:\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metric)\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=40)\n",
    "        val_loss, val_metric = model.evaluate(X_test, y_test)\n",
    "        \n",
    "        # Print the validation loss and metric\n",
    "#         print('Optimizer: {}, Metric: {}, Validation Loss: {:.4f}, Validation Metric: {:.4f}'.format(optimizer, metric, val_loss, val_metric))\n",
    "        if val_loss < best_loss: \n",
    "            best_loss = val_loss\n",
    "            best_optimizer = optimizer\n",
    "            best_metric = metric\n",
    "print(best_loss)\n",
    "print(best_optimizer)\n",
    "print(best_metric)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=Recall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5527 - recall_13: 0.7778\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5823 - recall_13: 0.6389\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5589 - recall_13: 0.7778\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5286 - recall_13: 0.8333\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4166 - recall_13: 0.8333\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4741 - recall_13: 0.8333\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5134 - recall_13: 0.8472\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6260 - recall_13: 0.6111\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3918 - recall_13: 0.8472\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3824 - recall_13: 0.8472\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3709 - recall_13: 0.8472\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4327 - recall_13: 0.9028\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3749 - recall_13: 0.8472\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4226 - recall_13: 0.8333\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3832 - recall_13: 0.8750\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4690 - recall_13: 0.7639\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4000 - recall_13: 0.7917\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4082 - recall_13: 0.8472\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4319 - recall_13: 0.9167\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4830 - recall_13: 0.5694\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5162 - recall_13: 0.8750\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3591 - recall_13: 0.8611\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3831 - recall_13: 0.8333\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4386 - recall_13: 0.7361\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4320 - recall_13: 0.8056\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3604 - recall_13: 0.8472\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3980 - recall_13: 0.7639\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3559 - recall_13: 0.8750\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3719 - recall_13: 0.8333\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3649 - recall_13: 0.8472\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3682 - recall_13: 0.9028\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3950 - recall_13: 0.8333\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3352 - recall_13: 0.9444\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4268 - recall_13: 0.6667\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3894 - recall_13: 0.8194\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3907 - recall_13: 0.8333\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3679 - recall_13: 0.8194\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3419 - recall_13: 0.8750\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3776 - recall_13: 0.9028\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3668 - recall_13: 0.8333\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3548 - recall_13: 0.8056\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4629 - recall_13: 0.7917\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4025 - recall_13: 0.7639\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3756 - recall_13: 0.9167\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3421 - recall_13: 0.8056\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3863 - recall_13: 0.6944\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3486 - recall_13: 0.8611\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3557 - recall_13: 0.8194\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3403 - recall_13: 0.8611\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3667 - recall_13: 0.7917\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_new, labels, test_size=0.2, random_state=84)\n",
    "\n",
    "h = model.fit(\n",
    "  X_train, # training data\n",
    "  y_train, # training targets\n",
    "  epochs=50,\n",
    "  batch_size=40,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report the training accuracy at that 5th epoch \n",
    "#Look at preciosn & recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "Accuracy is: 79.72027972027972\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_train)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n",
      "Accuracy is: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2789350/3347757405.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(col, rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "\n",
    "# print feature importances\n",
    "fig, ax = plt.subplots()\n",
    "col = ['0_x1', '0_x2', '1_x1', '1_x2','2_x1', '2_x2','3_x1', '3_x2','4_x1', '4_x2','5_x1', '5_x2','6_x1', '6_x2',]\n",
    "ax.bar(col, result.importances_mean)\n",
    "ax.set_xticklabels(col, rotation=90)\n",
    "ax.set_title('Feature Importances from Permutation Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEWCAYAAABLzQ1kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfUUlEQVR4nO3deZgU1fn28e89MyAICIJgDJEoKm7EBXElKkZj1LjHNeCelyzuS7xizCuaRKP+fI1JNFHiLsYYoxKXRCEqEo0aEFDBXYmKoOCGCCogz/tH1Wgzv1m6e7qma5j7w1XXVNdyzulh5pnTT506pYjAzMzyp6baDTAzs8Y5QJuZ5ZQDtJlZTjlAm5nllAO0mVlOOUCbmeWUA7S1mqSuku6WtEDSba0oZ4Sk8ZVsWzVI+oeko6rdDmv/HKA7EEnflTRF0keS5qaB5OsVKPogYE2gT0QcXG4hEXFzROxegfasQNJwSSHpzgbbN0+3TyyynHMljW3puIjYMyJuKLO5Zp9zgO4gJJ0GXAZcQBJMBwC/B/arQPFfBV6MiGUVKCsr84HtJfUp2HYU8GKlKlDCv1NWMf5h6gAk9QR+DhwfEXdExKKIWBoRd0fEj9NjVpF0maQ56XKZpFXSfcMlzZZ0uqR5ae/7mHTfecA5wKFpz/y4hj1NSeukPdW69PXRkl6VtFDSLEkjCrY/UnDeDpImp6mTyZJ2KNg3UdIvJD2aljNe0hrNfBuWAOOAw9Lza4FDgZsbfK9+I+kNSR9KelLSjun2PYCfFrzPpwracb6kR4HFwMB02/fS/X+QdHtB+RdJekCSiv3/s47LAbpj2B7oAtzZzDFnA9sBWwCbA9sAPyvY/yWgJ9AfOA64QtLqETGapFd+a0R0j4hrmmuIpG7Ab4E9I6IHsAMwvZHjegP3psf2AS4F7m3QA/4ucAzQD+gMnNFc3cCNwJHp+reAGcCcBsdMJvke9Ab+BNwmqUtE3NfgfW5ecM4RwCigB/Bag/JOB76W/vHZkeR7d1R4jgUrggN0x9AHeKeFFMQI4OcRMS8i5gPnkQSeekvT/Usj4u/AR8CGZbZnOTBYUteImBsRMxs55tvASxFxU0Qsi4hbgOeBfQqOuS4iXoyIj4G/kATWJkXEv4HekjYkCdQ3NnLM2Ih4N63z/wGr0PL7vD4iZqbnLG1Q3mKS7+OlwFjgxIiY3UJ5ZoADdEfxLrBGfYqhCV9mxd7fa+m2z8toEOAXA91LbUhELCJJLfwAmCvpXkkbFdGe+jb1L3j9VhntuQk4AdiFRj5RSDpD0nNpWuUDkk8NzaVOAN5obmdEPAG8CojkD4lZURygO4bHgE+B/Zs5Zg7Jxb56A/jfH/+LtQhYteD1lwp3RsT9EfFNYC2SXvEfi2hPfZveLLNN9W4CfgT8Pe3dfi5NQZwJHAKsHhG9gAUkgRWgqbREs+kKSceT9MTnpOWbFcUBugOIiAUkF/KukLS/pFUldZK0p6SL08NuAX4mqW96se0cko/k5ZgO7CRpQHqB8qz6HZLWlLRfmov+lCRVsryRMv4ODEqHBtZJOhTYBLinzDYBEBGzgJ1Jcu4N9QCWkYz4qJN0DrBawf63gXVKGakhaRDwS2AkSarjTElblNd662gcoDuINJ96GsmFv/kkH8tPIBnZAEkQmQI8DTwDTE23lVPXBODWtKwnWTGo1qTtmAO8RxIsf9hIGe8Ce5NcZHuXpOe5d0S8U06bGpT9SEQ09ungfuA+kqF3rwGfsGL6ov4mnHclTW2pnjSlNBa4KCKeioiXSEaC3FQ/QsasOfLFZDOzfHIP2swspxygzcwqTNK16U1dMxpsP1HS85JmFlz/aZIDtJlZ5V0P7FG4QdIuJFMrbB4RmwKXtFSIA7SZWYVFxCSSi+CFfghcGBGfpsfMa6mc5m5cqKqLH3rFVy/tfzlpx/Wq3QTLoS51tHpuk65bnlB0zPlk+hXfJ7m9v96YiBjTwmmDgB0lnU8yQuiMiJjc3Am5DdBmZm2qhIkI02DcUkBuqI5kjpftgK2Bv0ga2Ny8LE5xmJkBSMUv5ZkN3BGJ/5DcoNXsNAIO0GZmkPSgi13KM45kDpj6O0w7A83eeOUUh5kZtKZn3EhRugUYTjJJ2WxgNHAtcG069G4JRUw76wBtZgZQU1uxoiLi8CZ2jSylHAdoMzNoTeoiMw7QZmZQ0RRHpThAm5mBe9BmZrnlHrSZWU65B21mllMVHMVRKQ7QZmbgHrSZWW7VOAdtZpZP7kGbmeWUR3GYmeWULxKameWUUxxmZjnlFIeZWU65B21mllPuQZuZ5ZR70GZmOeVRHGZmOeUetJlZTjkHbWaWU+5Bm5nllHvQZmY5lcMedP5aZGZWBaqpKXppsSzpWknzJM1oZN/pkkLSGi2V4wBtZgZIKnopwvXAHo3UsTawO/B6MYU4QJuZAaiEpQURMQl4r5FdvwbOBKKYJjlAm5lRWg9a0ihJUwqWUUWUvx/wZkQ8VWybfJHQzAyKTV0AEBFjgDEllL0q8FOS9EbRHKDNzICaIi7+tcJ6wLrAU+kfgq8AUyVtExFvNXWSA7SZGRSVWy5XRDwD9Pu8Kum/wNCIeKe58zIJ0JIW0kwSPCJWy6JeM7NylZLiKKKsW4DhwBqSZgOjI+KaUsvJJEBHRA8ASb8A5gI3kfx9GgGslUWdZmatUckAHRGHt7B/nWLKyTrFsW9EbF7w+g+SngLOybheM7OSVDJAV0rWw+wWSRohqVZSjaQRwKKM6zQzK1mFb1SpiKwD9HeBQ4C30+XgdJuZWa6oRkUvbSXTFEdE/BfYL8s6zMwqocOlOCQNkvRA/YQhkjaT9LMs6zQzK0dHTHH8ETgLWAoQEU8Dh2Vcp5lZ6So4F0elZD2KY9WI+E+DvzjLMq7TzKxkeUxxZB2g35G0HulNK5IOIhkXbWaWKx0xQB9PMqHIRpLeBGYBIzOu08ysZBnPxVGWrEdxvArsJqkbUBMRC7Osz8ysbPnrQGc+iuNkSasBi4FfS5oqqaTp9szM2kJHHMVxbER8SDIHah/gCODCjOs0MytZHgN01jno+neyF3BjRMxUHjPxZtbh5TE0ZR2gn5Q0nmSi6rMk9QCWZ1ynmVnJ2vIW7mJlHaCPA7YAXo2IxZL6AMdkXOdKZcY/7+SFR+8Hid5fXocdjzqVuk6dq90sq6K35s7l7LPO5L133wWJgw4+hBFHHFXtZrV7Ha4HHRHLJc0CBknqkmVdK6NF77/DzIfu4jujr6Su8yo8OOYCXp38MIN2+Ga1m2ZVVFtXyxln/oSNN9mURYs+4rCDv8N22w9jvfXXr3bT2rUOF6AlfQ84meT5W9OB7YDHgG9kWe/KJJZ/xmdLl1BTW8eypZ+yaq8+1W6SVVnfvv3o2zd5elK3bt0ZOHAg8+a97QDdSh0uQJME562BxyNiF0kbARdkXOdKo9vqazB4twP580+Poq5TZ/pvPISvbDKk2s2yHHnzzdk8/9xzfG2zzVs+2JqXv/ic+TC7TyLiEwBJq0TE88CGTR0saZSkKZKmPHHPnzNuWv59umghrz/9OIf88joOv2gsS5d8wstPPFjtZllOLF60iNNPOYkf/+SndO/evdrNaffyOMwu6wA9W1IvYBwwQdLfgNeaOjgixkTE0IgYuu3envRuzvPT6dHnS3Tt0ZOa2jrW2XIYb7/yXLWbZTmwdOlSTjvlJPb69j7s9k3f+1UJNTUqemkrWV8kPCBdPVfSQ0BP4L4s61yZdOvdl3mznmfZkk+o7bQKc56fzhpf3aDazbIqiwjOPedsBg4cyJFHe1BUpXTEHDSSvg5sEBHXSeoL9CeZNMla0G/djVh3yNcZd/5JqLaWPmsPZKOv71ntZlmVTZv6JPfc9Tc2GDSIQw5MHlh04imnseNOO1e5Ze1bDuNz5qM4RgNDSfLO1wGdgLHAsCzrXZkM2WckQ/bxBID2hSFbDeWpmS9UuxkrnUr2oCVdC+wNzIuIwem2/wH2AZYArwDHRMQHzZWTdQ76AGBf0id5R8QcoEfGdZqZlUwqfinC9cAeDbZNAAZHxGbAiyRPm2pW1gF6SUQEX0zY3y3j+szMylLJi4QRMQl4r8G28RFR/0Spx0nuD2m+TeW8kRL8RdJVQC9J/wf4J8lzCs3McqWUAF04JDhdRpVY3bHAP1o6KOtRHJdI+ibwIUke+pyImJBlnWZm5SglBR0RY0ieFlVGPTqb5NmsN7d0bNYXCbsBD0bEBEkbAhtK6hQRS7Os18ysVG0xzE7S0SQXD3dN07/NyjrFMQlYRVJ/kvHPR5Akz83MciXrOwkl7QGcCewbEYuLOSfrAK20IQcCf4iIg4FNM67TzKxklRzFIekWkonhNpQ0W9JxwOUko9gmSJou6cqWysn8iSqStgdGkMwNDVCbcZ1mZiWr5C3cEXF4I5uvKbWcrAP0KSRj/e5MH3c1EHgo4zrNzErW4W71joiHgYcLXr8KnJRlnWZm5chhfM4mQEu6LCJOkXQ36U0qhSJi3yzqNTMrV0fqQd+Ufr0ko/LNzCoqh/E5mwAdEU+mXx9OZ7AjIuZnUZeZWSXksQed2TA7SedKegd4AXhR0nxJ52RVn5lZa+Rxwv5MArSk00imFN06InpHxOrAtsAwSadmUaeZWWtUeDa7isiqB30EcHhEfD4xfzqCYyRwZEZ1mpmVLY/PJMzqImGniHin4caImC+pU0Z1mpmVLYcp6MwC9JIy95mZVUUeLxJmFaA3l/RhI9sFdMmoTjOzsnWYAB0Rnm/DzNqVthydUazMn+ptZtYe5LAD7QBtZgYdKMVhZtbe5DA+O0CbmQHU5DBCO0CbmeGLhGZmuZXD+OwAbWYGvkhoZpZbOYzPDtBmZgAifxHaAdrMjHzmoDObsN/MrD2p5IT9kq6VNE/SjIJtvSVNkPRS+nX1FtvUyvdkZrZSqJGKXopwPbBHg20/AR6IiA2AB9LXzbep1DdhZrYyquQTVSJiEvBeg837ATek6zcA+7dUjnPQZma0yTC7NSNibrr+FrBmSye4B21mRmk9aEmjJE0pWEaVUldEBBAtHecetJkZUFtCDzoixgBjSqzibUlrRcRcSWsB81o6wT1oMzPa5KGxdwFHpetHAX9r6QT3oM3MqOw4aEm3AMOBNSTNBkYDFwJ/kXQc8BpwSEvlOECbmVHZi4QRcXgTu3YtpRwHaDMz8jkXR4s5aCVGSjonfT1A0jbZN83MrO20QQ66ZMVcJPw9sD1Q32VfCFyRWYvMzKqgtkZFL22lmBTHthExRNI0gIh4X1LnjNtlZtamcpjhKCpAL5VUSzqoWlJfYHmmrTIza2N5fCZhMSmO3wJ3Av0knQ88AlyQaavMzNpYJefiqJQWe9ARcbOkJ0mGhwjYPyKey7xlZmZtqF0+8krSAGAxcHfhtoh4PcuGmZm1pRzG56Jy0PeS5J8FdAHWBV4ANs2wXWZmbaotR2cUq5gUx9cKX0saAvwosxaZmVVBu0xxNBQRUyVtm0VjCv3nvwuyrsLaodVPO6HaTbAc+nja5a0uI48zxxWTgz6t4GUNMASYk1mLzMyqoL32oHsUrC8jyUnfnk1zzMyqI4cp6OYDdHqDSo+IOKON2mNmVhXt6iKhpLqIWCZpWFs2yMysGnIYn5vtQf+HJN88XdJdwG3AovqdEXFHxm0zM2szOUxBF5WD7gK8C3yDL8ZDB+AAbWYrjTzOxdFcgO6XjuCYwReBuV6LT6M1M2tP2tswu1qgO43PwucAbWYrlRx2oJsN0HMj4udt1hIzsypqV6M4yOf81WZmmchhfG42QJf09Fkzs/YsjxcJm8yLR8R7bdkQM7NqquSE/ZJOlTRT0gxJt0jqUk6b8njh0syszdWo+KU5kvoDJwFDI2IwyYCLw8ppU8mz2ZmZrYxU2ctudUBXSUuBVSlzgjkHaDMzoK5C+YSIeFPSJcDrwMfA+IgYX05ZTnGYmZFMN1rCMkrSlIJlVEE5qwP7kTx96stAN0kjy2mTe9BmZpQ2zC4ixgBjmti9GzArIuYDSLoD2AEYW2qbHKDNzKjonYSvA9tJWpUkxbErMKWcghygzcyo3DjoiHhC0l+BqSQPOZlG073tZjlAm5kBtRW8IhcRo4HRrS3HAdrMDKjJ4ewWDtBmZrS/2ezMzDqM9jZZkplZh5HHyZIcoM3McIrDzCy32tuE/WZmHUYe571wgDYzI5mLI28coM3MyOcz/hygzczwKA4zs9zKX3h2gDYzA6DGozjMzPLJozjMzHLKozjMzHIqf+HZAdrMDHAP2swst2pzGKAzzYtL2kdSHnPvZmYrUAlLW8k6eB4KvCTpYkkbZVyXmVnZpOKXtpJpgI6IkcCWwCvA9ZIekzRKUo8s6zUzK1UNKnppuzZlLCI+BP4K/BlYCzgAmCrpxKzrNjMrVofrQUvaV9KdwESgE7BNROwJbA6cnmXdZmalUAn/2krWozi+A/w6IiYVboyIxZKOy7huM7Oi5XEUR6YBOiKOambfA1nWbWZWikrGZ0m9gKuBwUAAx0bEY6WWk3WK40BJL0laIOlDSQslfZhlnWZm5ahwDvo3wH0RsRFJSve5ctqUdYrjYmCfiCircWZmbaVSuWVJPYGdgKMBImIJsKScsrIexfG2g7OZtQc1Kn5JhwtPKVhGFRS1LjAfuE7SNElXS+pWTpsy6UFLOjBdnSLpVmAc8Gn9/oi4I4t6zczKVcoTVSJiDDCmid11wBDgxIh4QtJvgJ8A/7fUNmWV4tinYH0xsHvB6wAcoM0sVyo4fG42MDsinkhf/5UkQJcskwAdEccASBoWEY8W7pM0LIs6VxY/GjaArdbuyYJPlnHauCQ71L1zLacOX5d+PTozb+ESLp04i0VLPqtyS60tXTl6BHvuNJj57y1k6MEXfL79h4ftzPcP2ZHPlgf3/WsGZ//mb1VsZftWqQeqRMRbkt6QtGFEvADsCjxbVpsq06Qm/a7IbZZ66OX3+OWEl1fYtv9mX+KZuQs58fZneWbuQg7YbM0qtc6q5aa7H2e/469YYdtOQzdg7+FfY5tDL2Srg87nshs9crU1KnyjyonAzZKeBrYALmj+8MZllYPeHtgB6CvptIJdqwG1WdS5snju7Y/o273zCtu2HtCT0f94EYCJL7/LeXsOYuyUOdVonlXJo1NfYcBavVfYNurgHbnkugksWboMgPnvf1SNpq00KjkOOiKmA0NbW05WPejOQHeSPwA9CpYPgYMyqnOl1atLHR98nPwSfvDxMnp18TTeBut/tR/DtlyPSTeewfirT2arTQZUu0ntWh6nG80qB/0w8LCk6yPitWLPS4eqjALY8sizGTj8wBbO6Jii2g2wXKirraF3z27sdOQlDN30q4y9+Fg23vvcajer3eowt3pLups0jjT2GJmI2Lex8wqHrhx03VTHodQHnyyjV9ekF92rax0LPllW7SZZDrz59geMe2A6AFNmvsby5cEaq3fnHac6ypO/+JzZMLtLMiq3Q5ry+gKGr9+Hcc+8zfD1+zD59QXVbpLlwN0Tn2bnrQcxacpLrD+gH5071Tk4t0JbzlJXrCxTHFaGU3Zeh02/1IMeXeq46pDB3DptLnc+8xanD1+XXQf1Yf5HS7j0oVnVbqa1sRt+dTQ7brUBa/Tqzsv3/YJfXPl3bhj3GFedO4Ipt/2UJUs/43vn3FTtZrZrOcxwoIjsMgmSNgB+BWwCdKnfHhEDWzrXKQ5rzL2/vbbaTbAc+nja5a0Or5NfXVB0zNl6YM82CedZj4O+DvgDsAzYBbgRGJtxnWZmpcvhMI6sA3TXdN5nRcRrEXEu8O2M6zQzK1mNVPTSVrIeUPuppBqSJ3ufALxJMj7azCxXcpiCzrwHfTKwKnASsBUwEmjyKStmZlWTwxRH1o+8mgwgaXn9BEpmZnmUx2F2WT/yantJzwLPp683l/T7LOs0MytHhR95VRFZpzguA74FvAsQEU+RPArGzCxX8higM591JyLeaHC7tycyNrPcyWOKI+sA/YakHYCQ1InkoqGfUWhmuZPHOwmzTnH8ADge6E8yxG6L9LWZWa7kcBBH5qM43gFGZFmHmVlF5LAHndV0o7+jmWmLI+KkLOo1MytXR8pBTylYPw8YnVE9ZmYVUamHxlZSVtON3lC/LumUwtdmZrnUUQJ0A5421MxyryOlOMzM2pU8DrPL6iLhQr7oOa8q6cP6XUBExGpZ1GtmVq5Kx2dJtSTX496MiL3LKSOrHHSPLMo1M8tM5XvQ9Tfmld0hzfpGFTOzdqGSE/ZL+grJw0mublWbWnOymdnKopQ7CSWNkjSlYBnVoLjLgDOB5a1pky8SmplBSSmOiBgDjGm0GGlvYF5EPClpeGua5ABtZkZFh9kNA/aVtBfQBVhN0tiIGFlqQU5xmJlRufmgI+KsiPhKRKwDHAY8WE5wBvegzcyADjQO2sysvcniTsKImAhMLPd8B2gzM9yDNjPLrRzGZwdoMzNwD9rMLMfyF6EdoM3M6EAT9puZtTdOcZiZ5ZQn7Dczy6v8xWcHaDMzyGV8doA2MwPnoM3Mcks5jNAO0GZmOMVhZpZbOexAO0CbmYGH2ZmZ5ZZ70GZmOeUAbWaWU05xmJnllHvQZmY5lcP47ABtZgbkMkI7QJuZ4Ry0mVlu5XHC/ppqN8DMLBdUwtJcMdLakh6S9KykmZJOLrdJ7kGbmVHRFMcy4PSImCqpB/CkpAkR8WypBTlAm5lRuWF2ETEXmJuuL5T0HNAfKDlAKyIq0yrLjKRRETGm2u2wfPHPRfVIGgWMKtg0prH/C0nrAJOAwRHxYcn1OEDnn6QpETG02u2wfPHPRb5J6g48DJwfEXeUU4YvEpqZVZikTsDtwM3lBmdwgDYzqyglj2a5BnguIi5tTVkO0O2D84zWGP9c5NMw4AjgG5Kmp8te5RTkHLSZWU65B21mllMO0GZmOeUAXUGSPkvzTTMlPSXpdEk16b6hkn5b7TbWk/RRtdvQUTX83ks6WtLlZZY1XNI9Bes7FOy7XtJBrWutVZPvJKysjyNiCwBJ/YA/AasBoyNiCjClim2zld9w4CPg31Vuh1WIe9AZiYh5JHcanaBEYU9n54Kru9PS+/WR9GNJkyU9Lem8+rIkjZP0ZNozH5Vuq017SDMkPSPp1HT7epLuS4//l6SN0u3rSnosPfaXbf39sOJI6ivp9vTnYLKkYen2bdL/v2mS/i1pwwbnrQP8ADg1/bnaMd21U3r8q/W9aUk3Stq/4NybJe3XJm/QShMRXiq0AB81su0DYE2S3s096ba7gWHpeneSTzK7kwybEskfznuAndJjeqdfuwIzgD7AVsCEgnp6pV8fADZI17cFHkzX7wKOTNePb6ytXtrs5+QzYHrB8jpwebrvT8DX0/UBJGNpIfkkVpeu7wbcnq4X/lydC5xRUM/1wG3pz9MmwMvp9p2Bcel6T2BWfdle8rU4xVEdjwKXSroZuCMiZkvanSRIT0uP6Q5sQHIf/0mSDki3r51ufwEYKOl3wL3A+PTW0h2A2/TFzC+rpF+HAd9J128CLsrqzVmLPk+FQZKDBupv2d4N2KTg/2+19P+1J3CDpA2AADoVWde4iFgOPCtpTYCIeFjS7yX1JfmZuD0ilrXyPVkGHKAzJGkgSW9pHrBx/faIuFDSvcBewKOSvkXSc/5VRFzVoIzhJL+020fEYkkTgS4R8b6kzYFvkXy0PQQ4Bfig8Je/AQ96z78aYLuI+KRwY3oR8aGIOCBNZ0wssrxPC4spWL8RGAkcBhxTdmstU85BZyTtnVxJ8tE1GuxbLyKeiYiLgMnARsD9wLFpbwlJ/dMLjT2B99PgvBGwXbp/DaAmIm4HfgYMiWS2rFmSDk6PURrEIem1H5auj8junVsrjQdOrH8haYt0tSfwZrp+dBPnLgR6FFnP9SR/0Iky5im2tuEAXVld64fZAf8k+WU7r5HjTkkv7j0NLAX+ERHjSfKPj0l6BvgryS/bfUCdkjllLwQeT8voD0yUNB0YC5yVbh8BHCfpKWAmUH/x52Tg+LTs/pV801ZRJwFD0wvFz5J8OgK4GPiVpGk0/cn3buCABhcJGxURbwPPAddVqN2WAd/qbdYBSVoVeIbkk9eCarfHGucetFkHI2k3kt7z7xyc8809aDOznHIP2swspxygzcxyygHazCynHKAtE/piZr8Zkm5LRw2UW9bns7JJulrSJs0cu8KMbiXU8d90bLlZbjhAW1Y+jogtImIwsIQvxvMCIKmsu1gj4nst3FgxnOR2d7N2zwHa2sK/gPXT3u2/JN1FMjdEraT/KZjB7/vw+R2Ql0t6QdI/gX71BUmaKGlour6HpKlK5t5+oLEZ3ZqZHa6PpPFKZgi8mhVvgzbLBc/FYZlKe8p7ktwRCTAEGBwRs5RMnbogIraWtArJvCTjgS2BDUlmYFsTeBa4tkG5fYE/ksz4N0tS74h4T9KVJDP1XZIe9yfg1xHxiKQBJLfUbwyMBh6JiJ9L+jZwXKbfCLMyOEBbVrqmt6FD0oO+hiT18J+ImJVu3x3YTF889aMnyUx9OwG3RMRnwBxJDzZS/nbApPqyIuK9JtrR1OxwOwEHpufeK+n98t6mWXYcoC0rK0ypCZAGyUWFm4ATI+L+BseV9Yj6JjQ1O1wFqzDLhnPQVk33Az+U1AlA0iBJ3UjmwD40zVGvBezSyLmPkzwtZN303N7p9oYzujU1O9wk4Lvptj2B1Sv1pswqxQHaqulqkvzyVEkzgKtIPtXdCbyU7rsReKzhiRExn+SRYnekM/fdmu5qOKNbU7PDnUcS4GeSpDpez+g9mpXNc3GYmeWUe9BmZjnlAG1mllMO0GZmOeUAbWaWUw7QZmY55QBtZpZTDtBmZjn1/wFDmL7xL76sIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(rounded, y_test)\n",
    "labels = ['Diseased', 'Healthy']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAABJpklEQVR4nO3deXzcV3Xw/8+Z0YxG+y5vki3JS7zEduw4DiELIUBIIDgtUEigkHRLadlaePoQ+mqhhFJ+9GlpS5u+HihPSmmBkLI6CwQTUpJAEi+J7cRbbMu79l0zWkYzc39/zPc7Go1mNCNpvpJHOu/XSy9L35mR71jynLnn3HuuGGNQSimlErnmewBKKaUuTxoglFJKJaUBQimlVFIaIJRSSiWlAUIppVRSGiCUUkolpQFCqRkSkQYRMSKSl8F97xWR5+ZiXEpliwYItSiIyFkRCYpIdcL1l60X+YZ5Gtq0Ao1Sc0kDhFpMzgB321+IyGagcP6Go9TlTQOEWkz+E/hg3Nf3AN+Mv4OIlInIN0WkU0TOichfiIjLus0tIn8nIl0i0gy8Pclj/5+ItIrIJRH5axFxz2bAIrJcRHaLSI+InBKRP4i7baeI7BeRARFpF5EvW9d9IvJfItItIn0isk9ElsxmHGpx0gChFpMXgFIR2WC9cN8F/FfCff4ZKAOagDcQDSi/Y932B8AdwDZgB/DuhMd+AwgBa6z73Ar8/izH/DBwEVhu/X1/IyK3WLf9E/BPxphSYDXwiHX9Hus51ANVwIeA4VmOQy1CGiDUYmPPIt4CHAMu2TfEBY1PG2MGjTFngb8HPmDd5T3APxpjLhhjeoAvxj12CfA24E+MMQFjTAfwD9b3mxERqQeuBz5ljBkxxhwEvs74LGgMWCMi1cYYvzHmhbjrVcAaY0zYGHPAGDMw03GoxUsDhFps/hN4H3AvCekloBrwAOfirp0DVlifLwcuJNxmW2U9ttVK6/QBXwVqZzHW5UCPMWYwxXh+D1gHHLfSSHdY1/8TeBJ4WERaRORvRcQzi3GoRUoDhFpUjDHniBar3wb8IOHmLqLvvlfFXVvJ+CyjlWjaJv422wVgFKg2xpRbH6XGmE2zGG4LUCkiJcnGY4w5aYy5m2gQ+hLwPREpMsaMGWM+Z4zZCLyeaFrsgyg1TRog1GL0e8AtxphA/EVjTJhoHv8LIlIiIquATzBep3gE+JiI1IlIBXB/3GNbgZ8Bfy8ipSLiEpHVIvKGaYwr3yow+0TERzQQ/Br4onVtizX2/wIQkd8WkRpjTATos75HRETeKCKbrZTZANGgF5nGOJQCNECoRcgYc9oYsz/FzR8FAkAz8BzwbeAh67Z/I5q6OQS8xOQZyAcBL3AU6AW+ByybxtD8RIvJ9sctRJflNhCdTfwQ+Kwx5ufW/W8DjoiIn2jB+i5jzDCw1Pq7B4jWWX5JNO2k1LSIHhiklFIqGZ1BKKWUSkoDhFJKqaQ0QCillEpKA4RSSqmkFkz3yOrqatPQ0DDfw1BKqZxy4MCBLmNMTbLbFkyAaGhoYP/+VCsXlVJKJSMi51LdpikmpZRSSWmAUEoplZQGCKWUUklpgFBKKZWUBgillFJJaYBQSimVlAYIpZRSSWmAyDFnugI8d7JrvoehlFoENEDkmH99+hSfeOTgfA9DKbUIaIDIMV3+UYaC4fkehlJqEdAAkWN6AkGGx8LoQU9KKadpgMgx3YEg4YhhLKwBQinlLA0QOaYnEARgeEzTTEopZ2mAyCEjY+FY/WFEA4RSymEaIHKIPXsAGNZCtVLKYRogcsiEAKEzCKWUwzRA5JBuDRBKqTmkASKH9MYFiBFNMSmlHKYBIofoDEIpNZc0QOSQnsBo7HMNEEopp2mAyCG6ikkpNZc0QOSQbn+Q6mIvoPsglFLO0wCRQ3qHgiwvLwA0xaSUcp6jAUJEbhOREyJySkTuT3Gf94jIURE5IiLfjrt+j4ictD7ucXKcuaI7EGSFHSCCkXkejVJqoctz6huLiBt4EHgLcBHYJyK7jTFH4+6zFvg0cL0xpldEaq3rlcBngR2AAQ5Yj+11ary5oCcQpLo4H2+eS2cQSinHOTmD2AmcMsY0G2OCwMPAnQn3+QPgQfuF3xjTYV1/K7DHGNNj3bYHuM3BsV72QuEIfUNjVBZ5KfC4tQahlHKckwFiBXAh7uuL1rV464B1IvIrEXlBRG6bxmMRkftEZL+I7O/s7Mzi0C8/fcNjAFQVRwOErmJSSjltvovUecBa4GbgbuDfRKQ80wcbY75mjNlhjNlRU1PjzAgvE/YS14pCLwVet6aYlFKOczJAXALq476us67FuwjsNsaMGWPOAK8RDRiZPHZR6fZHA0RVkRefRwOEUsp5TgaIfcBaEWkUES9wF7A74T4/Ijp7QESqiaacmoEngVtFpEJEKoBbrWuLlj2DqCz2UuBxaQ1CKeU4x1YxGWNCIvIRoi/sbuAhY8wREXkA2G+M2c14IDgKhIE/M8Z0A4jI54kGGYAHjDE9To01F9htNiqLrBST1iCUUg5zLEAAGGOeAJ5IuPaZuM8N8AnrI/GxDwEPOTm+XNITiBapKwqjReq+obF5HpFSaqGb7yK1ylBPYJRSXx4et0trEEqpOaEBIkd0B4JUFecDRPdBaIpJKeUwDRA5oicQpLIo2qhPl7kqpeaCBogcMSFAaIpJKTUHNEDkiJ5AkMrCaIDwedyMjEWIRMw8j0optZBpgJjCA48e5ZF9F9Lf0WHGGHqHglQWj6eYAEZD2tFVKeUcR5e55rKOwRH+/ddnqC3J553bV5Dnnr9YOjASYixsqIpLMUH0TAg7WCilVLbpDCKFp451YAy0D4zyy9fmtxFgbBd1kgChlFJO0QCRwp6j7dRVFFBdnM/D85xmSgwQPmvWoLuplVJO0gCRRGA0xHOnurh141LefXUdvzjeQcfAyLyNJ9UMQvsxKaWcpAEiiWdPdhIMRXjLxiW895p6whHD9166OG/jie/DBJpiUkrNDQ0QSfzsaDvlhR6uaaigsbqIaxsr+e6+C0RbR8297oDd6tvaSe2N/tg0xaSUcpIGiAShcIRfHO/glitqYyuX7tpZz7nuIV5onp+Gsr2BIAUed2zFkk9nEEqpOaABIsH+c730DY3x5o1LYtduv3IZJb48vrvv/LyMqTtuFzVoDUIpNTc0QCTYc7Qdr9vFTevGjzD1edz85rYVPPFqG/3z0Ga7JzFA6CompdQc0AARxxjDnqPtvH5NFcX5E/cQvveaeoKhCD86OPcnn04KEJpiUkrNAQ0QcV5r93O+Z4i3xKWXbJuWl7F5RRnf2Xt+zovV3f5gbBc1aA1CKTU3NEDE2XO0DYA3b5gcICA6izjeNsgrl/rncljRPkxxASI/z4UIeiaEUspRGiDi7Dnaztb6cpaU+pLevuuq5fg8rjndWT0yFmYoGKYiLkCIiLb8Vko5TgOEpX1ghEMX+7k1SXrJVurz8PbNy9l9sIWhYGhOxjW+B8I74boGCKWU0zRAWPYcbQdIWn+Id9fOevyjIR4/3DoXw6LHP7HNhs3ncTMc1HbfSinnaICw7DnazqqqQtbWFk95vx2rKmiqKeKR/XOTZuoZsmYQxYkBwqX7IJRSjtIAAfhHQzx/upu3bFiCiEx5XxHhzq0r2H+uly7/qONjG+/DlD/hup5LrZRymgYI4JcnOgmGI2nTS7Y3bajFGPjF8Q6HRxZd4grEjhu1FXjculFOKeUoDRBEl7dWFHq4elVFRvfftLyUZWU+njrW7vDIopvk8lxCacHEjXs+LVIrpRzmaIAQkdtE5ISInBKR+5Pcfq+IdIrIQevj9+NuC8dd3+3UGMfs5nzrl2R8rKiIcMv6Wp492eV4HaAnEKSiyDsp9VXgcWsNQinlKMcChIi4gQeB24GNwN0isjHJXb9rjLnK+vh63PXhuOu7nBpnx+AoDdVF3Lops/SS7c0bljAUDPNCc7dDI4vqCQQnLXEFrUEopZzn5AxiJ3DKGNNsjAkCDwN3Ovj3zciK8gJ2f+QG3rpp6bQed93qKgo8bp465mwdIrEPk01rEEoppzkZIFYA8WtBL1rXEr1LRA6LyPdEpD7uuk9E9ovICyLyG8n+AhG5z7rP/s7OzuyNPAM+j5sb1lbz1LF2R3sz2SmmZH+/ziCUUk6a7yL1o0CDMWYLsAf4j7jbVhljdgDvA/5RRFYnPtgY8zVjzA5jzI6amprEmx335g21tPSPcKx10LG/o3uKFJPWIJRSTnIyQFwC4mcEdda1GGNMtzHG3kzwdeDquNsuWX82A/8DbHNwrDPyxvW1AI6tZgqFI/QPj6VMMY2FDWNh3U2tlHKGkwFiH7BWRBpFxAvcBUxYjSQiy+K+3AUcs65XiEi+9Xk1cD1w1MGxzkhtiY+t9eX83KH9EL3W4URJZxB6qpxSymGOBQhjTAj4CPAk0Rf+R4wxR0TkARGxVyV9TESOiMgh4GPAvdb1DcB+6/rTwP9njLnsAgTAWzbUcuhCHx2DI1n/3j1Wo76kNQivngmhlHJWXvq7zJwx5gngiYRrn4n7/NPAp5M87tfAZifHli1v2rCEv/vZazx9vIP3XrMyq9+7O9ZmY4oZhDbsU0o5ZL6L1Dlv/dISVpQX8HMHlrv2xFp950+6TY8dVUo5TQPELIkIb9pQy7MnO7NeD+gNJG/1DVDgjf7oNEAopZyiASIL3rRhCSNjEX59uiur39c+LKii0DPptti51LpZTinlEA0QWfC6pkqKvO6sp5l6AkHKCjxJe0TpKiallNM0QGRBfp6bG9fW8ItjHVndVZ1qkxxEN8qBppiUUs7RAJElb9pQS9vACEdaBrL2PXtT9GGCuCK1ppiUUg7RAJElb1xfiwj8PIu7qlM16oO4FFNIA4RSyhkaILKkujifbfXlWe3u2j1FgIhtlNMZhFLKIRogsujmK2p55VI/gyNjs/5expiMUkxapFZKOUUDRBatKC8Axs+Rno2B4RChiEkZIDxuF3ku0SK1UsoxGiCyqLI4+mJu71+YjZ4haxd1cfIAAfahQdpqQynlDA0QWWQvSe3JRoCI9WGa3GbD5tNjR5VSDtIAkUWVsQAxmuae6dlpqsrCqWcQWoNQSjlFA0QW2QEiKykmuw9T2hSTBgillDM0QGRRoTcPn8cVa7I3G7EaRIoiNWiKSSnlLA0QWVZVlJ+dGYQ/SKHXHWvKl0yBx6UBQinlGA0QWVZZ5M1SkTr1Hgib1iBm5i9+9ArfevHcfA9DqcueBogsy1aAmGoXta3AqzWI6eobCvLtF8/zPyc653soSl32NEBkWVWRNysb5br8o2kDhM+jNYjp+tWpbiKGrOx2V2qh0wCRZdmYQYyMhTnZ7ueKJSVT3k9TTNP37MnozGFwJDTPI1Hq8qcBIssqi70Mj4Vnlfp55VI/wXCEHQ2VU95Pl7lOjzGGZ17TAKFUpjRAZJm9sa17Fpvl9p3tAeDqVRVT3q/AWuaazUOKFrLTnQFa+kco9Lo1xaRUBjRAZJldN+gNzPwF6MDZXlbXFGVUg4gYCIa1H1Mm7PTSmzYswT8a0sCqVBoaILKsqnh2M4hIxLD/XC87Vk2dXoK4lt/asC8jz7zWSWN1ERuWlTAWNoyG9N9NqalogMgyu7neTAvVpzv99A+PsaNh6vQS6LnU0zEaCvNCcw83ra2mJD8PgAFNMyk1JUcDhIjcJiInROSUiNyf5PZ7RaRTRA5aH78fd9s9InLS+rjHyXFmU+UsO7ruO9sLkLZADXHnUmuASOvA2V6Gx8LcuLaGEp8H0EK1UunkOfWNRcQNPAi8BbgI7BOR3caYowl3/a4x5iMJj60EPgvsAAxwwHpsr1PjzZZSXx4et8y43cb+cz1UF3tpqCpMe1+7DYeuZErvmZNdeNzCdaureKG5G9AAoVQ6Ts4gdgKnjDHNxpgg8DBwZ4aPfSuwxxjTYwWFPcBtDo0zq0SEikIvPTPcLLf/bC9Xr6pARNLeV1NMmXvmtU62r6ygKD8vbgahKSalpuJkgFgBXIj7+qJ1LdG7ROSwiHxPROqn81gRuU9E9ovI/s7Oy6d1QmWRd0YziI6BEc73DHFNBukl0HOpM9U5OMrR1gFuWlcDQIkvOnHWGYRSU5vvIvWjQIMxZgvRWcJ/TOfBxpivGWN2GGN21NTUODLAmYjupp7+Kqb956IZtHT7H2wFmmLKyHOnom8eblqbGCB0BqHUVJwMEJeA+riv66xrMcaYbmOM/Ur6deDqTB97OZtpu439Z3vxeVxsWl6W0f0LvNEfn6aYpvbsa11UFnnZtLwUQIvUSmXIyQCxD1grIo0i4gXuAnbH30FElsV9uQs4Zn3+JHCriFSISAVwq3UtJ1TNNECc62FrXTnevMx+LD5dxZSWMYZnTnZxw5pqXK5oXac4X1NMSmXCsVVMxpiQiHyE6Au7G3jIGHNERB4A9htjdgMfE5FdQAjoAe61HtsjIp8nGmQAHjDG9Dg11myrLMpnYCTEWDiCx53Zi/1QMMSRlgH+6A2rM/57tAaR3rHWQbr8o9y4tjp2ze0SirxuDRBKpZFRgBCRImDYGBMRkXXAeuAnxpgpk7jGmCeAJxKufSbu808Dn07x2IeAhzIZ3+XGPke6NxCkttSX0WMOnu8jHDFcncEGOVtsFZPWIFKy22vYBWpbic+jNQil0sg0xfQM4BORFcDPgA8A33BqULnOPkd6OiuZ9p/rRQS2r8w8QPjyNMWUzjMnO7liSQlLEgJ1iS9PZxBKpZFpgBBjzBDwTuBfjTG/BWxybli5bSa7qfed7eGKJSWUFXgyfozLJeTn6bnUqQwHw+w708tN66on3Vbiy2NwVGcQSk0l4wAhItcB7wcet665nRlS7pvuDCIcMbx8vi+j/kuJCrxuRjTFlNQLZ7oJhiPcuHbyEuhoiklnEEpNJdMA8SdEawU/tArNTcDTjo0qx1XYMwh/ZnshjrcN4B8NZdTBNVGBHjua0rOvdZGf52Jn4+R/V00xKZVeRkVqY8wvgV8CiIgL6DLGfMzJgeWyikIvIpmnmA6csxv0zWAG4XEzPKZtq5N59mQnOxsrY8uB42mRWqn0MppBiMi3RaTUWs30KnBURP7M2aHlLrdLKC/w0DOUWYDYf7aXpaU+VpQXTPvv8umxo0l1+Uc52eHnhjWT6w8Qbao4oDMIpaaUaYppozFmAPgN4CdAI9GVTCqF6eym3n+2hx0NmTXoS1Tgdes+iCSOtw4CsHlF8l3pJb48gqEIoyH9t1MqlUwDhEdEPEQDxG5r/4Oe1ziFqqJ8ujPo6Hqpb5iW/hF2ZNh/KZHWIJI73jYAwBVLS5Lebu+m9ussQqmUMg0QXwXOAkXAMyKyChhwalALQaYziP1noxvEMzkgKBlNMSV3rHWQ2pJ8qorzk96u/ZiUSi+jAGGM+YoxZoUx5m0m6hzwRofHltMqizMLEAfO9VLkdbM+xTvddDTFlNzxtgHWLytNebu2/FYqvUyL1GUi8mX77AUR+XuiswmVQlWRl96hIJHI1Jm4fWd72baygrwMezYlKvDoRrlEoXCEkx3+KYOuHhqkVHqZvio9BAwC77E+BoB/d2pQC0FFoZeIgb7h1C9AQ8EQJ9oG2D7D+gNoDSKZs90BgqFImgARnUHoSialUsu0m+tqY8y74r7+nIgcdGA8C0ZVsd1uYzTWeiNRc2eAiGHG6SUAn1drEImOWSuY1i9NnWIq1RmEUmllOoMYFpEb7C9E5Hpg2JkhLQzj/ZhSvwCd7vQDsKa2eMZ/T4HHzWgokjaVtZgcbxsgzyWsrk2dBdUahFLpZTqD+BDwTRGxF5X3Avc4M6SFYTxApG63carDj9slNFTNvJwTOxMiFKbQ69jxHln3d0+eYNvKct60YUnWv/fx1kGaaorIz0vdLqxYA4RSaWW6iumQMWYrsAXYYozZBtzi6MhyXFVRdHnlVA37TnX4WVVZmPEJcsnk4pkQxhi+9kwz33/poiPf/3jb4JTpJQCP24XP48KvHV2VSmlar0zGmAFrRzXAJxwYz4JRURTNcfdMsVnudKefppqZp5cgN48d7QkECYYjnO8Zyvr3HhgZ41LfMOuXpa/raEdXpaY2mzOpp98XYhHJz3NTkp+XcgYRCkc40xWYVf0BxgNELu2FaBsYAeB8d/YDxIm2aIF6Q5oZBGhHV6XSmU2A0KpoGlNtljvfM8RY2Mw6QNg1iOFg7nR0bbcCxMBIiP6h7KZ4jrdGJ7iZziAGdBXTotXSN8xXnjqpCzymMGWAEJFBERlI8jEILJ+jMeasisLUAeJ0ZwCA1TWz229YkIMpptb+kdjnF3qzO4s41jZIqS+PpRmcBV6qM4hF7YlXWvnyntdo7grM91AuW1MGCGNMiTGmNMlHiTEmd5bMzJOqIm/KFNOpjugS19WznUF4oz/CXAoQ7XEBItt1iBNtg6xfVppRZ9xoiklnEItVl1UfbLaWm6vJZpNiUmlEG/YlX+Z6qsPPktL82IatmYoVqXNoFVPbwAglVjfVbAaISMRwom2QDRluPCzJ1yL1YtZtnfioM4jUNEA4qLLYS29gDGMm5zhPd/pZPcsVTBC3DyKHZhBtA6M01hRRUejJaoC41DeMfzQ0ZZO+eFqkXtzs9O+ZTg0QqWiAcFBVkZdgOIJ/dOKLkDGG0x3+WReoIW4fRC4FiP5hlpT6WFlZyIUsBohjdoE60xmEz8PwWJixcO4U+FX2dFkBorlLU0ypaIBwUKW1WS6xUN0xOMrgaCg7ASIXU0z9Iywr81FfWZjVGcRxa4nruiWZBQh7N3VgVGcRi1EsxaQziJQcDRAicpuInBCRUyJy/xT3e5eIGBHZYX3dICLDInLQ+vi/To7TKVVWu43EQnWsQJ2FFFOubZQbDoYZGAnFZhCXeocJZekd/Im2QVZVFVKUn9n6Ce3HtLj1BIJ43EJ3IJj15dYLhWMBQkTcwIPA7cBG4G4R2ZjkfiXAx4EXE246bYy5yvr4kFPjdFKsH1PCbupsNOmz5ee5EMmdGoS9SW6pFSBCETNh2etsHGsbmFZn3NJYy299cVhshoIhhoJhttSVA5pmSsXJGcRO4JQxptkYEwQeBu5Mcr/PA18CsvMqcRkZb9g3eQZRkp9HbUny4zCnQ0SiZ0LkSIqptT/aBHhpWTRAAFmpQwwHw5ztCqTtwRRPjx1dvOzz4nc0RM9i0TRTck4GiBXAhbivL1rXYkRkO1BvjHk8yeMbReRlEfmliNyY7C8QkfvsU+46OzuzNvBsqZwixdRUW5zRWv1M5NKhQfYu6qVWDQKys9T1ZMfgtM/W0BTT4mW/adtWX47bJTqDSGHeitQi4gK+DHwyyc2twEqra+wngG+LyKS3hsaYrxljdhhjdtTU1Dg74Bko9LrJz3NN2gtxutPPmizUH2y+HAoQbf3Rf4ulpT6WlfnIc0lWdlMftw8JynCJK+ixo4tZt/V/0q6FndG9EEk5GSAuAfVxX9dZ12wlwJXA/4jIWeB1wG4R2WGMGTXGdAMYYw4Ap4F1Do7VESJCVZF3wqFBAyNjtA+MZqX+YCvwunOmBtFubZIrys8jz+1iRUUB53tmf/bU8bZBCjzuWNoqEzqDWLzsFFN1cT5N1UWaYkrByQCxD1grIo0i4gXuAnbbNxpj+o0x1caYBmNMA/ACsMsYs19EaqwiNyLSBKwFmh0cq2OiDfvGZxCnYyuYZteDKV6u1SCWlo33SVqZpaWux9sGWLe0BLcr87TdeIDQGcRiY6d9q4q9NNUUcaYroE37knAsQBhjQsBHgCeBY8AjxpgjIvKAiOxK8/CbgMPWudffAz5kjOlxaqxOqizKn1Cktpv0ZXUGkUsppoHRCQGirmL2m+WMMRxrHci4xYYtP8+NN8/FoO6DWHS6/aP4PC4KvXk0VhczGorQ0q+nKCdytOGeMeYJ4ImEa59Jcd+b4z7/PvB9J8c2V6qKvBOagZ3q8ONxy7RSIen4vG76h3PjXXB7/whra6tjX6+sLKQnEGRwZCxWE5iuzsFReofGuGKaAQKgJF/bbSxG3YFg7NTHJms239wZoK4ie/8vFwLdSe2waMO+8RnEqQ4/DVVF5Lmz909f4HExkgMpplA4QsfgyIRW3ONLXWf+7u2YtYN6OktcbbPtx6RpidzU7Q9SXRxdZTgeIHQlUyINEA6rLPIyFAzHisjNndnpwRQvV1JMXf4gEcOkGgTMbqnribbp9WCKFz12dGazrzNdATZ+9qd85sev5swiARXVHRiNLUOvKc6nOD9PVzIloQHCYfF7IYKhCOd6hrIfILy5ESDid1HbsrFZ7njrIEtLfVRY/9bTMZsZxEvnehkZi/DN58+x61+e43jbQPoHqctCjz9IVXE0xSQiNNUUadvvJDRAOCy+3cbZ7gDhiMlKD6Z4Po87J1JMbf3jm+RsZYUeSn15s5pBHGsbzOiI0WRmc2jQSaue9O/3XkPv0Bi7/uVXPPTcmaTt3dXlwxhDVyBIVfH4Gwpd6pqcBgiH2Q37eoaCsSWul3uKKRIxhB3IrbfFtdmIt7Jq5ktdx8IRTnUMzqhADXaKaWYziJPtgzRVF/PG9bX89OM3ctPaah547Cj3/vs+OgeTHxSl5p9/NEQwFIn93wRorC7mUt+wpgoTaIBw2Hg/ptFYF9emLO6BgGiACEVM1s41+Oh3XuZPv3swK98rXtvAKB63UFk4MRW0srJwxrupmzsDjIUNG2ZQoIbZpZhOdvhZsyQa7KuK8/m3D+7g879xJS80d3PbPz7DkZb+GX1f5Sx70Yi9ignG/09qHWIiDRAOs38Ju/1BTnX6WVFeQKE3u6uLs31o0IFzvew7m/1tJ+0DI9SW+HAlbGarryzkYs/wjFYEPX2iA4BtK8tnNKYSnwf/aGjaM6bhYJgLvUOsjZsNiggfeN0qHvvoDfhHQ/zwpUtTfAc1X+yzqCvjU0xxS13VOA0QDistyCPPJfQEgtFjRrOcXoLxMyGyUYcIjIZoGxihtX9k0kl4s9XWPzIpvQTRGUQwHKF9cHoNfY0xPLLvAtc0VLCqamazMvts7EBwes/1dKcfY5IfTrR2SQn1s5gVKWfZM4jquBlEY7U9g9ClrvE0QDhMRKgo8tLtD3K6I5DVJn22giweGnS2e/wdVLbXhbcNJA8Q9dbmpPPd03tB3X+ul+auAL+1oz79nVOYaT8mO124NkXAr68o4GLvwt2Zm8u5evskufgidaE3j2VlPp1BJNAAMQeqiry82tLP8FiY1bXZrT9AdlNMZ7vGX6RPZzFAGGOiM4jS5DMImP5eiEf2XaDI6+btm5fNeFwz7eh6smOQPJeknLnUZ/m87ctJ//AY2z+/h5+80jrfQ5kRuw9TZcKy6KaaIk5rDWICDRBzoKLQy7HW6Bp5R2cQWUgx2VNst0ti75KzYWAkxPBYOGmAWF5egEumtxfCPxri8VdaecfW5RkfMZrMTGcQJ9v9NFQX4c1L/l+orqKAgZFQzrRAmY4LPUMMBcPsOdY+30OZkW5/kOL8vFhq1tZUXUxzp1+XKcfRADEHKou92DXQbC9xheyeS93cFWBZmY9VVYWc7sjs3ZQxJu2Lu31Q0JIkKSZvnotlZQXTmkE8friFoWB4VuklmHlH15Md/pTpJRhPm11cgHWIDqtW9GJzTvbPpDswOiG9ZGusLmJwJDTpgK/FTAPEHLDXW5cXeiZNa7PBTjGNjs1+meuZrgCN1UWsqSnmVIYppp8dbeem//M0J9sHU97HPnd6WZIAAdNv+/3dfRdYU1vM9hmuXrLN5NjRkbEw57oDUweILPSYuly1D0Rz+Jf6hnMyAHb7g0n/H+pKpsk0QMwB+5dxTU32jhmNl80itR0gVtcWc647kNHeigPnejEGnm/uTnmf9v7JbTbiRQNEZi+mpzoGeel8H+/ZUTfrf89SawYxMI0AcaYrQMTAmiQrmGx1FQXAAp1BDIxvAtx7JvdmEfGdXOPZHQ60ad84DRBzwJ5BOJFeguzVIHoDQfqGxmIziLGwyehdvb0hbP/Z3pT3sfsw1ZZO/o8J0d3UXf5RhjJYbvrI/ovkuYR3bq9Le990ZlKkPmnVZtYtSf3zLCvwUJKftyBXMrUPjlBhtUjJyQDhH411co23vLwAb55LN8vF0QAxByqtdyvZ7sFk83mjP8bZziDOWEtc7RkEjJ+Al4oxhiMt0QL8/ik217X2j1BV5CU/z530djslk+4FdSwc4QcvXeRNG2qpLk4ebKbD53GR55JppZhOtQ/ikvG188mICHULdCVTx8AIS8sK2NlYyYs5FiCMMfQEkqeY3C6hoaowdqiX0gAxJ5aVR9MqG5bNrB1EOvYMYrZr0890xgUIKx+brg7R0j9C39AYTTVFtPSPcKkv+Qt8+8AIS1KklyBuqWuavRC/ON5Blz/Ie2ZZnLaJCMW+PPzTCBAnrTM9UgU7W11FwYLcLNcxOEptST47Gys50xWgY2B6Gxzn08BwiFDExDq5JmqqLqZZN8vFaICYA9vqy/nvD13H9WuqHPn+viylmM50BXC7hPrKQkp8HpaU5qddyXTkUjS9dM91DUDqWUSqXdS2TPdCPLLvArUl+bxhXc2U95uO6XZ0fa19MKN0YX1FIRd7hxfcsslosM/n2sbo73MuzSK6rPPhk6WYABprijjfPUQoS33Ncp0GiDkgIlzTUOlIgRrA43bhccvsU0xdAVZWFuKxTrtbU5t+JdORlgFE4De3r6DQ6+bAueR1iHQziIpCD8X5U7f9bh8Y4ekTHbzr6rqsnshXkp95R9dgKMLZ7iHWTlF/sNVVFDAUDE84UTDXhSOGLn+Q2hIfm5aXUuR151QdoifFJjlbU3URoYjhwgKsHc2EBogFwpeFlt/N1gom2+qaYpo7pt44dKRlgMbqIkp9HravrEhaqB4NhekOBFMucQUrZ19RMGXO/vsvXSRiyFp6yTadjq72mR5ra9O3F48tdV1ALzbdgVHCEcOS0nzy3C6ubqjkxTOpV69dbmJtNpKsYgJo0pVME2iAWCAKPO5Z1SCMMZxNCBBraosZHA3RMcXZBkdb+rlyeRkAV6+q4HjbwKR0jb0sMtUSV9tUeyGMMfz3/ovsbKycsjg8EyU+DwMZpphOtls9mDKYQdRXLrylrvbPsqYk+rO8trGS19r9OTNLsju5JtsoB8Rqb7qSKUoDxAJR4HXPqgbRPjDK8FiYhoQZBKReydQbCNLSP8Km5dHi+46GCiIGXj7fN+F+bVPsoo5nB4hkM5YXmns40xXI+uwBonshMp1BnOwYRCSzFWl1FQtvs5y9i3qJtVz52sZKIHf2Q9iBrKIweYAoL/RSUejRlUwWDRALxGxPlbNXbjQlzCAg9Uome3nrJmsGsW1lBS6ZXKhuS7OL2rayqpDRUGTSaWyvXurno995iepiL2/bvDTTp5Sx6RSpT3b4WVlZOKmPTzLF+XlUFHoW1EomewZRa80GN9eVkZ/nypkA0e0fpazAk7KHFkTTTJpiitIAsUBEaxAzX3lhT6nj0ze1JfkU5+elnEHYG+TsGURxfh4blpWyP6FQbQeIqYrUMJ6zj08zPXuyk/d+9Xny89w8fN91WT9sCcYPDcpktdGp9ql7MCWqryxcUJvl7DYbNdYy0fw8N9tXVrD3bG7UIboCwQlHjSbTVF1Es6aYAA0QC0aBxz2rA4POdAbweVwT6gQiwuopVjIdaRlgeZmPirj/cNc0VPLy+b4JLTraBkYo8LhjbS1SSVzq+uODl/jdb+yjvrKQH/zx6x3biV7syyNiIJDm328sHKG5y8+aDArUtrqKAi4uoM1yHYMjVBZ5J7wD39lYydGWgYzrOPOpxx9MWX+wNdYU0Tk4Ou0GjguRowFCRG4TkRMickpE7p/ifu8SESMiO+Kufdp63AkReauT41wICryzSzGd6QrQUFU06TjQ1TVFKfdCHGnpZ6OVXrJdvaqC4bFwrL05jB8UlG6Z74ryAkSiOfuvP9vMxx8+yPaVFXz3D69LO/uYDbuja7rNcue6hxgLm+nNIKy9EDM5TvVy1D4Q3SQX79qmSiIGDkzRauVy0R0YTbmCydZUHf35aqHawQAhIm7gQeB2YCNwt4hsTHK/EuDjwItx1zYCdwGbgNuAf7W+n0phtjWIM12BWDfLeGtqi2kbGJn0bmooGKK5KxBLL9l2NFQAE/sytac4KCiRz+NmaamPb/z6DH/9+DHetnkp//G7Oykr8MzkKWUs035Mpzqi3WozWcFkq7OOU+30p14Jlks6ByfvZ9lWX4HHLbyQA8tdu/3BCWdRJ2P/TudKXcVJTs4gdgKnjDHNxpgg8DBwZ5L7fR74EhC/X/9O4GFjzKgx5gxwyvp+KgWfZ+armELhCOd7hmhIcjraeIfLie+mjrUOYgyTAsSysgJWlBew/9z4f67WNLuo49VXFtI7NMYHr1vFP9+9PaNi8GyVZNjR1V7iOp1Ul93VdaH0ZEo2gyjwutlaV37Zv6CGI4beoSDVaWoQ9ZWFXLmilEcP5+aJednkZIBYAVyI+/qidS1GRLYD9caYx6f7WOvx94nIfhHZ39nZmZ1R56gCr2vG+yAu9g4Tipik+wtiK5kSCtVH7QL1irJJj9nREN0wZ4whEjF0JHnXmcof37yaL75zM5/btQm3y5md54lKMzw06GSHn7qKgmkVyu2Dg9KtZDrV4WfP0cv7hLZIxNDpH036s9zZWMkrF/sz6sY7X/qGgkQMKfswxbtjy3IOXehbMIF9puatSC0iLuDLwCdn+j2MMV8zxuwwxuyoqcleb55cNJsUk51rTZZiWllZSJ5LJp1PfaRlgPJCD8uTzAx2NFTSMTjKhZ5heoaCjIVN2iWutpuvqOXunSsda0uSTKaHBqU7RS6Z2LkQafZC/N2TJ/jwt19iNDT7Mz2c0h0IEo6YpC3br22qIhQxvHSub+4HlqF0bTbi2eecP7bIZxFOBohLQPyupjrrmq0EuBL4HxE5C7wO2G0VqtM9ViWwA8RMGsM1x5a4Tn7x87hdNFQXTZpBHGkZYNPy0qQv5DtWWXWIcz0ZL3GdT5mcSx2OGE53+lk7xSFByfg8bmpK8qecQRhj2Hu2h2AowrHW1KfyOaWlbzij2Yu9Sa62ZPLP8upV0T0wl3PbjXS7qOPVVxZyVX05jx1ucXpYlzUnA8Q+YK2INIqIl2jRebd9ozGm3xhTbYxpMMY0AC8Au4wx+6373SUi+SLSCKwF9jo41pzn87oxBkZD098LcabLT1mBh4rC5MXg1TVFE2YQY+EIJ9oGYxvkEq1bUkKJL499Z3tjASLTGsR8yKRIfb5niGAoMqOltvUVBVPupj7dOd6q4uD5uV8J9MWfHOdD/3UgbYpyfJPc5BlEcX4eV64ou6w7u3YHpu7DlOiOLcs40jKwqFczORYgjDEh4CPAk8Ax4BFjzBEReUBEdqV57BHgEeAo8FPgw8aYy3fufRmYzZkQZ7oCNFQXpUzrrK4ptpZ4RoPPqQ4/wXBkUoHa5nYJ21dWcOBcT6zNRiarmOZLkdeNyNQzCPu87emmmCDacuNiX+oZhP2i6vO4ePlC37S//2wMB8M8daydcMRwLs1ZHONtNpL/LK9trOTghb5Zn0viFDsIZzKDAHj7FivNdGjxziIcrUEYY54wxqwzxqw2xnzBuvYZY8zuJPe92Zo92F9/wXrcFcaYnzg5zoXAPl3tO3svpLnnZGe7hia02Ei0praYUNwLyHiLjdQHIO1YVcFr7X5OtA3idgk1JbM//c0pIkJx/tTtNuxjRqebYoJo076WvpGUZwzsPdMTO+Pi4BwHiF8c72DIWv2Wrr1E4i7qRDsbqwiGIhyynkP/8BiHLvTx44OX+Ic9r/GTV+Y3n9/lDyKSug9TomVlBVzTULGo6xDZ71ug5sXtVy7lji3L+NJPj1PgcXHv9Y0ZPW5kLMylvuEpO6TaS11PdfhZU1vMkZZ+CjzupDUL246GaBO3nx5po6Y4f85WJM1Uqc/D4GjqGcSpDj/Ly3wU50//v0x9RSHhiKG1fyTWTsRmjOHF5h52NlayeUUZTx5pp9s/mtFKm2x49FALlUVeegLBtO0l2gcm76KOt7OhEhH4xCOHGB6bfA5GodfNDWurYym9udbtH6Wi0Dut38U7tizns7uPcLJ9cEZvDnKdttpYIPLcLv7hvVdx68Yl/NWjR/nO3vMZPe5s9+QeTIli51Nb7zCPtAywYVnJlP/RrqovJ88ldA6Opu3iejlIdybEyY5B1szwBcLu6pqsJ9OFnmHaBka4tqmKq+rLATh0sW9Gf890+UdDPH2ig11bl7O01DdppVoi+6jRVMoKPbxv50rqKwt466YlfPr29Xz1A1fzsz+9ie/e9zqGgmF+fHD+0jU9GfRhSnT75qW4hEW7J0IDxALicbv45/dt4w3ravjzH77CD1++mPYx8edQp1Kcnxd9AenwE4kYjrUMpCxQ2wq87tgeiaVJipqXm6k6ukYihlMzWOJqs8+FSLaSyV71c21jJZvrynC7ZFK7dKf8/Gg7o6EId2xZRlNN0aTNkIk6BkZiXVxT+cJvbubh+67ji+/cwh++YTVv3bSUdUtK2NlYyYZlpXz7xfPzdgRrdwZ9mBLVlvi4trGKxw63zGjcx9sG+P6B9P8PL1caIBaY/Dw3X/3A1VzXVMUnHznE42ne+TQn6eKazJraYk53+rnQO8TgaGjK+oPNXu66rKwgw9HPnxJf6mNHL/YOMzIWmXGAWFZWgEtI2rRv75keKgo9rKkpptCbxxVLSuYsQDx2uIVlZT62r6ygyVqpNtWLYLoZxFREhPddu5KjrQMcvtg/0yHPSlcGfZiSuWPrMpo7AzNagvzg06f5s+8dwj9F+vJypgFiAfJ53Hz9nh1cvaqCjz/88pRr3M90BagtyacoTW49utQ1wKuXJp4BMZVrrL5Ml/MeCNtUKaaTM+jBFM+bF+2SmyzFtPdsD9c0VMaaJG5bWc6hC32ON/frHxrjl6918vbNy3C5hKbqYgZHQrG9AokiERNNF85iNnjnVcsp8LgzTn9mW09g+jMIgNuvXIbbJTPaE3H4Yl+0kWGKs9ovdxogFqhCbx4P3XsNm1aU8eFvvcQLzck3MCUeM5rKmtpi/KMhfnG8gzyXsG5p+hfLaxurWFFewLaV5dMd/pybKsW092wPbpdMq813orrKwkkpprb+Ec51D7HTOpUNorWbwdFQ2nrAbD15tI2xsOGOrcuB8V30qVYy9QwFCUVM0k1ymSr1edi1dTm7D7XMeSvtsXCEvqGxGc0gKou8vH51FY8dbp1WmqlvKBhb+bf3Mt5AOBUNEAtYic/DN39nJ/WVBXz4Wy/R0jf5HWyqLq6J7JVMTx5pY01tMfl56ZvoVRR5+dX9t/C6pqrpD36O2SmmxBeAUDjCD1+6xBuvqJlVV9n6isJJm+Xs+kP8v8+2ldFZl9P7IR473Ep9ZQFb66IzwVhTxhQrmdrtY2NnWU+6+9qVDAXD/GiOi9W9Q1abjRnMIADesWU553uGeOVS5ukxO5WWSyfuJdIAscCVFXr46gd2MBqKTNot2z80RncgmPEMAqIrXzJJL+Wa4vw8QhHDSMKpfM+c7KRjcJR3Xz27s7DrKgpoHxyZ0Gtp75me2Cl8tqbqIkp9eY7WIXoCQX51qos7tiyPbY5cUV5Afp4r5QyiwzoGtmYWMwiArXVlbJyHYnW3lTpL18k1lbduWorHLdPaE2EHk3duX8GhC/2X7QbCqWiAWATW1Bbz5fds5fDFfj7z41dj/zHPdKfuwZSopiSfEqtOkUmBOtfEOrqOTkx9/Pf+i1QVebllfe2svn99ZSHGQEvfeFf7vWd62NFQMWG5sMslbK0vd3TD3E9fbSMcMdxh7RS2/97G6tQrmTqyNIMQEe6+diXHWgc4NINitTGGB58+xYm26RWMu2N9mGY2/rJCDzeureHxaaSZDl3oo6m6iDdvWEIwHJnzTZDZoAFikbh101I+essaHtl/kW+9GC0SnumKvlvMZAZhHz8KCzNAJOvo2hMI8vNj7fzmthVTHnKfifqEcyG6/aOc7PBPqD/Ytq2s4ETbAAGHVr48driFpuoiNi6b+HNsqkl9FrPdhykbO+J/46rlFHrdfOfF6RerT3X4+T9PnuCDD71Ia3/mZ33bfZgy6eSayh1blnGpb5iXMpzdHb7Yz5a6Mnasim4gfLE599JMGiAWkT958zreeEUNn3v0CAfO9XCmM4BLxs+CTsfOU29ckAFickfXH718ibGw4bd2zC69BNEiNYxvlttnnbh3bbIAUV9OxODIctCOwRFeaO7mji3LJvXeaqoujjUlTNQ+OEJFoSej2lM6JXHF6umeY/28tdiif3iM3/vG/oyDaCzFNMMaBMBbNi7B63bx5JG2tPftGBihbWCELXXllBV6WL+0lL1nc69QrQFiEXG7hH987zaWlxfwof96iX1ne6mrKMz43fEHrlvFp29fP2+tEpyU2NHVGMMj+y+wta6MK5bOvsXC0lIfeS6JrWTae6YHn8fF5hXlk+5r76h2IiXxk1faiBhiq5fiNdUUEY4YzvdMnkV0DIzOagVTort3rmR4bPo7q399qpsV5QX839++muNtA3z84ZcJZ7AkuDswitsllM7id7fE5+GaxgqeeS394WR2+mxrfbRed21jJQfO9SYNvpczDRCLTFmhh699YAeB0RDPN3dnlF6yXVVfzh++YbWDo5s/iTOIVy8NcLxtMCuzB4gG5+XlBbEU096z3WxfWZE0OFcUeWmsLuLlKVp/9wSC/PG3DvCL49M7he6xwy2sW1LMuiRtQ5pq7JYqkwNE++Bo0jbfM7WlroxNy6dXrI5EDC+c6eb1q6u4+YpaPrdrEz8/1sHfPHEs7WN7AkEqi7yx/SYzdePaGo63DcZqMqkcvtiH2yVsXBYNEDsbKxkZi/Bqy/xsEpwpDRCL0BVLS/jbd28Bkp8itxiVJBw7+t8HLpCf5+IdSd5pz1R9ZQEXe4cZGBnjaMtA0vqD7ar6cl6+0JfyxfPLe07wxCtt/O439vN3T57I6F10a/8w+872cseW5M9pfC/E5ADROTCS1RmEiHD3zmixOtOZ0rG2AfqGxrhudXRZ8Aeua+De1zfw/547w3+9cG7Kx3b5p9+HKZkb1lQD8Nyprinvd+hiP+uWlFDgjabkrrGaV+baclcNEIvUHVuW843fuYY/vGlhzgimK75IPTIW5kcvX+K2K5fOau9DovqKQi72DnHgbC8Rw5QBYtvKcjoHR2npn/xO9UTbIN9+8Tx3XVPPe3fU8y9Pn+KDD71Il390yr//sUPRJZrxq5filfo81JTkT1rqGj1XfHa7qJO50y5WZ7iz+vnT0Ry+HSAA/vKOjdyyvpbP7j4yZeon2iF39gFi47JSqoq8PHsydYAwxnD4Yl9sjwlEi/tNNUUaIFTuuPmK2sv6pLe5ZLfxHhgJsedoOwMjId6TpfSSra6igC5/kP850YHHLWyrr0h5X7sOkZhmMsbw+ceOUpyfx6duW8+X3r2Fv333Fvaf7eWOrzzHgXMTX4D6h8d4eO953vvV5/nCE8fYWlcWSyUl01Q9eSVTb2wXdXYDhF2sfvRQa0a9ip4/3U1TddGE3l5ul/CVu7extraYD3/rJV5rT778NdrJdfbjd7mEG9ZW8+zJrpTtUC70DNM3NMaWuvIJ169trGTf2Z6MZnvTcax1IHZyY7ZpgFCK6AtNkdfN4MgYj+y/wIryAq7L8g5w+yyIRw+3sqWuPJZ+SGb90lLy81wcTFhS+dSxDp471cWfvHkdFVbK5D076vnBH78eb56L9371Bb7+bDM/O9LGH3/rANd84efc/4NX6Bwc5RNvWce/3bNjyjE21RRPmkHYBwU50VPr3VfXMTwWZs/RqVcGhcIRXjzTw+tWT/6ZFOdH28r4vG7u++b+pCujZtLJNZUb19bQ5R/leIq9GHa79i11EzeUXttYxeBIiONtA1kZh+2vdh/hgw+9mNXvadMAoZSlxOfhtfZBnjvVxbuvrpt1QTORfS5ETyCYdHlrPG+eiytXlE1ouREMRfjCE8doqiniA9etmnD/TcvLePSjN/DG9bX89ePHuO8/D/Bicw/v27mSH3/4ep765Bv42JvWpq0jrK4pondobMJhP/ZRo9ksUtu2r6xgRXlB2tVMr7YM4B8N8fokAQJgeXkB//r+7VzoHeZT3zs8oXYzGgozOBrKSg0C4Ma10TrEsyeTp7QOX+zDm+eatPrNTilmM83U1j/C3rM9KetKs6UBQilLiS+PX53qxpjoO9tsszfLwdT1B9u2+nJevdQfWxr5zefPcqYrwF++fSMe9+T/umUFHr72gav51/dv59/vvYYX/vxN/NWuTWytL0953niiZE377E1y2SxS21wuYddVy3n2ZBfdU9RQfn06mvOfqq/XNQ2V/O+3XsFPXm3jG78+G7s+fhZ1dgLcklIfVywpSVmHOHyxn43LSif9jJaXF1BXUZDVABE9p4KsLqaIpwFCKYu9kun1q6smHQ2aDTUl+eTnuXAJXL0qdf3Btm1lBaOhCMfbBugJBPmnp05y07oabr6iJuVjRIS3bV7GG9fXJg0i6TRZbVfiVzLZjfqcOld819blhCOGJ6Y4s/r5091csaQkdvZ6Kvfd1MSbNyzhb544FqvfxNpsZGkGAdFZxN6zPQwHJ/ZXCkcMr17qn1CgjrezsZK9Z3qy1ofq0UMtbF5RNq3l6tOhAUIpi72SKdvFaZuIUF9ZyKblZRltNrzKapN+8EIfX95zgqFgmL94+4aMZwMzUVdRgMctnO6Km0EMjlJe6MHnmf0u6mTWLy1h3ZLilGmmYCjCvrM9E1YvpSIi/P1vbWVJqY8Pf+slegNBumMziCwGiHU1BEMR9p6dOBto7vQTCIYnFaht1zZW0h0IJt1rMl1nuwIcutjPO7YmX5WWDRoglLJUFnkp8eXx1k1LHfs7Hti1ic/duSmj+y4v81Fbks/3X7rEt188z/uvXZl0g1s25bldrKoqmjSDyPYKpngiwp1XrWD/ud7YRsJ4By/0MTIWyShAQHQz6L++fztd/iB/+shBOq1OtNlYxWTb2VCJN8/FswlLaxN3UE96XGP0OWQjzfTooWhAdar+ABoglIr5xFvW8a3fv3bK1UWz9fo11WxfmT69BNEXzqvqoyfMFefn8advXufYuOI1VRdNrEEMjjp+KuAuK4f+aJJT254/3Y0IvK4x81VlW+rK+cs7NvA/Jzp58OlTwMzPgkimwOtmZ0PlpDrE4YvRn1VTig7JDVWF1JTkZ+UAoUcPt7CzoZLl5c4d6asBQilLfWVhytTAfLEPEIpf1uq01bXRpn2hcLQ43jEw4lj9wVZfWcj2leXsTpJm+vXpLjYtL6WscHqbFn/7dat4x9blnOkK4HW7Yu3qs+WGtdWcaB+M1WggOoO4ckVpyhVwIsLOxkpeTFGHONk+yB9/60DapbDH2wZ4rd3vaHoJNEAodVl799V1fOq29ZOWtTqpqbqIsbDhQu9w9Cxqv/MzCIA7r1rB8bbBCWc9jIyFefl8H69fXT3t7ycifPGdm2mqKWJpmS/rtZvx5a7RWUQwFOFYywBb07zJuLaxktb+kUlnlP/44CXufPBXPPFKG5/6/itTnku++2ALbld0QYKTHA0QInKbiJwQkVMicn+S2z8kIq+IyEEReU5ENlrXG0Rk2Lp+UET+r5PjVOpyVVOSzx/dvHpGK5Jmyt5p3dzpp3coyFjYsMThGQTA2zYvwyWw+9Cl2LUD53oJhjOvPyQqzs/ju/ddx799cOoNgjOxYWkp1cXe2H6IE22DBMORtLPQxP0QwVCEv9p9hI8/fJCNy0q5//b1HLrQx/deupj08cYYHj3cwvVrqrO2dDcVx37rRMQNPAjcDmwE7rYDQJxvG2M2G2OuAv4W+HLcbaeNMVdZHx9yapxKqYlWW3shTnf6Y0eN1s7BDKKmJJ/r11Tz44MtsfTLr0934XZJrNndTL9vNlq2J3K5hBvWVPOc1XYj1Q7qROtqSygr8LD3TA+t/cPc9bXn+cavz/K71zfynftex303NnH1qgq+9JPj9A9P3hV+8EIfF3qGeUeKnlrZ5OTbkp3AKWNMszEmCDwM3Bl/B2NMfKKtCJi7Q2qVUkmVF3qpLPLS3BmI5dez3agvlTuvWsHF3vFT254/3c3WurJYr6zLzY1ra+gOBDnaOsDhi31UFnmpq5i6aOyyAt5Tx9u54yvPcbxtkH953zY+847oBkiXS/jcrk30DAX5x5+/Nunxuw+14HW7eOuVzq22i43Vwe+9ArgQ9/VF69oEIvJhETlNdAbxsbibGkXkZRH5pYjcmOwvEJH7RGS/iOzv7Ex/iIdSKjNN1vnUsRmEA7uok3nrpiV481zsPngJ/2iIQxf7Z5xemgvxdYjDF/vZvKIso1rHtY2VdPmDlBd62P2R6yctVb1yRRnv27mSbz5/bkJNJhwxPH64lZuvqJnV4UeZmvcitTHmQWPMauBTwF9Yl1uBlcaYbcAngG+LyKRzLo0xXzPG7DDG7KipSb27VCk1PdHzqf2xg3GcXsVkK/F5ePOGWh473MoLp7sJR8yMCtRzpbbUx/qlJfzsaBuvtQ+m3EGd6K6d9fzVOzby44/cwJra5Omv/3XrFZT48vjs7ldjKbcXz3TTMTjKrquc2/sQz8kAcQmI35JaZ11L5WHgNwCMMaPGmG7r8wPAaWBuFoErpWiqKabLH+RUh5+yAud2USeza+sKugNBvrznNbxuV0ZtSebTjWurefl8HxFDxsukS3we7r2+ccrUWUWRl0/eegUvNPfwuNWG5NFDrRR63bxp/ZJsDD0tJwPEPmCtiDSKiBe4C9gdfwcRWRv35duBk9b1GqvIjYg0AWuBZgfHqpSKs9payfR8c/ec1R9sN19RQ0l+HkdbB9i2snxOg9NM3Lh2PHuxJcUO6pl6386VbFxWyhceP0b/8Bg/ebWVt2xc4uhmzniOBQhjTAj4CPAkcAx4xBhzREQeEJFd1t0+IiJHROQg0VTSPdb1m4DD1vXvAR8yxuTWUUxK5TC7q2v7wOic1R9sPo+b26wC7OWcXrLtbIy23VhW5sv6v5XbJTxw5yZa+0f43W/so29oLLbrfC44ujTAGPME8ETCtc/Eff7xFI/7PvB9J8emlEptZWUheS6JniQ3xzMIgPdcU88PXr7ELetr5/zvni6fx827ttfFugFn246GSt65bQU/ePkSZQWeCTMWp12ea8eUUvPK43axsrKQ5q7AnM8gIHq2w+HP3krRZbq8NdEX37nZ0e9//+3r2XO0nXdsXYY3b+7WFuXGv75Sas5FVzIF5rwGYcuV4DAXakt9PPXJN1Ba4PzS1njzvsxVKXV5sltuzMcMQk1WW+qb84K9BgilVFJN1ill81GDUJcHncMppZJ666alNHcF0nYnVQuXBgilVFIVRV7+/G0b5nsYah5pikkppVRSGiCUUkolpQFCKaVUUhoglFJKJaUBQimlVFIaIJRSSiWlAUIppVRSGiCUUkolJfZRdrlORDqBc7P4FtVAV5aGk0v0eS8u+rwXl0ye9ypjTNIe4gsmQMyWiOw3xuyY73HMNX3ei4s+78Vlts9bU0xKKaWS0gChlFIqKQ0Q47423wOYJ/q8Fxd93ovLrJ631iCUUkolpTMIpZRSSWmAUEopldSiDxAicpuInBCRUyJy/3yPx0ki8pCIdIjIq3HXKkVkj4ictP6smM8xZpuI1IvI0yJyVESOiMjHresL/Xn7RGSviByynvfnrOuNIvKi9fv+XRHxzvdYnSAibhF5WUQes75eLM/7rIi8IiIHRWS/dW3Gv+uLOkCIiBt4ELgd2AjcLSIb53dUjvoGcFvCtfuBp4wxa4GnrK8XkhDwSWPMRuB1wIetn/FCf96jwC3GmK3AVcBtIvI64EvAPxhj1gC9wO/N3xAd9XHgWNzXi+V5A7zRGHNV3P6HGf+uL+oAAewEThljmo0xQeBh4M55HpNjjDHPAD0Jl+8E/sP6/D+A35jLMTnNGNNqjHnJ+nyQ6IvGChb+8zbGGL/1pcf6MMAtwPes6wvueQOISB3wduDr1tfCInjeU5jx7/piDxArgAtxX1+0ri0mS4wxrdbnbcCS+RyMk0SkAdgGvMgieN5WmuUg0AHsAU4DfcaYkHWXhfr7/o/A/wYi1tdVLI7nDdE3AT8TkQMicp91bca/63nZHp3KXcYYIyILct2ziBQD3wf+xBgzEH1TGbVQn7cxJgxcJSLlwA+B9fM7IueJyB1AhzHmgIjcPM/DmQ83GGMuiUgtsEdEjsffON3f9cU+g7gE1Md9XWddW0zaRWQZgPVnxzyPJ+tExEM0OHzLGPMD6/KCf942Y0wf8DRwHVAuIvYbw4X4+349sEtEzhJNGd8C/BML/3kDYIy5ZP3ZQfRNwU5m8bu+2APEPmCttcLBC9wF7J7nMc213cA91uf3AD+ex7FknZV//n/AMWPMl+NuWujPu8aaOSAiBcBbiNZfngbebd1twT1vY8ynjTF1xpgGov+ff2GMeT8L/HkDiEiRiJTYnwO3Aq8yi9/1Rb+TWkTeRjRn6QYeMsZ8YX5H5BwR+Q5wM9EWwO3AZ4EfAY8AK4m2S3+PMSaxkJ2zROQG4FngFcZz0n9OtA6xkJ/3FqIFSTfRN4KPGGMeEJEmou+sK4GXgd82xozO30idY6WY/pcx5o7F8Lyt5/hD68s84NvGmC+ISBUz/F1f9AFCKaVUcos9xaSUUioFDRBKKaWS0gChlFIqKQ0QSimlktIAoZRSKikNEEpNg4iErU6Z9kfWmvyJSEN8p12l5pu22lBqeoaNMVfN9yCUmgs6g1AqC6w+/H9r9eLfKyJrrOsNIvILETksIk+JyErr+hIR+aF1XsMhEXm99a3cIvJv1hkOP7N2QSs1LzRAKDU9BQkppvfG3dZvjNkM/AvR3fkA/wz8hzFmC/At4CvW9a8Av7TOa9gOHLGurwUeNMZsAvqAdzn6bJSagu6kVmoaRMRvjClOcv0s0QN6mq3mgG3GmCoR6QKWGWPGrOutxphqEekE6uLbPVjtyPdYB7sgIp8CPMaYv56Dp6bUJDqDUCp7TIrPpyO+P1AYrROqeaQBQqnseW/cn89bn/+aaFdRgPcTbRwI0aMf/whiB/uUzdUglcqUvjtRanoKrFPabD81xthLXStE5DDRWcDd1rWPAv8uIn8GdAK/Y13/OPA1Efk9ojOFPwJaUeoyojUIpbLAqkHsMMZ0zfdYlMoWTTEppZRKSmcQSimlktIZhFJKqaQ0QCillEpKA4RSSqmkNEAopZRKSgOEUkqppP5/lWOP4IeOVhYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "#Plot accuracy on same plt\n",
    "#Downward trend for loss, and upward trend for the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    72\n",
      "0    71\n",
      "Name: labels, dtype: int64\n",
      "1    18\n",
      "0    18\n",
      "Name: labels, dtype: int64\n",
      "5 100 20\n",
      "5 100 30\n",
      "4 100 40\n",
      "3 100 50\n",
      "3 200 20\n",
      "8 200 20\n",
      "4 200 30\n",
      "2 200 40\n",
      "4 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "7 100 20\n",
      "5 100 30\n",
      "9 100 30\n",
      "8 100 40\n",
      "7 100 50\n",
      "7 200 20\n",
      "7 200 30\n",
      "7 200 40\n",
      "4 200 50\n",
      "3 100 20\n",
      "3 100 30\n",
      "9 100 30\n",
      "4 100 50\n",
      "9 100 50\n",
      "4 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "9 200 50\n",
      "9 100 20\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 200 20\n",
      "6 200 20\n",
      "7 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "6 100 20\n",
      "5 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "5 200 20\n",
      "3 200 30\n",
      "8 200 30\n",
      "9 200 40\n",
      "9 200 50\n",
      "8 100 20\n",
      "9 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "2 200 20\n",
      "6 200 20\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "7 100 50\n",
      "5 200 20\n",
      "9 200 20\n",
      "2 200 40\n",
      "5 200 40\n",
      "4 200 50\n",
      "2 100 20\n",
      "4 100 20\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "2 200 30\n",
      "4 200 30\n",
      "2 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "8 100 20\n",
      "3 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "7 100 50\n",
      "6 200 20\n",
      "5 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "2 100 20\n",
      "6 100 20\n",
      "5 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 200 20\n",
      "2 200 30\n",
      "5 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "6 100 20\n",
      "4 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "4 100 50\n",
      "4 200 20\n",
      "9 200 20\n",
      "2 200 40\n",
      "6 200 40\n",
      "6 200 50\n",
      "5 100 20\n",
      "4 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "3 200 20\n",
      "9 200 20\n",
      "8 200 30\n",
      "9 200 40\n",
      "2 100 20\n",
      "4 100 30\n",
      "2 100 40\n",
      "9 100 40\n",
      "8 100 50\n",
      "5 200 20\n",
      "2 200 30\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "4 100 30\n",
      "2 100 40\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 200 20\n",
      "8 200 20\n",
      "9 200 30\n",
      "9 200 40\n",
      "2 100 20\n",
      "6 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "8 100 50\n",
      "6 200 20\n",
      "6 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "6 200 50\n",
      "6 100 20\n",
      "4 100 30\n",
      "4 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "6 200 40\n",
      "4 200 50\n",
      "6 100 20\n",
      "4 100 30\n",
      "9 100 30\n",
      "4 100 50\n",
      "9 100 50\n",
      "2 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "8 100 20\n",
      "2 100 40\n",
      "2 100 50\n",
      "2 200 20\n",
      "5 200 20\n",
      "3 200 30\n",
      "2 200 40\n",
      "8 200 40\n",
      "5 200 50\n",
      "2 100 20\n",
      "6 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "5 100 50\n",
      "3 200 20\n",
      "7 200 20\n",
      "5 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "7 100 20\n",
      "8 100 30\n",
      "9 100 40\n",
      "9 100 50\n",
      "9 200 20\n",
      "7 200 30\n",
      "6 200 40\n",
      "6 200 50\n",
      "7 100 20\n",
      "5 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "5 100 50\n",
      "2 200 20\n",
      "7 200 20\n",
      "7 200 30\n",
      "7 200 40\n",
      "5 200 50\n",
      "5 100 20\n",
      "3 100 30\n",
      "8 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "9 200 20\n",
      "9 200 30\n",
      "8 200 40\n",
      "7 200 50\n",
      "3 100 20\n",
      "9 100 20\n",
      "9 100 30\n",
      "9 100 40\n",
      "2 200 20\n",
      "2 200 30\n",
      "6 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "6 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "5 200 20\n",
      "3 200 30\n",
      "8 200 30\n",
      "7 200 40\n",
      "7 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "5 100 50\n",
      "3 200 20\n",
      "3 200 30\n",
      "8 200 30\n",
      "8 200 40\n",
      "2 100 20\n",
      "6 100 20\n",
      "4 100 30\n",
      "3 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "7 200 20\n",
      "2 200 40\n",
      "4 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "5 100 20\n",
      "8 100 20\n",
      "6 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "7 100 50\n",
      "8 200 20\n",
      "2 200 40\n",
      "7 200 40\n",
      "7 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "6 100 30\n",
      "2 100 40\n",
      "8 100 40\n",
      "5 100 50\n",
      "5 200 20\n",
      "2 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 100 20\n",
      "8 100 20\n",
      "5 100 30\n",
      "4 100 40\n",
      "8 100 40\n",
      "9 100 50\n",
      "8 200 20\n",
      "9 200 30\n",
      "6 200 40\n",
      "5 200 50\n",
      "3 100 20\n",
      "7 100 20\n",
      "8 100 30\n",
      "9 100 40\n",
      "3 200 20\n",
      "7 200 20\n",
      "6 200 30\n",
      "6 200 40\n",
      "6 200 50\n",
      "2 100 20\n",
      "3 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "3 100 50\n",
      "7 100 50\n",
      "5 200 20\n",
      "4 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "5 100 20\n",
      "3 100 30\n",
      "4 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "5 200 20\n",
      "4 200 30\n",
      "9 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "5 100 20\n",
      "9 100 20\n",
      "8 100 30\n",
      "3 100 50\n",
      "6 100 50\n",
      "4 200 20\n",
      "3 200 30\n",
      "7 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "4 100 30\n",
      "8 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "3 200 20\n",
      "2 200 30\n",
      "6 200 30\n",
      "5 200 40\n",
      "5 200 50\n",
      "3 100 20\n",
      "7 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "6 200 20\n",
      "5 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "5 200 20\n",
      "4 200 30\n",
      "9 200 30\n",
      "2 200 50\n",
      "6 200 50\n",
      "8 100 20\n",
      "4 100 30\n",
      "3 100 40\n",
      "6 100 40\n",
      "6 100 50\n",
      "4 200 20\n",
      "3 200 30\n",
      "8 200 30\n",
      "2 200 50\n",
      "5 200 50\n",
      "3 100 20\n",
      "7 100 20\n",
      "5 100 30\n",
      "2 100 40\n",
      "6 100 40\n",
      "4 100 50\n",
      "9 100 50\n",
      "3 200 30\n",
      "5 200 30\n",
      "3 200 40\n",
      "6 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "7 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "2 200 20\n",
      "7 200 20\n",
      "8 200 30\n",
      "9 200 40\n",
      "2 100 20\n",
      "6 100 20\n",
      "5 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 200 20\n",
      "3 200 30\n",
      "7 200 30\n",
      "7 200 40\n",
      "6 200 50\n",
      "4 100 20\n",
      "2 100 30\n",
      "7 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "2 200 20\n",
      "6 200 20\n",
      "4 200 30\n",
      "9 200 30\n",
      "8 200 40\n",
      "6 200 50\n",
      "4 100 20\n",
      "9 100 20\n",
      "7 100 30\n",
      "6 100 40\n",
      "5 100 50\n",
      "4 200 20\n",
      "8 200 20\n",
      "9 200 30\n",
      "6 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "6 100 20\n",
      "6 100 30\n",
      "5 100 40\n",
      "2 100 50\n",
      "9 100 50\n",
      "2 200 30\n",
      "5 200 30\n",
      "4 200 40\n",
      "2 200 50\n",
      "7 200 50\n",
      "5 100 20\n",
      "2 100 30\n",
      "6 100 30\n",
      "3 100 40\n",
      "2 100 50\n",
      "5 100 50\n",
      "3 200 20\n",
      "6 200 20\n",
      "8 200 30\n",
      "8 200 40\n",
      "9 200 50\n",
      "6 100 20\n",
      "2 100 30\n",
      "7 100 30\n",
      "7 100 40\n",
      "5 100 50\n",
      "3 200 20\n",
      "3 200 30\n",
      "7 200 30\n",
      "9 200 40\n",
      "7 200 50\n",
      "7 100 20\n",
      "5 100 30\n",
      "6 100 40\n",
      "8 100 50\n",
      "8 200 20\n",
      "2 200 40\n",
      "8 200 40\n",
      "8 200 50\n",
      "5 100 20\n",
      "3 100 30\n",
      "7 100 30\n",
      "7 100 40\n",
      "6 100 50\n",
      "3 200 20\n",
      "7 200 20\n",
      "7 200 30\n",
      "8 200 40\n",
      "8 200 50\n",
      "9 100 20\n",
      "7 100 30\n",
      "7 100 40\n",
      "7 100 50\n",
      "7 200 20\n",
      "4 200 30\n",
      "3 200 40\n",
      "9 200 40\n",
      "8 200 50\n",
      "7 100 20\n",
      "5 100 30\n",
      "3 100 40\n",
      "9 100 40\n",
      "7 100 50\n",
      "5 200 20\n",
      "2 200 30\n",
      "6 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "2 100 20\n",
      "9 100 20\n",
      "7 100 30\n",
      "4 100 40\n",
      "2 100 50\n",
      "2 200 20\n",
      "6 200 20\n",
      "5 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "5 100 20\n",
      "9 100 20\n",
      "2 100 40\n",
      "5 100 40\n",
      "2 100 50\n",
      "6 100 50\n",
      "4 200 20\n",
      "9 200 20\n",
      "3 200 40\n",
      "7 200 40\n",
      "5 200 50\n",
      "3 100 20\n",
      "8 100 20\n",
      "6 100 30\n",
      "9 100 40\n",
      "2 200 20\n",
      "6 200 20\n",
      "6 200 30\n",
      "5 200 40\n",
      "4 200 50\n",
      "9 200 50\n",
      "7 100 20\n",
      "3 100 30\n",
      "9 100 30\n",
      "2 100 50\n",
      "8 100 50\n",
      "8 200 20\n",
      "5 200 30\n",
      "3 200 40\n",
      "7 200 40\n",
      "9 200 50\n",
      "2 100 30\n",
      "9 100 30\n",
      "9 100 40\n",
      "6 100 50\n",
      "4 200 20\n",
      "9 200 20\n",
      "8 200 30\n",
      "4 200 40\n",
      "3 200 50\n",
      "9 200 50\n",
      "3 100 20\n",
      "6 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "8 100 50\n",
      "7 200 20\n",
      "4 200 30\n",
      "3 200 40\n",
      "6 200 40\n",
      "3 200 50\n",
      "3 100 20\n",
      "8 100 20\n",
      "9 100 30\n",
      "5 100 40\n",
      "3 100 50\n",
      "9 100 50\n",
      "8 200 20\n",
      "4 200 30\n",
      "3 200 40\n",
      "8 200 40\n",
      "7 200 50\n",
      "7 100 20\n",
      "9 100 20\n",
      "8 100 30\n",
      "2 100 50\n",
      "4 200 20\n",
      "9 200 20\n",
      "2 200 40\n",
      "2 200 50\n",
      "6 200 50\n",
      "6 100 20\n",
      "3 100 30\n",
      "3 100 40\n",
      "8 100 40\n",
      "6 100 50\n",
      "4 200 20\n",
      "9 200 20\n",
      "2 200 40\n",
      "4 200 40\n",
      "3 200 50\n",
      "7 200 50\n",
      "4 100 20\n",
      "4 100 30\n",
      "8 100 30\n",
      "6 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "8 200 20\n",
      "9 200 30\n",
      "2 200 50\n",
      "6 200 50\n",
      "5 100 20\n",
      "3 100 30\n",
      "3 100 40\n",
      "7 100 40\n",
      "7 100 50\n",
      "8 200 20\n",
      "8 200 30\n",
      "9 200 40\n",
      "8 200 50\n",
      "2 100 20\n",
      "8 100 20\n",
      "9 100 30\n",
      "9 100 40\n",
      "2 200 20\n",
      "6 200 20\n",
      "6 200 30\n",
      "4 200 40\n",
      "9 200 40\n",
      "8 200 50\n",
      "9 100 20\n",
      "7 100 30\n",
      "7 100 40\n",
      "8 100 50\n",
      "7 200 20\n",
      "6 200 30\n",
      "5 200 40\n",
      "3 200 50\n",
      "8 200 50\n",
      "7 100 20\n",
      "9 100 20\n",
      "8 100 30\n",
      "3 100 50\n",
      "9 100 50\n",
      "9 200 20\n",
      "9 200 30\n",
      "6 200 40\n",
      "4 200 50\n",
      "3 100 20\n",
      "8 100 20\n",
      "6 100 30\n",
      "5 100 40\n",
      "4 100 50\n",
      "8 100 50\n",
      "3 200 30\n",
      "7 200 30\n",
      "7 200 40\n",
      "9 200 50\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 64)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 64)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 64)\n",
      "  warnings.warn(\n",
      "/home/sanmati/miniconda3/envs/sana-env/lib/python3.10/site-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 64)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2128,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy={1: 1000, 0: 1000})\n",
    "\n",
    "# Fit SMOTE on X and y\n",
    "smote.fit(X_train, y_train)\n",
    "\n",
    "# Generate synthetic samples\n",
    "n_synthetic_samples = 1000\n",
    "X_synthetic, y_synthetic = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Concatenate original and synthetic data\n",
    "X_new = np.concatenate((X_train, X_synthetic))\n",
    "y_new = np.concatenate((y_train, y_synthetic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.sample(frac=1)\n",
    "labels = df2.labels\n",
    "df_one_feature = df2.drop(['labels'], axis =1 )\n",
    "col = df_one_feature.columns\n",
    "mm = MinMaxScaler()\n",
    "df_one_feature = mm.fit_transform(df_one_feature)\n",
    "df_one_feature = df_one_feature*100\n",
    "\n",
    "\n",
    "# train = df_new[0:120]\n",
    "# train_labels = np.array(labels[0:120])\n",
    "\n",
    "# test = df_new[120:]\n",
    "# test_labels = np.array(labels[120:])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_one_feature, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes):\n",
    "    layers = []\n",
    "    \n",
    "    nodes_increment = (last_layer_nodes-first_layer_nodes)/ (n_layers-1)\n",
    "    nodes = first_layer_nodes\n",
    "    for i in range(1, n_layers+1):\n",
    "        layers.append(math.ceil(nodes))\n",
    "        nodes = nodes + nodes_increment\n",
    "    return layers\n",
    "\n",
    "FindLayerNodesLinear(7, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel(n_layers, first_layer_nodes, activation_func, loss_func, last_layer_nodes):\n",
    "    model = Sequential()\n",
    "    print(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    n_nodes = FindLayerNodesLinear(n_layers, first_layer_nodes, last_layer_nodes)\n",
    "    for i in range(1, n_layers):\n",
    "        if i==1:\n",
    "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=activation_func))\n",
    "        else:\n",
    "            model.add(Dense(n_nodes[i-1], activation=activation_func))\n",
    "            \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='sgd', loss=loss_func, metrics = [\"accuracy\"]) \n",
    "    \n",
    "    return model\n",
    "\n",
    "model =  KerasClassifier(build_fn=createmodel, verbose = False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_funcs = ['relu', 'tanh'] \n",
    "loss_funcs = ['binary_crossentropy']\n",
    "param_grid = dict(n_layers=np.arange(2,10), first_layer_nodes = [50,100,150,200],activation_func = activation_funcs, loss_func = loss_funcs, last_layer_nodes= [30,40,50], batch_size = [30,40,50], epochs = [50,100,150])\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_one_feature = Sequential()\n",
    "model_one_feature.add(Dense(100, input_shape=(14,), activation='tanh'))\n",
    "model_one_feature.add(Dense(75, input_shape=(14,), activation='tanh'))\n",
    "model_one_feature.add(Dense(50, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(84, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(76, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(67, input_shape=(14,), activation='tanh'))\n",
    "# model.add(Dense(59, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(51, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(75, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(65, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(70, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(55, input_shape=(14,), activation='relu'))\n",
    "# model.add(Dense(50, input_shape=(14,), activation='relu'))\n",
    "model_one_feature.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "metrics = ['accuracy', Recall(), AUC()]\n",
    "best_loss = float('inf')\n",
    "best_optimizer = None\n",
    "best_metric = None\n",
    "# Compile the model with each optimizer and metric\n",
    "for optimizer in optimizers:\n",
    "    for metric in metrics:\n",
    "        model_one_feature.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metric)\n",
    "        \n",
    "        # Train and evaluate the model\n",
    "        history = model_one_feature.fit(X_train, y_train, epochs=50, batch_size=40)\n",
    "        val_loss, val_metric = model_one_feature.evaluate(X_test, y_test)\n",
    "        \n",
    "        # Print the validation loss and metric\n",
    "#         print('Optimizer: {}, Metric: {}, Validation Loss: {:.4f}, Validation Metric: {:.4f}'.format(optimizer, metric, val_loss, val_metric))\n",
    "        if val_loss < best_loss: \n",
    "            best_loss = val_loss\n",
    "            best_optimizer = optimizer\n",
    "            best_metric = metric\n",
    "print(best_loss)\n",
    "print(best_optimizer)\n",
    "print(best_metric)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_feature.compile(optimizer='sgd', loss='binary_crossentropy', metrics=Recall())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_new, labels, test_size=0.2, random_state=84)\n",
    "\n",
    "h_new = model_one_feature.fit(\n",
    "  X_train, # training data\n",
    "  y_train, # training targets\n",
    "  epochs=50,\n",
    "  batch_size=40,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_one_feature.predict(X_train)\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_train)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_one_feature.predict(X_test)\n",
    "\n",
    "rounded = [int(round(x[0])) for x in y_pred]\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(rounded,y_test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(model_one_feature, X_test, y_test, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "\n",
    "# print feature importances\n",
    "fig, ax = plt.subplots()\n",
    "col = ['0_x1', '1_x1','2_x1','3_x1', '4_x1','5_x1','6_x1']\n",
    "ax.bar(col, result.importances_mean)\n",
    "ax.set_xticklabels(col, rotation=90)\n",
    "ax.set_title('Feature Importances from Permutation Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(rounded, y_test)\n",
    "labels = ['Diseased', 'Healthy']\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_new.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "#Plot accuracy on same plt\n",
    "#Downward trend for loss, and upward trend for the accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sana-env",
   "language": "python",
   "name": "sana-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
